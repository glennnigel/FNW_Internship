{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9418540",
   "metadata": {},
   "source": [
    "<h1><u><font color='red'>Assignment-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdecfa93",
   "metadata": {},
   "source": [
    "<h2> <u> <font color='green'>Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b2f72",
   "metadata": {},
   "source": [
    "<h2> <font color='Blue'> 1) Write a python program to display all the header tags from wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "c8c683bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "#send a request to get source code of page\n",
    "wikipage =  requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "wikipage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "id": "911ac32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6779cfe",
   "metadata": {},
   "source": [
    "<h6>Note:\n",
    "Running the Declaration- \"Wikipage\" will seek permission to access source code for the webpage. \n",
    "incase the response is in the 200 series means it is a success or a positive response.\n",
    "and incase it is in the 500 series it usually understood that the server is busy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae006e0a",
   "metadata": {},
   "source": [
    "<h3>NEXT:\n",
    "Saving page content which includes HTML Codes, Jscripts, CSS and media content into a identifier; in this case \"Wiki\".\n",
    "The above operation is done using the Beautiful soup library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4ac93329",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wiki= BeautifulSoup(wikipage.content)\n",
    "#Wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66eadde",
   "metadata": {},
   "source": [
    "<h6>Note: I have not displayed the source code for the webpage as it is inconvenient to read using jupiter notebook. \n",
    "Personally i have used Google Chrome's inspect feature to do the same.\n",
    "if it is to be displayed, we can always do it by including the declared \"wiki\" as part of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6af5ba",
   "metadata": {},
   "source": [
    "<h3>NEXT: Inspect the Source code to find the header tags, usually denoted as h1 , h2, h3... h6.\n",
    "\n",
    "      Hence looking for above 'tags'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb8bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting search parameters\n",
    "tags = [\"h1\", \"h2\", \"h3\", \"h4\",\"h5\",\"h6\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1f8701",
   "metadata": {},
   "source": [
    "<h3> NEXT: Using the built-in function in Beautiful soups- 'find_all' we can find above parameters.\n",
    "      And using a simple for loop we can display them using a print command.\n",
    "      This is similar to using 'Find' (Ctrl-F) on webpages, MS office etc. where we simply search for the                         parameters/keywords. We can then choose to display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "889b511b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Page is a  h1\n",
      "Welcome to Wikipedia is a  h1\n",
      "From today's featured article is a  h2\n",
      "Did you know ... is a  h2\n",
      "In the news is a  h2\n",
      "On this day is a  h2\n",
      "Today's featured picture is a  h2\n",
      "Other areas of Wikipedia is a  h2\n",
      "Wikipedia's sister projects is a  h2\n",
      "Wikipedia languages is a  h2\n",
      "Navigation menu is a  h2\n",
      "Personal tools is a  h3\n",
      "Namespaces is a  h3\n",
      "Views is a  h3\n",
      "Search is a  h3\n",
      "Navigation is a  h3\n",
      "Contribute is a  h3\n",
      "Tools is a  h3\n",
      "Print/export is a  h3\n",
      "In other projects is a  h3\n",
      "Languages is a  h3\n"
     ]
    }
   ],
   "source": [
    "#printing a list of all headers in above URL using the search parameters in 'tags'.\n",
    "for tag in Wiki.find_all(tags):\n",
    "    print(tag.text.strip(), 'is a ', tag.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac1f52b",
   "metadata": {},
   "source": [
    "<h3>NEXT: As the above displayed solution is a little monotonous to look at, we can either choose to construct a Dataframe by inistialising an empty list and then saving the header tags into it, and then displaying the result as a DF.\n",
    "\n",
    "OR\n",
    "\n",
    "Displaying the same content using a simple print statement, but adding some highlight and font colour etc (courtesy the coloroma library). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "877eacde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[42mMain Page\u001b[0m is a \u001b[31mh1\u001b[0m\n",
      "\u001b[42mWelcome to Wikipedia\u001b[0m is a \u001b[31mh1\u001b[0m\n",
      "\u001b[42mFrom today's featured article\u001b[0m is a \u001b[31mh2\u001b[0m\n",
      "\u001b[42mDid you know ...\u001b[0m is a \u001b[31mh2\u001b[0m\n",
      "\u001b[42mIn the news\u001b[0m is a \u001b[31mh2\u001b[0m\n",
      "\u001b[42mOn this day\u001b[0m is a \u001b[31mh2\u001b[0m\n",
      "\u001b[42mToday's featured picture\u001b[0m is a \u001b[31mh2\u001b[0m\n",
      "\u001b[42mOther areas of Wikipedia\u001b[0m is a \u001b[31mh2\u001b[0m\n",
      "\u001b[42mWikipedia's sister projects\u001b[0m is a \u001b[31mh2\u001b[0m\n",
      "\u001b[42mWikipedia languages\u001b[0m is a \u001b[31mh2\u001b[0m\n",
      "\u001b[42mNavigation menu\u001b[0m is a \u001b[31mh2\u001b[0m\n",
      "\u001b[42mPersonal tools\u001b[0m is a \u001b[31mh3\u001b[0m\n",
      "\u001b[42mNamespaces\u001b[0m is a \u001b[31mh3\u001b[0m\n",
      "\u001b[42mViews\u001b[0m is a \u001b[31mh3\u001b[0m\n",
      "\u001b[42mSearch\u001b[0m is a \u001b[31mh3\u001b[0m\n",
      "\u001b[42mNavigation\u001b[0m is a \u001b[31mh3\u001b[0m\n",
      "\u001b[42mContribute\u001b[0m is a \u001b[31mh3\u001b[0m\n",
      "\u001b[42mTools\u001b[0m is a \u001b[31mh3\u001b[0m\n",
      "\u001b[42mPrint/export\u001b[0m is a \u001b[31mh3\u001b[0m\n",
      "\u001b[42mIn other projects\u001b[0m is a \u001b[31mh3\u001b[0m\n",
      "\u001b[42mLanguages\u001b[0m is a \u001b[31mh3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#running the same previous code but displayed with some formatting using coloroma library\n",
    "from colorama import Fore, Back, Style\n",
    "for tag in Wiki.find_all(tags):\n",
    "    print(Back.GREEN + tag.text.strip()+Style.RESET_ALL+ ' is a '+ Fore.RED +  tag.name + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff87f46",
   "metadata": {},
   "source": [
    "<h2><center><font color='red'>SUCCESS!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45c7b1f",
   "metadata": {},
   "source": [
    "<h2><font color = 'red'>*********************************************************************************************************</fomt>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d7a52f",
   "metadata": {},
   "source": [
    "<h2> <font color='Blue'>2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)\n",
    "and make data frame.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebf7ebe",
   "metadata": {},
   "source": [
    "<h5>Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796f0a12",
   "metadata": {},
   "source": [
    "<h6> The below URL was chosen following a google search for the the request 'top' + '100' + 'movies'+ 'imdb'.<br> \n",
    "<font color='blue'> <u> https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&count=100&start=000&ref_=adv_next'</font> </u><br>\n",
    "    Using the above URL for this demonstration.<br><br>\n",
    "<h3><font color='green'> First: Step1.</font> Libraries required. \n",
    "    skipping import since we have already imported in this file for the previous example  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6ca916",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step2.</font> Determine the <font color='red'>URL </font>to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cbfebec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_url = 'https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&count=100&start=000&ref_=adv_next'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195c8a15",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step2.1.</font> making 'Request' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "bd6da224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#request for Source code of URL-'imdb'with error handling function\n",
    "def request_access():\n",
    "    link= 'https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&count=100&start=000&ref_=adv_next'\n",
    "    check=requests.get(link)\n",
    "    #error handling\n",
    "    #if response is anything except 200 an exception is made\n",
    "    if check.status_code != 200:\n",
    "        raise Exception(f'Server Busy, Try again later! {link}')\n",
    "    # Parse using BeautifulSoup function\n",
    "    imdb_content = BeautifulSoup(check.text, 'html.parser')\n",
    "    return imdb_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb87b477",
   "metadata": {},
   "source": [
    "<h5>As no exception handling was carried out - Request is a Success. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cace0656",
   "metadata": {},
   "source": [
    "<h3><font color='green'>Step2.2.</font> Save page content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "7add6028",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_content=request_access()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a440589f",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step3.</font> Using Inspect in Google Chrome, analyse and identify the elements in question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3778dcf5",
   "metadata": {},
   "source": [
    "<h5>Inferences:<br>\n",
    "    1.Found that the divisional tag <font color='red'>'lister-item-header'</font> holds composite values of <font color='red'>'Rank', 'Name','Year or release'</font>.<br>\n",
    "    2.The header tags in question are <font color='red'>'h3', 'a' . with attributes 'class', 'href' etc</font>.<br>\n",
    "    3.Since we need to operate in this area, lets marquee the division as selection.<br>\n",
    "    4.From the selection, we can use the header tags to get the elements required. <br>\n",
    "    5.Creating an empty list to hold the movie names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4e8a085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceeding to harvest title from selection\n",
    "\n",
    "def harvest_movnames(imdb_content):\n",
    "    \n",
    "    #marquee the selection\n",
    "    \n",
    "    selection=\"lister-item-header\"\n",
    "    marquee=imdb_content.find_all('h3',{'class':selection})\n",
    "    \n",
    "    #Inititalise Empty list to store names\n",
    "    \n",
    "    movie_names=[]\n",
    "    \n",
    "    #from marquee harvest movie names using a simple text search in selection\n",
    "    \n",
    "    for tag in marquee:\n",
    "        title = tag.find('a').text\n",
    "        movie_names.append(title)\n",
    "    \n",
    "    #return the movie names\n",
    "        \n",
    "    return movie_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14396818",
   "metadata": {},
   "source": [
    "<h5> Above function holds all <font color='red'>100 movie names</font> in order of Rank.<br><br>\n",
    "     To check if above function works, We can simply display all 100 names by calling the above () which will just cause a<br> clutter in the notebook, hence assigning to another variable and calling only 3 names from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "04b8ff23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Shawshank Redemption', 'The Godfather', 'The Dark Knight']"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#harvest_movnames(imdb_content)------ to display all 100 movie names\n",
    "#assigning to another variable\n",
    "nom = harvest_movnames(imdb_content)\n",
    "#calling 3 names from top\n",
    "nom[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bce427",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step4.</font> Using Inspect in Google Chrome, analyse and identify the <font color='red'>year of release</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a359c91",
   "metadata": {},
   "source": [
    "<h5> 1.Similar to the previous (), the year of release is in the same division, we can either approach the same way and create a marquee or we can use the fact that there is a unique class, based on which we can make a selection marquee.<br><br>\n",
    "    2. Once we have a marquee selection, we can get the user readable portion of the string using the get_text() in bs4, and the remove the head and tail section using strip().<br><br>\n",
    "    3. Like before we initialise an empty list to store the year of release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "eeb33220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harvest_year(imdb_content):\n",
    "    \n",
    "     #marquee the selection\n",
    "    \n",
    "    selection2 = \"lister-item-year text-muted unbold\"           \n",
    "    marquee2=imdb_content.find_all('span',{'class':selection2})\n",
    "    \n",
    "     #Inititalise Empty list to store year of movie release\n",
    "        \n",
    "    year_released=[]\n",
    "    \n",
    "     #from marquee harvest year of movie release using a simple text search in selection\n",
    "    \n",
    "    for year in marquee2:\n",
    "        year_released.append(year.get_text().strip()[1:5])\n",
    "        \n",
    "     #return the year of movie release\n",
    "        \n",
    "    return year_released"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d3f87b",
   "metadata": {},
   "source": [
    "<h5> Above function holds all <font color='red'>100 year of release</font> in order of Rank.<br><br>\n",
    "     To check if above function works, We can simply display all 100 years by calling the above () which will just cause a<br> clutter in the notebook, hence assigning to another variable and calling only 3 names from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "110224e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1994', '1972', '2008']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#harvest_year(imdb_content)------ to display all 100 movie release year\n",
    "year=harvest_year(imdb_content)\n",
    "year[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f62e6a4",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step5.</font> Using Inspect in Google Chrome, analyse and identify the Rating of the respective movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee1b8f2",
   "metadata": {},
   "source": [
    "<h5> 1.Similar to the previous (), the year of release is in the same division, there is a unique class, based on which we can make a selection marquee.<br><br>\n",
    "    2. Once we have a marquee selection, we can get the user readable portion of the string using the get_text() in bs4, and the remove the head and tail section using strip().<br><br>\n",
    "    3. Like before we initialise an empty list to store the rating of the Movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "def97eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_imdb(imdb_content):\n",
    "    \n",
    "     #marquee the selection\n",
    "        \n",
    "    selection3=\"inline-block ratings-imdb-rating\"            \n",
    "    marquee3=doc.find_all('div',{'class':selection3})\n",
    "    \n",
    "     #Inititalise Empty list to store movie rating\n",
    "        \n",
    "    imdb_rating=[]\n",
    "    \n",
    "     #from marquee harvest mmovie rating using a simple text search in selection\n",
    "        \n",
    "    for rating in marquee3:\n",
    "        imdb_rating.append(rating.get_text().strip())\n",
    "        \n",
    "     #return the movie rating\n",
    "        \n",
    "    return imdb_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a6ac3",
   "metadata": {},
   "source": [
    "<h5> Above function holds all <font color='red'>100 Rating</font> in order of Rank.<br><br>\n",
    "     To check if above function works, We can simply display all 100 IMDB Ratings by calling the above () which will just cause a<br> clutter in the notebook, hence assigning to another variable and calling only 3 ratings from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "bc299a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.3', '9.2', '9.0']"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rating_imdb(imdb_content)------ to display all 100 movie rating.\n",
    "imdb_r=rating_imdb(imdb_content)\n",
    "imdb_r[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e97db",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step6.</font> Using Inspect in Google Chrome, analyse and identify the Rank of the respective movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "af97a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harvest_rank(imdb_content):\n",
    "    \n",
    "  \n",
    "    #Inititalise Empty list to store IMDB' rank for Movie\n",
    "    movie_rank=[]\n",
    "    \n",
    "    #marquee the selection\n",
    "    selection4=\"lister-item-index unbold text-primary\"\n",
    "    \n",
    "     #from marquee harvest IMDB' rank for Movie using a simple text search in selection\n",
    "     #since the rank had a '.' after it, removing it by using string operations- replace()\n",
    "    \n",
    "    for rank in imdb_content.find_all('span',class_=selection4):\n",
    "        movie_rank.append(rank.text.replace('.',''))    \n",
    "        \n",
    "        #return the IMDB' rank for Movie\n",
    "        \n",
    "    return movie_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd4f91",
   "metadata": {},
   "source": [
    "<h5> Above function holds all <font color='red'>100 rank</font> in order of movie ranks.<br><br>\n",
    "     To check if above function works, We can simply display all 100 IMDB Ranks by calling the above () which will just cause a<br> clutter in the notebook, hence assigning to another variable and calling only 3 ranks from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "01ad1149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#harvest_rank(imdb_content)------ to display all 100 movie ranks.\n",
    "imdb_rank=harvest_rank(imdb_content)\n",
    "imdb_rank[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdf57c2",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step7.</font> Composing a Dictionary using the above found lists as a precursor to the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf71f95a",
   "metadata": {},
   "source": [
    "<h5>1. Initialising Dictionary<br>\n",
    "2. Adding list to dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "26c4c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inititalising Dictionary\n",
    "pre_data = dict()\n",
    "#Adding lists to Dictionary\n",
    "pre_data = {'Name of Movie':nom, 'IMDB Rating':imdb_r, 'Year of Release':year,'IMDB Rank':imdb_rank }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ccf862",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Finally: Step8.</font> Structuring a DataFrame from the Dictionary composed in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "6e69dc0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Movie</th>\n",
       "      <th>IMDB Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "      <th>IMDB Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1972</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1974</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1957</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1994</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Inception</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Lord of the Rings: The Two Towers</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Lord of the Rings: The Fellowship of the Ring</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2001</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1994</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Il buono, il brutto, il cattivo</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1966</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Matrix</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1999</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Goodfellas</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1990</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Empire Strikes Back</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1980</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1975</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2014</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cidade de Deus</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2002</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sen to Chihiro no kamikakushi</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2001</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Saving Private Ryan</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1998</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The Green Mile</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1999</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>La vita è bella</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1997</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Se7en</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1995</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1991</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1991</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Star Wars</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1977</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Seppuku</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1962</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Shichinin no samurai</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1954</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>It's a Wonderful Life</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1946</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Gisaengchung</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2019</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Whiplash</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2014</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Top Gun: Maverick</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2022</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The Intouchables</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2011</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The Prestige</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2006</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>The Departed</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2006</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>The Pianist</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2002</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Gladiator</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2000</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>American History X</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1998</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The Usual Suspects</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1995</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Léon</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1994</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>The Lion King</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1994</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Nuovo Cinema Paradiso</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1988</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Hotaru no haka</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1988</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Back to the Future</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1985</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Apocalypse Now</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1979</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Alien</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1979</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Once Upon a Time in the West</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1968</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Psycho</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1960</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Rear Window</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1954</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Casablanca</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1942</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Modern Times</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1936</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>City Lights</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1931</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Capharnaüm</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2018</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Joker</td>\n",
       "      <td>8.4</td>\n",
       "      <td>I) (</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Kimi no na wa.</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2016</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Spider-Man: Into the Spider-Verse</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2018</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2019</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2018</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Coco</td>\n",
       "      <td>8.4</td>\n",
       "      <td>I) (</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Django Unchained</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2012</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2012</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2009</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>WALL·E</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2008</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>The Lives of Others</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2006</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Oldeuboi</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2003</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Memento</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2000</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>American Beauty</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1999</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Mononoke-hime</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1997</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Braveheart</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1995</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Idi i smotri</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1985</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Aliens</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1986</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Amadeus</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1984</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Raiders of the Lost Ark</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1981</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Das Boot</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1981</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>The Shining</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1980</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Tengoku to jigoku</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1963</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1964</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Witness for the Prosecution</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1957</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Paths of Glory</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1957</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Sunset Blvd.</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1950</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>The Great Dictator</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1940</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Jagten</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2012</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2010</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Inglourious Basterds</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2009</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Eternal Sunshine of the Spotless Mind</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2004</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Requiem for a Dream</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Good Will Hunting</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1997</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1995</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Reservoir Dogs</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1992</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Once Upon a Time in America</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1984</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Star Wars: Episode VI - Return of the Jedi</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1983</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2001: A Space Odyssey</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1968</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Lawrence of Arabia</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1962</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1959</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Vertigo</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1958</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1952</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Citizen Kane</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1941</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1931</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           Name of Movie  \\\n",
       "0                                               The Shawshank Redemption   \n",
       "1                                                          The Godfather   \n",
       "2                                                        The Dark Knight   \n",
       "3                          The Lord of the Rings: The Return of the King   \n",
       "4                                                       Schindler's List   \n",
       "5                                                  The Godfather Part II   \n",
       "6                                                           12 Angry Men   \n",
       "7                                                           Pulp Fiction   \n",
       "8                                                              Inception   \n",
       "9                                  The Lord of the Rings: The Two Towers   \n",
       "10                                                            Fight Club   \n",
       "11                     The Lord of the Rings: The Fellowship of the Ring   \n",
       "12                                                          Forrest Gump   \n",
       "13                                       Il buono, il brutto, il cattivo   \n",
       "14                                                            The Matrix   \n",
       "15                                                            Goodfellas   \n",
       "16                                               The Empire Strikes Back   \n",
       "17                                       One Flew Over the Cuckoo's Nest   \n",
       "18                                                          Interstellar   \n",
       "19                                                        Cidade de Deus   \n",
       "20                                         Sen to Chihiro no kamikakushi   \n",
       "21                                                   Saving Private Ryan   \n",
       "22                                                        The Green Mile   \n",
       "23                                                       La vita è bella   \n",
       "24                                                                 Se7en   \n",
       "25                                            Terminator 2: Judgment Day   \n",
       "26                                              The Silence of the Lambs   \n",
       "27                                                             Star Wars   \n",
       "28                                                               Seppuku   \n",
       "29                                                  Shichinin no samurai   \n",
       "30                                                 It's a Wonderful Life   \n",
       "31                                                          Gisaengchung   \n",
       "32                                                              Whiplash   \n",
       "33                                                     Top Gun: Maverick   \n",
       "34                                                      The Intouchables   \n",
       "35                                                          The Prestige   \n",
       "36                                                          The Departed   \n",
       "37                                                           The Pianist   \n",
       "38                                                             Gladiator   \n",
       "39                                                    American History X   \n",
       "40                                                    The Usual Suspects   \n",
       "41                                                                  Léon   \n",
       "42                                                         The Lion King   \n",
       "43                                                 Nuovo Cinema Paradiso   \n",
       "44                                                        Hotaru no haka   \n",
       "45                                                    Back to the Future   \n",
       "46                                                        Apocalypse Now   \n",
       "47                                                                 Alien   \n",
       "48                                          Once Upon a Time in the West   \n",
       "49                                                                Psycho   \n",
       "50                                                           Rear Window   \n",
       "51                                                            Casablanca   \n",
       "52                                                          Modern Times   \n",
       "53                                                           City Lights   \n",
       "54                                                            Capharnaüm   \n",
       "55                                                                 Joker   \n",
       "56                                                        Kimi no na wa.   \n",
       "57                                     Spider-Man: Into the Spider-Verse   \n",
       "58                                                     Avengers: Endgame   \n",
       "59                                                Avengers: Infinity War   \n",
       "60                                                                  Coco   \n",
       "61                                                      Django Unchained   \n",
       "62                                                 The Dark Knight Rises   \n",
       "63                                                              3 Idiots   \n",
       "64                                                                WALL·E   \n",
       "65                                                   The Lives of Others   \n",
       "66                                                              Oldeuboi   \n",
       "67                                                               Memento   \n",
       "68                                                       American Beauty   \n",
       "69                                                         Mononoke-hime   \n",
       "70                                                            Braveheart   \n",
       "71                                                          Idi i smotri   \n",
       "72                                                                Aliens   \n",
       "73                                                               Amadeus   \n",
       "74                                               Raiders of the Lost Ark   \n",
       "75                                                              Das Boot   \n",
       "76                                                           The Shining   \n",
       "77                                                     Tengoku to jigoku   \n",
       "78  Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb   \n",
       "79                                           Witness for the Prosecution   \n",
       "80                                                        Paths of Glory   \n",
       "81                                                          Sunset Blvd.   \n",
       "82                                                    The Great Dictator   \n",
       "83                                                                Jagten   \n",
       "84                                                           Toy Story 3   \n",
       "85                                                  Inglourious Basterds   \n",
       "86                                 Eternal Sunshine of the Spotless Mind   \n",
       "87                                                   Requiem for a Dream   \n",
       "88                                                     Good Will Hunting   \n",
       "89                                                             Toy Story   \n",
       "90                                                        Reservoir Dogs   \n",
       "91                                           Once Upon a Time in America   \n",
       "92                            Star Wars: Episode VI - Return of the Jedi   \n",
       "93                                                 2001: A Space Odyssey   \n",
       "94                                                    Lawrence of Arabia   \n",
       "95                                                    North by Northwest   \n",
       "96                                                               Vertigo   \n",
       "97                                                   Singin' in the Rain   \n",
       "98                                                          Citizen Kane   \n",
       "99                                     M - Eine Stadt sucht einen Mörder   \n",
       "\n",
       "   IMDB Rating Year of Release IMDB Rank  \n",
       "0          9.3            1994         1  \n",
       "1          9.2            1972         2  \n",
       "2          9.0            2008         3  \n",
       "3          9.0            2003         4  \n",
       "4          9.0            1993         5  \n",
       "5          9.0            1974         6  \n",
       "6          9.0            1957         7  \n",
       "7          8.9            1994         8  \n",
       "8          8.8            2010         9  \n",
       "9          8.8            2002        10  \n",
       "10         8.8            1999        11  \n",
       "11         8.8            2001        12  \n",
       "12         8.8            1994        13  \n",
       "13         8.8            1966        14  \n",
       "14         8.7            1999        15  \n",
       "15         8.7            1990        16  \n",
       "16         8.7            1980        17  \n",
       "17         8.7            1975        18  \n",
       "18         8.6            2014        19  \n",
       "19         8.6            2002        20  \n",
       "20         8.6            2001        21  \n",
       "21         8.6            1998        22  \n",
       "22         8.6            1999        23  \n",
       "23         8.6            1997        24  \n",
       "24         8.6            1995        25  \n",
       "25         8.6            1991        26  \n",
       "26         8.6            1991        27  \n",
       "27         8.6            1977        28  \n",
       "28         8.6            1962        29  \n",
       "29         8.6            1954        30  \n",
       "30         8.6            1946        31  \n",
       "31         8.5            2019        32  \n",
       "32         8.5            2014        33  \n",
       "33         8.5            2022        34  \n",
       "34         8.5            2011        35  \n",
       "35         8.5            2006        36  \n",
       "36         8.5            2006        37  \n",
       "37         8.5            2002        38  \n",
       "38         8.5            2000        39  \n",
       "39         8.5            1998        40  \n",
       "40         8.5            1995        41  \n",
       "41         8.5            1994        42  \n",
       "42         8.5            1994        43  \n",
       "43         8.5            1988        44  \n",
       "44         8.5            1988        45  \n",
       "45         8.5            1985        46  \n",
       "46         8.5            1979        47  \n",
       "47         8.5            1979        48  \n",
       "48         8.5            1968        49  \n",
       "49         8.5            1960        50  \n",
       "50         8.5            1954        51  \n",
       "51         8.5            1942        52  \n",
       "52         8.5            1936        53  \n",
       "53         8.5            1931        54  \n",
       "54         8.4            2018        55  \n",
       "55         8.4            I) (        56  \n",
       "56         8.4            2016        57  \n",
       "57         8.4            2018        58  \n",
       "58         8.4            2019        59  \n",
       "59         8.4            2018        60  \n",
       "60         8.4            I) (        61  \n",
       "61         8.4            2012        62  \n",
       "62         8.4            2012        63  \n",
       "63         8.4            2009        64  \n",
       "64         8.4            2008        65  \n",
       "65         8.4            2006        66  \n",
       "66         8.4            2003        67  \n",
       "67         8.4            2000        68  \n",
       "68         8.4            1999        69  \n",
       "69         8.4            1997        70  \n",
       "70         8.4            1995        71  \n",
       "71         8.4            1985        72  \n",
       "72         8.4            1986        73  \n",
       "73         8.4            1984        74  \n",
       "74         8.4            1981        75  \n",
       "75         8.4            1981        76  \n",
       "76         8.4            1980        77  \n",
       "77         8.4            1963        78  \n",
       "78         8.4            1964        79  \n",
       "79         8.4            1957        80  \n",
       "80         8.4            1957        81  \n",
       "81         8.4            1950        82  \n",
       "82         8.4            1940        83  \n",
       "83         8.3            2012        84  \n",
       "84         8.3            2010        85  \n",
       "85         8.3            2009        86  \n",
       "86         8.3            2004        87  \n",
       "87         8.3            2000        88  \n",
       "88         8.3            1997        89  \n",
       "89         8.3            1995        90  \n",
       "90         8.3            1992        91  \n",
       "91         8.3            1984        92  \n",
       "92         8.3            1983        93  \n",
       "93         8.3            1968        94  \n",
       "94         8.3            1962        95  \n",
       "95         8.3            1959        96  \n",
       "96         8.3            1958        97  \n",
       "97         8.3            1952        98  \n",
       "98         8.3            1941        99  \n",
       "99         8.3            1931       100  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df = pd.DataFrame(pre_data)\n",
    "#display(imdb_df)-------Can be used to display head and tail of DF\n",
    "\n",
    "#permanently disabling display restrictions.\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "imdb_df\n",
    "\n",
    "\n",
    "#pd.reset_option('all')  -----------To Undo Global override, as it may Override future display restrictions in a DF   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a17f48",
   "metadata": {},
   "source": [
    "<h5><font color='red'>Final result:</font> Displayed the Name , Rating and year of release. Additionally, displayed the IMDB Rank.\n",
    "   <br> Note:  Display restriction of DF is overridden to display full DF.\n",
    "<h3> <center><font color='red'>SUCCESS!!</font>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e966991d",
   "metadata": {},
   "source": [
    "<h2><font color='red'>********************************************************************************************************* </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488f78e4",
   "metadata": {},
   "source": [
    "<h2> <font color ='blue'> 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of\n",
    "release) and make data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf34ce5",
   "metadata": {},
   "source": [
    "<h5>Solution:<br> \n",
    "    1. Following the same approach used for Q2<br>\n",
    "    2. Solving in brief as detailed explainations are already mentioned done in Q2. <br>3.skipping sample interim Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a57f0c3",
   "metadata": {},
   "source": [
    "<h6> The below URL was chosen following a google search for the the request 'top' + '100' +'indian'+ 'movies'+ 'imdb'.<br> \n",
    "<font color='blue'> <u> 'https://www.imdb.com/list/ls079077479/'</font> </u><br>\n",
    "    Using the above URL for this demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316350f5",
   "metadata": {},
   "source": [
    "<h3><font color='green'> First: Step1.</font> Libraries required. \n",
    "    skipping import since we have already imported in this file for the previous example  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052d128e",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step2.</font> Determine the <font color='red'>URL </font>to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "e4f16815",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_url = 'https://www.imdb.com/list/ls079077479/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ed79df",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step3.</font> making 'Request' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "bf9d1110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#request for Source code of URL-'imdb'with error handling function\n",
    "def request_access2():\n",
    "    link2= 'https://www.imdb.com/list/ls079077479/'\n",
    "    check2=requests.get(link2)\n",
    "    #error handling\n",
    "    #if response is anything except 200 an exception is made\n",
    "    if check2.status_code != 200:\n",
    "        raise Exception(f'Server Busy, Try again later! {link2}')\n",
    "    # Parse using BeautifulSoup function\n",
    "    ind_content = BeautifulSoup(check2.text, 'html.parser')\n",
    "    return ind_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbc756b",
   "metadata": {},
   "source": [
    "<h3><font color='green'>Step2.2.</font> Save page content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "3a1d49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_content=request_access2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaf21f6",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step3.</font> Using Inspect in Google Chrome, analyse and identify the elements in question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcca09c",
   "metadata": {},
   "source": [
    "<h5>Inferences:<br>\n",
    "    1.Found that the divisional tag <font color='red'>'lister-item-header'</font> holds composite values of <font color='red'>'Rank', 'Name','Year or release'</font>.<br>\n",
    "    2.The header tags in question are <font color='red'>'h3', 'a' . with attributes 'class', 'href' etc</font>.<br>\n",
    "    3.Since we need to operate in this area, lets marquee the division as selection.<br>\n",
    "    4.From the selection, we can use the header tags to get the elements required. <br>\n",
    "    5.Creating an empty list to hold the movie names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "78ea01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceeding to harvest title from selection\n",
    "\n",
    "def harvest_indian_movies(ind_content):\n",
    "    \n",
    "    #marquee the selection\n",
    "    \n",
    "    selectind=\"lister-item-header\"\n",
    "    marquee_ind=ind_content.find_all('h3',{'class':selectind})\n",
    "    \n",
    "    #Inititalise Empty list to store names\n",
    "    \n",
    "    indmov_names=[]\n",
    "    \n",
    "    #from marquee harvest movie names using a simple text search in selection\n",
    "    \n",
    "    for indtag in marquee_ind:\n",
    "        indmov = indtag.find('a').text\n",
    "        indmov_names.append(indmov)\n",
    "    \n",
    "    #return the Indian movie names\n",
    "        \n",
    "    return indmov_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6a2b65",
   "metadata": {},
   "source": [
    "<h5> Above function holds all <font color='red'>100 indian movie names</font> in order of Rank.<br><br>\n",
    "     To check if above function works, We can simply display all 100 Indian Movie names by calling the above () which will just cause a<br> clutter in the notebook, hence assigning to another variable and calling only 3 names from the top."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717aa492",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step4.</font> Using Inspect in Google Chrome, analyse and identify the <font color='red'>year of release, IMDB rating and rank</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "b1062644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Year of release\n",
    "\n",
    "def harvest_indian_year(ind_content):\n",
    "    \n",
    "    selectind2 = \"lister-item-year text-muted unbold\"           \n",
    "    marquee_indy=ind_content.find_all('span',{'class':selectind2})\n",
    "          \n",
    "    year_indian_released=[]\n",
    "       \n",
    "    for iyear in marquee_indy:\n",
    "        year_indian_released.append(iyear.get_text().strip()[1:5])\n",
    "                \n",
    "    return year_indian_released\n",
    "\n",
    "#for IMDB Rating\n",
    "\n",
    "def rating_indian_imdb(ind_content):\n",
    "            \n",
    "    selectind3=\"inline-block ratings-imdb-rating\"            \n",
    "    marquee3_indr=doc.find_all('div',{'class':selectind3})       \n",
    "    imdb_indian_rating=[]\n",
    "\n",
    "    for irating in marquee3_indr:\n",
    "        imdb_indian_rating.append(irating.get_text().strip())\n",
    "  \n",
    "    return imdb_indian_rating\n",
    "\n",
    "# For Rank\n",
    "\n",
    "def harvest_ind_rank(imdb_content):\n",
    "    \n",
    "    movie_ind_rank=[]\n",
    "\n",
    "    selectind4=\"lister-item-index unbold text-primary\"\n",
    "\n",
    "    for irank in imdb_content.find_all('span',class_=selectind4):\n",
    "        movie_ind_rank.append(irank.text.replace('.',''))    \n",
    "        \n",
    "    return movie_ind_rank\n",
    "\n",
    "#Re-storing lists to export into dictionary\n",
    "ind_mov_names= harvest_indian_movies(ind_content)\n",
    "ind_ranking = harvest_ind_rank(imdb_content)\n",
    "ind_rating = rating_indian_imdb(ind_content)\n",
    "ind_release_year = harvest_indian_year(ind_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071b89b0",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step5.</font> Composing a Dictionary using the above found lists as a precursor to the DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "81336b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inititalising Dictionary\n",
    "ind_imdb_data = dict()\n",
    "#Adding lists to Dictionary\n",
    "ind_imdb_data = {'Name of Indian Movie':ind_mov_names, 'IMDB Rating':ind_rating, 'Year of Release':ind_release_year,'IMDB Rank':ind_ranking }\n",
    "#ind_imdb_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26854b58",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Finally: Step6.</font> Structuring a Dataframe based on the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "50e0206d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Indian Movie</th>\n",
       "      <th>IMDB Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "      <th>IMDB Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PK</td>\n",
       "      <td>9.3</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bãhubali: The Beginning</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vaaranam Aayiram</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bajrangi Bhaijaan</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chennai Express</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Drishyam</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kaakha..Kaakha: The Police</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Taare Zameen Par</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Magadheera</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lagaan: Once Upon a Time in India</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7 Aum Arivu</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chak De! India</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2007</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ghajini</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2005</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vishwaroopam</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2013</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Indian Rupee</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2011</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1 - Nenokkadine</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2014</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Thani Oruvan</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2015</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ek Villain</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2014</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Brothers</td>\n",
       "      <td>8.6</td>\n",
       "      <td>I) (</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Haider</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2014</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Thuppakki</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2012</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Kaththi</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2014</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Anniyan</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2005</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Arya</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2004</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Srimanthudu</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2015</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Premam</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2015</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Singam 2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2013</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Thattathin Marayathu</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2012</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Happy New Year</td>\n",
       "      <td>8.6</td>\n",
       "      <td>I) (</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Arya 2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2009</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Singam</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1983</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2014</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Eega</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Srimanthudu</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Bangalore Days</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2014</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ustad Hotel</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Koi... Mil Gaya</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2003</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Dasavatharam</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2008</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Student of the Year</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Neram</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2013</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Pokiri</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2006</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Race</td>\n",
       "      <td>8.5</td>\n",
       "      <td>I) (</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Dhoom</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2004</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Kanchana 2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>English Vinglish</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>I</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Ayan</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2009</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Attarintiki Daredi</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2013</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Yennai Arindhaal</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Enthiran</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2010</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Left Right Left</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2013</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>How Old Are You?</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2014</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Masss</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Kick</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2009</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Kaaviya Thalaivan</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2014</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Oru Vadakkan Selfie</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2015</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Jab Tak Hai Jaan</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2012</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Julayi</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2012</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>7th Day</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2014</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Mankatha</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2011</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Bodyguard</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2010</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Race Gurram</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2014</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Biriyani</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2013</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Krrish</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2006</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Gabbar Singh</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2012</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Urumi</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2011</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Krrish 3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2013</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Rakhta Charitra 2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2010</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Athidhi</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2007</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Mozhi</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2007</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Mumbai Police</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2013</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>ABCD: American-Born Confused Desi</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2013</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Bunny</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2005</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Pithamagan</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2003</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Kandukondain Kandukondain</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2000</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Rajamanikyam</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2005</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Mirchi</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2013</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Something Something... Unnakum Ennakum</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2006</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>S/O Satyamurthy</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2015</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Anjaan</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2014</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Nandanam</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2002</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Arrambam</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2013</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Twenty:20</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2008</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Dhoom:3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2013</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Velayudham</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2011</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Picket 43</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2015</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Om Shanti Om</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2007</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Sapthamashree Thaskaraha</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2014</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Bang Bang</td>\n",
       "      <td>8.3</td>\n",
       "      <td>I) (</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Ennum Eppozhum</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2015</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Maattrraan</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2012</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Thalaivaa</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2013</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Ek Tha Tiger</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2012</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Escape from Uganda</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2013</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Damarukam</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2012</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Kaaki Sattai</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2015</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Anwar</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2010</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Aagadu</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2014</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Maan Karate</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2014</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name of Indian Movie IMDB Rating Year of Release  \\\n",
       "0                                       PK         9.3            2014   \n",
       "1                  Bãhubali: The Beginning         9.2            2015   \n",
       "2                         Vaaranam Aayiram         9.0            2008   \n",
       "3                        Bajrangi Bhaijaan         9.0            2015   \n",
       "4                          Chennai Express         9.0            2013   \n",
       "5                                 Drishyam         9.0            2013   \n",
       "6               Kaakha..Kaakha: The Police         9.0            2003   \n",
       "7                         Taare Zameen Par         8.9            2007   \n",
       "8                                 3 Idiots         8.8            2009   \n",
       "9                               Magadheera         8.8            2009   \n",
       "10       Lagaan: Once Upon a Time in India         8.8            2001   \n",
       "11                             7 Aum Arivu         8.8            2011   \n",
       "12                          Chak De! India         8.8            2007   \n",
       "13                                 Ghajini         8.8            2005   \n",
       "14                            Vishwaroopam         8.7            2013   \n",
       "15                            Indian Rupee         8.7            2011   \n",
       "16                         1 - Nenokkadine         8.7            2014   \n",
       "17                            Thani Oruvan         8.7            2015   \n",
       "18                              Ek Villain         8.6            2014   \n",
       "19                                Brothers         8.6            I) (   \n",
       "20                                  Haider         8.6            2014   \n",
       "21                               Thuppakki         8.6            2012   \n",
       "22                                 Kaththi         8.6            2014   \n",
       "23                                 Anniyan         8.6            2005   \n",
       "24                                    Arya         8.6            2004   \n",
       "25                             Srimanthudu         8.6            2015   \n",
       "26                                  Premam         8.6            2015   \n",
       "27                                Singam 2         8.6            2013   \n",
       "28                    Thattathin Marayathu         8.6            2012   \n",
       "29                          Happy New Year         8.6            I) (   \n",
       "30                                  Arya 2         8.6            2009   \n",
       "31                                  Singam         8.5            2010   \n",
       "32                                    1983         8.5            2014   \n",
       "33                                    Eega         8.5            2012   \n",
       "34                             Srimanthudu         8.5            2015   \n",
       "35                          Bangalore Days         8.5            2014   \n",
       "36                             Ustad Hotel         8.5            2012   \n",
       "37                         Koi... Mil Gaya         8.5            2003   \n",
       "38                            Dasavatharam         8.5            2008   \n",
       "39                     Student of the Year         8.5            2012   \n",
       "40                                   Neram         8.5            2013   \n",
       "41                                  Pokiri         8.5            2006   \n",
       "42                                    Race         8.5            I) (   \n",
       "43                                   Dhoom         8.5            2004   \n",
       "44                              Kanchana 2         8.5            2015   \n",
       "45                        English Vinglish         8.5            2012   \n",
       "46                                       I         8.5            2015   \n",
       "47                                    Ayan         8.5            2009   \n",
       "48                      Attarintiki Daredi         8.5            2013   \n",
       "49                        Yennai Arindhaal         8.5            2015   \n",
       "50                                Enthiran         8.5            2010   \n",
       "51                         Left Right Left         8.5            2013   \n",
       "52                        How Old Are You?         8.5            2014   \n",
       "53                                   Masss         8.5            2015   \n",
       "54                                    Kick         8.4            2009   \n",
       "55                       Kaaviya Thalaivan         8.4            2014   \n",
       "56                     Oru Vadakkan Selfie         8.4            2015   \n",
       "57                        Jab Tak Hai Jaan         8.4            2012   \n",
       "58                                  Julayi         8.4            2012   \n",
       "59                                 7th Day         8.4            2014   \n",
       "60                                Mankatha         8.4            2011   \n",
       "61                               Bodyguard         8.4            2010   \n",
       "62                             Race Gurram         8.4            2014   \n",
       "63                                Biriyani         8.4            2013   \n",
       "64                                  Krrish         8.4            2006   \n",
       "65                            Gabbar Singh         8.4            2012   \n",
       "66                                   Urumi         8.4            2011   \n",
       "67                                Krrish 3         8.4            2013   \n",
       "68                       Rakhta Charitra 2         8.4            2010   \n",
       "69                                 Athidhi         8.4            2007   \n",
       "70                                   Mozhi         8.4            2007   \n",
       "71                           Mumbai Police         8.4            2013   \n",
       "72       ABCD: American-Born Confused Desi         8.4            2013   \n",
       "73                                   Bunny         8.4            2005   \n",
       "74                              Pithamagan         8.4            2003   \n",
       "75               Kandukondain Kandukondain         8.4            2000   \n",
       "76                            Rajamanikyam         8.4            2005   \n",
       "77                                  Mirchi         8.4            2013   \n",
       "78  Something Something... Unnakum Ennakum         8.4            2006   \n",
       "79                         S/O Satyamurthy         8.4            2015   \n",
       "80                                  Anjaan         8.4            2014   \n",
       "81                                Nandanam         8.4            2002   \n",
       "82                                Arrambam         8.4            2013   \n",
       "83                               Twenty:20         8.3            2008   \n",
       "84                                 Dhoom:3         8.3            2013   \n",
       "85                              Velayudham         8.3            2011   \n",
       "86                               Picket 43         8.3            2015   \n",
       "87                            Om Shanti Om         8.3            2007   \n",
       "88                Sapthamashree Thaskaraha         8.3            2014   \n",
       "89                               Bang Bang         8.3            I) (   \n",
       "90                          Ennum Eppozhum         8.3            2015   \n",
       "91                              Maattrraan         8.3            2012   \n",
       "92                               Thalaivaa         8.3            2013   \n",
       "93                            Ek Tha Tiger         8.3            2012   \n",
       "94                      Escape from Uganda         8.3            2013   \n",
       "95                               Damarukam         8.3            2012   \n",
       "96                            Kaaki Sattai         8.3            2015   \n",
       "97                                   Anwar         8.3            2010   \n",
       "98                                  Aagadu         8.3            2014   \n",
       "99                             Maan Karate         8.3            2014   \n",
       "\n",
       "   IMDB Rank  \n",
       "0          1  \n",
       "1          2  \n",
       "2          3  \n",
       "3          4  \n",
       "4          5  \n",
       "5          6  \n",
       "6          7  \n",
       "7          8  \n",
       "8          9  \n",
       "9         10  \n",
       "10        11  \n",
       "11        12  \n",
       "12        13  \n",
       "13        14  \n",
       "14        15  \n",
       "15        16  \n",
       "16        17  \n",
       "17        18  \n",
       "18        19  \n",
       "19        20  \n",
       "20        21  \n",
       "21        22  \n",
       "22        23  \n",
       "23        24  \n",
       "24        25  \n",
       "25        26  \n",
       "26        27  \n",
       "27        28  \n",
       "28        29  \n",
       "29        30  \n",
       "30        31  \n",
       "31        32  \n",
       "32        33  \n",
       "33        34  \n",
       "34        35  \n",
       "35        36  \n",
       "36        37  \n",
       "37        38  \n",
       "38        39  \n",
       "39        40  \n",
       "40        41  \n",
       "41        42  \n",
       "42        43  \n",
       "43        44  \n",
       "44        45  \n",
       "45        46  \n",
       "46        47  \n",
       "47        48  \n",
       "48        49  \n",
       "49        50  \n",
       "50        51  \n",
       "51        52  \n",
       "52        53  \n",
       "53        54  \n",
       "54        55  \n",
       "55        56  \n",
       "56        57  \n",
       "57        58  \n",
       "58        59  \n",
       "59        60  \n",
       "60        61  \n",
       "61        62  \n",
       "62        63  \n",
       "63        64  \n",
       "64        65  \n",
       "65        66  \n",
       "66        67  \n",
       "67        68  \n",
       "68        69  \n",
       "69        70  \n",
       "70        71  \n",
       "71        72  \n",
       "72        73  \n",
       "73        74  \n",
       "74        75  \n",
       "75        76  \n",
       "76        77  \n",
       "77        78  \n",
       "78        79  \n",
       "79        80  \n",
       "80        81  \n",
       "81        82  \n",
       "82        83  \n",
       "83        84  \n",
       "84        85  \n",
       "85        86  \n",
       "86        87  \n",
       "87        88  \n",
       "88        89  \n",
       "89        90  \n",
       "90        91  \n",
       "91        92  \n",
       "92        93  \n",
       "93        94  \n",
       "94        95  \n",
       "95        96  \n",
       "96        97  \n",
       "97        98  \n",
       "98        99  \n",
       "99       100  "
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "imdb_ind_df = pd.DataFrame(ind_imdb_data)\n",
    "#display(imdb_ind_df)-------Can be used to display head and tail of DF\n",
    "\n",
    "#permanently disabling display restrictions.\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "imdb_ind_df\n",
    "\n",
    "\n",
    "#pd.reset_option('all') # -----------To Undo Global override, as it may Override future display restrictions in a DF  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f18bed",
   "metadata": {},
   "source": [
    "<h5><font color='red'>Final result:</font> Displayed the Name , Rating and year of release. Additionally, displayed the IMDB Rank.\n",
    "   <br> Note:  Display restriction of DF is overridden to display full DF.\n",
    "<h3><center> <font color='red'>SUCCESS!!</font>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c0f22c",
   "metadata": {},
   "source": [
    "<h2><font color='red'>********************************************************************************************************* </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf129bee",
   "metadata": {},
   "source": [
    "<h2> <font color ='blue'> 4) Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) \n",
    "from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52dbad1",
   "metadata": {},
   "source": [
    "<h5>Solution:\n",
    "    <br>1. Using URL <font color=blue><u>https://presidentofindia.nic.in/former-presidents.htm</font></u> to scrap Data.\n",
    "    <br>2. Using Bs4.\n",
    "    <br>3. Required Libraries already imported; Skipping to URL's Source code access request and analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac91199c",
   "metadata": {},
   "source": [
    "<h3><font color='green'> First: Step1.</font> Create a function to request for Source code from the given URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "a484059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#request for Source code of URL-'presidents of India' with error handling function\n",
    "def request_presidential_access():\n",
    "    dir= 'https://presidentofindia.nic.in/former-presidents.htm'\n",
    "    confirm=requests.get(dir)\n",
    "    #error handling\n",
    "    #if response is anything except 200 an exception is made\n",
    "    if confirm.status_code != 200:\n",
    "        raise Exception(f'Server Busy, Try again later! {dir}')\n",
    "    # Parse using BeautifulSoup function\n",
    "    eagles = BeautifulSoup(confirm.content, 'html.parser')\n",
    "    return eagles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "1d80af33",
   "metadata": {},
   "outputs": [],
   "source": [
    "eagle = request_presidential_access()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f784f",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step2.</font> Inspection of HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74334d66",
   "metadata": {},
   "source": [
    "<h5>On inspection, it is found that the the president name and DOB are in one user readable string in one divisional tag. \n",
    "<br>I am going to extract this string, and then perform string operations to seperate it into different strings.\n",
    "<br>Term in office is in another tag. We can extract as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a99593",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step3.</font> Creating a selection of div tags of interest, and then scraping names of previous Presidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "294de1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceeding to harvestname and DOB from selection\n",
    "\n",
    "def harvest_eagle_name(eagle):\n",
    "    \n",
    "    #marquee the selection\n",
    "    building=\"presidentListing\"\n",
    "   \n",
    "    marquee_tool=eagle.find_all('div',{'class':building})\n",
    "   \n",
    "    #Inititalise Empty list to store names and DOB\n",
    "    \n",
    "    eagles_namedob2=[]\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in marquee_tool:\n",
    "        pres_name = i.find('h3').text.split('(').pop(0)\n",
    "        eagles_namedob2.append(pres_name)\n",
    "   \n",
    "    \n",
    "        \n",
    "    return eagles_namedob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "2fc5906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "elvis=harvest_eagle_name(eagle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638fe8ff",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step4.</font> Creating a selection of div tags that hold the date of Birth/death."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "001821c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceeding to harvestname and DOB from selection\n",
    "\n",
    "def harvest_eagle_dob(eagle):\n",
    "    \n",
    "    #marquee the selection\n",
    "    building=\"presidentListing\"\n",
    "   \n",
    "    marquee_tool=eagle.find_all('div',{'class':building})\n",
    "   \n",
    "    #Inititalise Empty list to store names and DOB\n",
    "    \n",
    "    eagles_dob2=[]\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in marquee_tool:\n",
    "        pres_name = i.find('h3').text.split('(').pop(1)\n",
    "        eagles_dob2.append(pres_name)\n",
    "   \n",
    "    \n",
    "        \n",
    "    return eagles_dob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "7113ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dob=harvest_eagle_dob(eagle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef0382",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step5.</font> Creating Marquee to extract string that contains Term of office, among other info.<br>Then using a series of String operations to extract only Term of office."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "cb5b7c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def office_term(eagle):\n",
    "    \n",
    "  \n",
    "    #initialised empty list to store term\n",
    "    term=[]\n",
    "    term2=[]\n",
    "    marker = \"presidentListing\" #---- as found in the           \n",
    "    select=eagle.find_all('div',{'class':marker})\n",
    " # Extracts the following. \n",
    " #<div class=\"presidentListing\">\n",
    " #<h3>Shri Ram Nath Kovind (birth - 1945)</h3>\n",
    " #<p><span class=\"terms\">Term of Office:</span> 25 July, 2017 to 25 July, 2022 </p>\n",
    " #<p><a href=\"https://ramnathkovind.nic.in\" target=\"_blank\">https://ramnathkovind.nic.in</a></p>\n",
    " #</div>    \n",
    "    #Next scraping the text and using string operators   \n",
    "    for yr in select:\n",
    "        term.append(yr.get_text().split(':').pop(1))\n",
    "    # running additional round of string operations to clean up data.    \n",
    "    for h in term:\n",
    "        term2.append(h.split('\\n').pop(0))\n",
    "    return term2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "d7bc0c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 25 July, 2017 to 25 July, 2022 ',\n",
       " ' 25 July, 2012 to 25 July, 2017 ',\n",
       " ' 25 July, 2007 to 25 July, 2012 ',\n",
       " ' 25 July, 2002 to 25 July, 2007 ',\n",
       " ' 25 July, 1997 to 25 July, 2002 ',\n",
       " ' 25 July, 1992 to 25 July, 1997 ',\n",
       " ' 25 July, 1987 to 25 July, 1992 ',\n",
       " ' 25 July, 1982 to 25 July, 1987 ',\n",
       " ' 25 July, 1977 to 25 July, 1982 ',\n",
       " ' 24 August, 1974 to 11 February, 1977',\n",
       " ' 3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974',\n",
       " ' 13 May, 1967 to 3 May, 1969',\n",
       " ' 13 May, 1962 to 13 May, 1967',\n",
       " ' 26 January, 1950 to 13 May, 1962']"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_in_office=office_term(eagle)\n",
    "term_in_office"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f08b17",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step6.</font> Initialising and appending the lists in a dictionary as a precursor to compose a DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "3da3daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inititalising Dictionary\n",
    "presidents_data = dict()\n",
    "#Adding lists to Dictionary\n",
    "presidents_data = {'Name of President':elvis, 'Birth/Death':dob, 'Term of office':term_in_office }\n",
    "#presidents_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fad030",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Finally: Step7.</font> Creating a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "id": "339a2fe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of President</th>\n",
       "      <th>Birth/Death</th>\n",
       "      <th>Term of office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>birth - 1945)</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>1935-2020)</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>birth - 1934)</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>1931-2015)</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>1920 - 2005)</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>1918-1999)</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>1910-2009)</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>1916-1994)</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>1913-1996)</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>1905-1977)</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>1894-1980)</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>1897-1969)</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>1888-1975)</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>1884-1963)</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name of President    Birth/Death  \\\n",
       "0           Shri Ram Nath Kovind   birth - 1945)   \n",
       "1          Shri Pranab Mukherjee      1935-2020)   \n",
       "2   Smt Pratibha Devisingh Patil   birth - 1934)   \n",
       "3         DR. A.P.J. Abdul Kalam      1931-2015)   \n",
       "4           Shri K. R. Narayanan    1920 - 2005)   \n",
       "5        Dr Shankar Dayal Sharma      1918-1999)   \n",
       "6            Shri R Venkataraman      1910-2009)   \n",
       "7               Giani Zail Singh      1916-1994)   \n",
       "8      Shri Neelam Sanjiva Reddy      1913-1996)   \n",
       "9       Dr. Fakhruddin Ali Ahmed      1905-1977)   \n",
       "10  Shri Varahagiri Venkata Giri      1894-1980)   \n",
       "11              Dr. Zakir Husain      1897-1969)   \n",
       "12  Dr. Sarvepalli Radhakrishnan      1888-1975)   \n",
       "13           Dr. Rajendra Prasad     1884-1963)    \n",
       "\n",
       "                                                          Term of office  \n",
       "0                                        25 July, 2017 to 25 July, 2022   \n",
       "1                                        25 July, 2012 to 25 July, 2017   \n",
       "2                                        25 July, 2007 to 25 July, 2012   \n",
       "3                                        25 July, 2002 to 25 July, 2007   \n",
       "4                                        25 July, 1997 to 25 July, 2002   \n",
       "5                                        25 July, 1992 to 25 July, 1997   \n",
       "6                                        25 July, 1987 to 25 July, 1992   \n",
       "7                                        25 July, 1982 to 25 July, 1987   \n",
       "8                                        25 July, 1977 to 25 July, 1982   \n",
       "9                                   24 August, 1974 to 11 February, 1977  \n",
       "10   3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974  \n",
       "11                                           13 May, 1967 to 3 May, 1969  \n",
       "12                                          13 May, 1962 to 13 May, 1967  \n",
       "13                                      26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 1040,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presidents_df = pd.DataFrame(presidents_data)\n",
    "\n",
    "presidents_df\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e04816",
   "metadata": {},
   "source": [
    "<h2><center><font color='red'>SUCCESS!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e2953",
   "metadata": {},
   "source": [
    "<h2><font color='red'>********************************************************************************************************* </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043b38d3",
   "metadata": {},
   "source": [
    "<h2> <font color ='blue'>5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "    <br><t>a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "    <br><t>b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "    <br><t>c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af59d1e5",
   "metadata": {},
   "source": [
    "<h5>Solution:\n",
    "<h6> <font color='blue'> <u> https://www.icc-cricket.com/rankings/mens/team-rankings/odi'</font> </u><br>\n",
    "    1. Using the above URL for this demonstration.<br>\n",
    "    2. Using Bs4.\n",
    "    <br><br>\n",
    "<h3><font color='green'> First: Step1.</font> Libraries required. \n",
    "    Skipping import since we have already imported in this file for the previous example.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1440631",
   "metadata": {},
   "source": [
    "<h5>On inspection, it is found that for 5(a) all the information to be scraped is uder <tr> tag with <font color='red'>\"rankings-block__banner\"</font> label.<br>\n",
    "    Hence extracting the same.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "id": "e824292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cricket_ticket():\n",
    "    path1= 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "    access=requests.get(path1)\n",
    "    #error handling\n",
    "    #if response is anything except 200 an exception is made\n",
    "    if access.status_code != 200:\n",
    "        raise Exception(f'Server Busy, Try again later! {path1}')\n",
    "    # Parse using BeautifulSoup function\n",
    "    icc = BeautifulSoup(access.content, 'html.parser')\n",
    "    return icc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "id": "e018feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_info=cricket_ticket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "id": "49fec5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_name1(icc_info):\n",
    "    label1 = \"u-hide-phablet\"         \n",
    "    country=icc_info.find_all('span',{'class':label1})\n",
    "          \n",
    "    country_name_off=[]\n",
    "       \n",
    "    for stat in country:\n",
    "        country_name_off.append(stat.get_text())\n",
    "                \n",
    "    return country_name_off\n",
    "\n",
    "def country_name2(icc_info):\n",
    "    label1 = \"u-show-phablet\"         \n",
    "    country=icc_info.find_all('span',{'class':label1})\n",
    "          \n",
    "    country_name_show=[]\n",
    "       \n",
    "    for stat in country:\n",
    "        country_name_show.append(stat.get_text())\n",
    "                \n",
    "    return country_name_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "id": "d06797b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New Zealand', 'England', 'India']"
      ]
     },
     "execution_count": 1079,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "official_name=country_name1(icc_info)\n",
    "official_name[:3] #-----------------Displaying ONLY top3 names to reduce clutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "id": "76116bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NZ', 'ENG', 'IND']"
      ]
     },
     "execution_count": 1080,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_name=country_name2(icc_info)\n",
    "show_name[:3]#-----------------Displaying ONLY top3 names to reduce clutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "id": "7bb979aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note New Zealand contains a different label as it is displayed in Block.\n",
    "#hence using a list of labels, to identify the required tags. \n",
    "def country_match_np(icc_info):\n",
    "    label1 = (\"table-body__cell u-center-text\", 'rankings-block__banner--matches', \"rankings-block__banner--points\")        \n",
    "    country2=icc_info.find_all('td',{'class':label1})\n",
    "          \n",
    "    country_matchap=[]\n",
    "\n",
    "       \n",
    "    for stat in country2:\n",
    "        country_matchap.append(stat.get_text())\n",
    "      \n",
    "    return country_matchap\n",
    "\n",
    "# this returns a list of \"matches played by team\" and \"team score\" in one list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "id": "470a36b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['19', '2,355', '27', '3,226', '31', '3,447']"
      ]
     },
     "execution_count": 1076,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_no=country_match_np(icc_info)\n",
    "match_no[:6] #----------------Displaying only 3 sets of matches played and score of each team to reduce clutter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "id": "491ef637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches played by listed teams: ['19', '27', '31', '22', '23', '21', '30', '29', '41', '18', '23', '27', '23', '21', '22', '23', '30', '15', '22', '22']\n",
      "\n",
      "Listed team Scores: ['2,355', '3,226', '3,447', '2,354', '2,325', '2,111', '2,753', '2,658', '2,902', '1,238', '1,214', '1,254', '910', '673', '697', '725', '919', '369', '331', '134']\n"
     ]
    }
   ],
   "source": [
    "# since the above list is populated by each teams matches played and points sequentially. \n",
    "# We can use string operators to seperate odd and even elements\n",
    "matches_played = [v for i, v in enumerate(match_no) if i % 2 == 0]\n",
    "team_score = [z for j, z in enumerate(match_no) if j % 2 != 0]\n",
    "\n",
    "print(\"Matches played by listed teams:\",matches_played)\n",
    "print()\n",
    "print('Listed team Scores:',team_score,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "id": "0c5b4983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_rting(icc_info):\n",
    "    label1 = (\"table-body__cell u-text-right rating\",\"rankings-block__banner--rating u-text-right\")\n",
    "                      \n",
    "                     \n",
    "    rating=icc_info.find_all('td',{'class':label1})\n",
    "          \n",
    "    country_rating=[]\n",
    "       \n",
    "    for rating in rating:\n",
    "        country_rating.append(rating.get_text())\n",
    "                \n",
    "    return country_rating                          \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "id": "31ec35af",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtg=country_rting(icc_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "id": "7cd54c68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Country | Official Name': ['New Zealand',\n",
       "  'England',\n",
       "  'India',\n",
       "  'Pakistan',\n",
       "  'Australia',\n",
       "  'South Africa',\n",
       "  'Bangladesh',\n",
       "  'Sri Lanka',\n",
       "  'West Indies',\n",
       "  'Afghanistan',\n",
       "  'Ireland',\n",
       "  'Scotland',\n",
       "  'Zimbabwe',\n",
       "  'Netherlands',\n",
       "  'UAE',\n",
       "  'United States',\n",
       "  'Oman',\n",
       "  'Namibia',\n",
       "  'Nepal',\n",
       "  'Papua New Guinea'],\n",
       " 'Country | Short Name': ['NZ',\n",
       "  'ENG',\n",
       "  'IND',\n",
       "  'PAK',\n",
       "  'AUS',\n",
       "  'SA',\n",
       "  'BAN',\n",
       "  'SL',\n",
       "  'WI',\n",
       "  'AFG',\n",
       "  'IRE',\n",
       "  'SCO',\n",
       "  'ZIM',\n",
       "  'NED',\n",
       "  'UAE',\n",
       "  'USA',\n",
       "  'OMA',\n",
       "  'NAM',\n",
       "  'NEP',\n",
       "  'PNG'],\n",
       " 'Matches Played': ['19',\n",
       "  '27',\n",
       "  '31',\n",
       "  '22',\n",
       "  '23',\n",
       "  '21',\n",
       "  '30',\n",
       "  '29',\n",
       "  '41',\n",
       "  '18',\n",
       "  '23',\n",
       "  '27',\n",
       "  '23',\n",
       "  '21',\n",
       "  '22',\n",
       "  '23',\n",
       "  '30',\n",
       "  '15',\n",
       "  '22',\n",
       "  '22'],\n",
       " 'Points Scored': ['2,355',\n",
       "  '3,226',\n",
       "  '3,447',\n",
       "  '2,354',\n",
       "  '2,325',\n",
       "  '2,111',\n",
       "  '2,753',\n",
       "  '2,658',\n",
       "  '2,902',\n",
       "  '1,238',\n",
       "  '1,214',\n",
       "  '1,254',\n",
       "  '910',\n",
       "  '673',\n",
       "  '697',\n",
       "  '725',\n",
       "  '919',\n",
       "  '369',\n",
       "  '331',\n",
       "  '134'],\n",
       " 'Rating': ['\\n                            124\\n                            \\n\\n',\n",
       "  '119',\n",
       "  '111',\n",
       "  '107',\n",
       "  '101',\n",
       "  '101',\n",
       "  '92',\n",
       "  '92',\n",
       "  '71',\n",
       "  '69',\n",
       "  '53',\n",
       "  '46',\n",
       "  '40',\n",
       "  '32',\n",
       "  '32',\n",
       "  '32',\n",
       "  '31',\n",
       "  '25',\n",
       "  '15',\n",
       "  '6']}"
      ]
     },
     "execution_count": 1296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialising a dictionary to store the lists as a precursor to make a dataframe.\n",
    "icc_mens_stats= dict()\n",
    "#Adding lists to Dictionary\n",
    "icc_mens_stats = {'Country | Official Name':official_name, 'Country | Short Name':show_name,'Matches Played':matches_played,'Points Scored':team_score, 'Rating':rtg}\n",
    "icc_mens_stats #-------can Comment the command to display the dictionary to avoid clutter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "id": "dbf37a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution to 5(a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country | Official Name</th>\n",
       "      <th>Country | Short Name</th>\n",
       "      <th>Matches Played</th>\n",
       "      <th>Points Scored</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>NZ</td>\n",
       "      <td>19</td>\n",
       "      <td>2,355</td>\n",
       "      <td>\\n                            124\\n                            \\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>ENG</td>\n",
       "      <td>27</td>\n",
       "      <td>3,226</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>IND</td>\n",
       "      <td>31</td>\n",
       "      <td>3,447</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>PAK</td>\n",
       "      <td>22</td>\n",
       "      <td>2,354</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Australia</td>\n",
       "      <td>AUS</td>\n",
       "      <td>23</td>\n",
       "      <td>2,325</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>SA</td>\n",
       "      <td>21</td>\n",
       "      <td>2,111</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>BAN</td>\n",
       "      <td>30</td>\n",
       "      <td>2,753</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>SL</td>\n",
       "      <td>29</td>\n",
       "      <td>2,658</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>WI</td>\n",
       "      <td>41</td>\n",
       "      <td>2,902</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>18</td>\n",
       "      <td>1,238</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country | Official Name Country | Short Name Matches Played Points Scored  \\\n",
       "1              New Zealand                   NZ             19         2,355   \n",
       "2                  England                  ENG             27         3,226   \n",
       "3                    India                  IND             31         3,447   \n",
       "4                 Pakistan                  PAK             22         2,354   \n",
       "5                Australia                  AUS             23         2,325   \n",
       "6             South Africa                   SA             21         2,111   \n",
       "7               Bangladesh                  BAN             30         2,753   \n",
       "8                Sri Lanka                   SL             29         2,658   \n",
       "9              West Indies                   WI             41         2,902   \n",
       "10             Afghanistan                  AFG             18         1,238   \n",
       "\n",
       "                                                                 Rating  \n",
       "1   \\n                            124\\n                            \\n\\n  \n",
       "2                                                                   119  \n",
       "3                                                                   111  \n",
       "4                                                                   107  \n",
       "5                                                                   101  \n",
       "6                                                                   101  \n",
       "7                                                                    92  \n",
       "8                                                                    92  \n",
       "9                                                                    71  \n",
       "10                                                                   69  "
      ]
     },
     "execution_count": 1297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#As python is parsing all countries, we need to limit it as required to have only top10.\n",
    "\n",
    "icc_mens_df = pd.DataFrame(icc_mens_stats)\n",
    "icc_mens_df.index = np.arange(1,len(icc_mens_df)+1)\n",
    "print('Solution to 5(a)')\n",
    "icc_mens_df.head(10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d6e73d",
   "metadata": {},
   "source": [
    "<h3>Solving for 5(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb455c58",
   "metadata": {},
   "source": [
    "<h4> Q5b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb395b",
   "metadata": {},
   "source": [
    "<h6> using the URL<font color='blue'> <u> 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi'</font> </u><br>\n",
    "    <br>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7988c0",
   "metadata": {},
   "source": [
    "<h5>Solution:\n",
    "<h6> <font color='blue'> <u> https://www.icc-cricket.com/rankings/mens/team-rankings/odi'</font> </u><br>\n",
    "    1. Using the above URL for this demonstration.<br>\n",
    "    2. Using Bs4.\n",
    "    <br><br>\n",
    "<h3><font color='green'> First: Step1.</font> Libraries required. \n",
    "    Skipping import since we have already imported in this file for the previous example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae42ddf5",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step2.</font> Request for access for Source code from website. use HTML parser to parse data into python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "id": "0d3a5fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_players():\n",
    "    path1= 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi'\n",
    "    player=requests.get(path1)\n",
    "    #error handling\n",
    "    #if response is anything except 200 an exception is made\n",
    "    if player.status_code != 200:\n",
    "        raise Exception(f'Server Busy, Try again later! {path1}')\n",
    "    # Parse using BeautifulSoup function\n",
    "    plyr = BeautifulSoup(player.content, 'html.parser')\n",
    "    return plyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "id": "6d17a5bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl=t_players()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cd3973",
   "metadata": {},
   "source": [
    "<h2><font color='red'> Important Note:</h2><h5>On analysing the html source code, there is a parallel in the structure between ODI-Test-T20L. hence with a mere change in URL, we can use same functions to fetch data across the different game formats.</font><br>\n",
    "    <font color='green'> Also, in player statistics, all the Rank 1's across the Batsmen-bowlers-Allrounders both present and All-time.</font><br><br>\n",
    "    <font color='maroon'> The same applies with the Rank 2-10 across genres viz, Batsmen-bowlers-Allrounders both present and All-time.</font><br><br>\n",
    "    Hence, i am making common functions to parse data into python as series of lists and then rely on basic String operators to construct the Dictionary/Dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd3765b",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step3.</font> Creating Function1 to find Position of all top players across genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "id": "eff2fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing all the Rank1 players through all genres, as they all have a block container, hence different tags.\n",
    "#First Parsing Ranks# 1-10 for all 6 genres. Used labels of both rank1 and rank2-10\n",
    "\n",
    "#Function1-----------------------------------------------------------------------POSITION()\n",
    "def player_pos(pl):\n",
    "    label1 = (\"rankings-table__pos-number\",\"rankings-block__pos-number\")         \n",
    "    layer1=pl.find_all('span',{'class':label1})\n",
    "          \n",
    "    pl_rank=[]\n",
    "       \n",
    "    for p in layer1:\n",
    "        pl_rank.append(p.get_text().strip())\n",
    "                \n",
    "    return pl_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "id": "9cd08062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']"
      ]
     },
     "execution_count": 1354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_rk=player_pos(pl)[:10]\n",
    "pl_rk #---------------------------to be used in forming df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d4fea2",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step4.1.</font> Create Function-2 to find the Rank1 player names across all Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "id": "3a7742b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceeding to harvest name of rank1 players across all genre.\n",
    "#working on rank 1 players as 9-10 are is in a different container already solved\n",
    "\n",
    "#Function2-----------------------------------------------------------------------Name of Rank1() in every Genre\n",
    "def playername1(pl):\n",
    "    \n",
    "    #marquee the selection\n",
    "   \n",
    "    selection=\"rankings-block__banner--name\"\n",
    "    marquee=pl.find_all('div',{'class':selection})\n",
    "    \n",
    "    #Inititalise Empty list to store names\n",
    "    \n",
    "    pl_name1 =[]\n",
    "    \n",
    "   \n",
    "    #select all the names from marquee\n",
    "    for tag1 in marquee:\n",
    "        \n",
    "        pl_name1.append(tag1.text)\n",
    "    \n",
    "    #return names\n",
    "        \n",
    "    return pl_name1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "id": "202f0697",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Babar Azam',\n",
       " 'Trent Boult',\n",
       " 'Shakib Al Hasan',\n",
       " 'Babar Azam',\n",
       " 'Trent Boult',\n",
       " 'Shakib Al Hasan']"
      ]
     },
     "execution_count": 1356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing the Rank1 across all Genres. this is because, on the webpage, the Rank1s have a block container around them.\n",
    "#using String operations we can extract the Rank1 player in each of the genre when required.\n",
    "player_names1=playername1(pl) #-------------------to be used multiple times later\n",
    "player_names1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2590a8b",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step4.2.</font> Create Function 3 to capture names of Rank2-10 player's names across all Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "id": "69e96524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceeding to harvest the remaining top 10 batsmen's names.\n",
    "#working on Batsmen 2-10 as rank 1 is in a different container\n",
    "#function3--------------------------------------------------------------------Name of Rank2-10 in every Genre\n",
    "def name2_10(pl):\n",
    "    \n",
    "    #marquee the selection\n",
    "    \n",
    "    selection=\"table-body__cell name\"\n",
    "    name210=pl.find_all('td',{'class':selection})\n",
    "    \n",
    "    #Inititalise Empty list to store names\n",
    "    \n",
    "    batname210 =[]\n",
    "    \n",
    "   \n",
    "    #select all the names from marquee\n",
    "    for bat in name210:\n",
    "        glove = bat.find('a').text.strip()\n",
    "        batname210.append(glove)\n",
    "    \n",
    "    #return names\n",
    "        \n",
    "    return batname210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "id": "cb714dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rassie van der Dussen',\n",
       " 'Quinton de Kock',\n",
       " 'Imam-ul-Haq',\n",
       " 'Virat Kohli',\n",
       " 'Rohit Sharma',\n",
       " 'David Warner',\n",
       " 'Jonny Bairstow',\n",
       " 'Ross Taylor',\n",
       " 'Aaron Finch']"
      ]
     },
     "execution_count": 1245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Batsmen name-2-10\n",
    "name_batsmen210=batname2_10(pl)[:9]\n",
    "name_batsmen210  #---------- Displaying only first 3 in list to avoid clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb588914",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step5.1.</font>Create function-4 to capture rank1 players' country player rating across all genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "id": "90b28566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceeding to harvest Country of origin of all rank1 players across all genre.\n",
    "#Note the div tag contains both Country of origin and Player rating. \n",
    "#First extracting Country\n",
    "#function4----------------------------------------------------------------Origin of Rank1 Player across all Genre\n",
    "def player_origin(pl):\n",
    "    \n",
    "    #marquee the selection\n",
    "    \n",
    "    selection = \"rankings-block__banner--nationality\"\n",
    "    gin = pl.find_all('div',{'class':selection})\n",
    "    \n",
    "    #Inititalise Empty list to store names\n",
    "    \n",
    "    pl_origin =[]\n",
    "    \n",
    "   \n",
    "    #select all the names from marquee\n",
    "    for ori in gin:\n",
    "        pl_origin.append(ori.text.strip()[0:3])\n",
    "    \n",
    "    #return names\n",
    "        \n",
    "    return pl_origin\n",
    "\n",
    "#function5----------------------------------------------------------------Rating of Rank1 Player across all Genre\n",
    "\n",
    "def player_rting(pl):\n",
    "    \n",
    "    #marquee the selection\n",
    "    \n",
    "    selection = \"rankings-block__banner--nationality\"\n",
    "    ting = pl.find_all('div',{'class':selection})\n",
    "    \n",
    "    #Inititalise Empty list to store names\n",
    "    \n",
    "    pl_rting =[]\n",
    "    \n",
    "   \n",
    "    #select all the names from marquee\n",
    "    for ra in ting:\n",
    "        pl_rting.append(ra.text.strip()[4:])\n",
    "    \n",
    "    #return names\n",
    "        \n",
    "    return pl_rting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1247,
   "id": "5c4edaaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PAK', 'NZ\\n', 'BAN', 'PAK', 'NZ\\n', 'BAN']\n",
      "['890', '20', '372', '890', '20', '372']\n"
     ]
    }
   ],
   "source": [
    "#Showing Rank1 Player's origin across all Genres, because on the webpage the Rank1s have a block container around them.\n",
    "#using String operations we can extract the Rank1 player in each of the genre when required.\n",
    "Origin1=player_origin(pl) #-------------------to be used multiple times later\n",
    "Rating1=player_rting(pl)\n",
    "print(Origin1)\n",
    "print(Rating1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7af7d1",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step5.2.</font>Create function-4 to capture rank2-10 players' country across all genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "id": "949d854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working on Batsmen 2-10 as rank 1 is in a different container\n",
    "#function6-------------------------------------------------------------Origin of Rank2-10 player across all Genre\n",
    "def batnation2_10(pl):\n",
    "    \n",
    "    #marquee the selection\n",
    "    \n",
    "    selection=\"table-body__logo-text\"\n",
    "    tion=pl.find_all('span',{'class':selection})\n",
    "    \n",
    "    #Inititalise Empty list to store names\n",
    "    \n",
    "    batnation210 =[]\n",
    "    \n",
    "   \n",
    "    #select all the names from marquee\n",
    "    for na in tion:\n",
    "        batnation210.append(na.text)\n",
    "    \n",
    "    #return names\n",
    "        \n",
    "    return batnation210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "id": "31d4feaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SA', 'SA', 'PAK']"
      ]
     },
     "execution_count": 1249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank 2-10 batsmans' origin country\n",
    "country_batsmen210=batnation2_10(pl)[0:9]\n",
    "country_batsmen210[:3]#---------- Displaying only first 3 in list to avoid clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6015eeae",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step6.</font>Create function-4 to capture rank1 players' rating across all genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "id": "7379ed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working on Batsmen rank 2-10 rating as rank 1 is in a dofferent container\n",
    "# Function6---------------------------------------------------------------------Rating of Rank2-10 Player\n",
    "def batnrtg(pl):\n",
    "    \n",
    "    #marquee the selection\n",
    "    \n",
    "    selection=\"table-body__cell u-text-right rating\"\n",
    "    ing=pl.find_all('td',{'class':selection})\n",
    "    \n",
    "    #Inititalise Empty list to store names\n",
    "    \n",
    "    batrtg210 =[]\n",
    "    \n",
    "   \n",
    "    #select all the names from marquee\n",
    "    for rat in ing:\n",
    "        \n",
    "        batrtg210.append(rat.text)\n",
    "    \n",
    "    #return names\n",
    "        \n",
    "    return batrtg210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "id": "03d6d3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['789', '784', '779']"
      ]
     },
     "execution_count": 1251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Batsmens rating\n",
    "player_rtg210=batnrtg(pl)[:9]\n",
    "player_rtg210[:3]#---------- Displaying only first 3 in list to avoid clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce16e5",
   "metadata": {},
   "source": [
    "<h3>NOTE: The Above Functions (1-6) will be used now to solve Q5(b). but it will also come in handy to solve Q5(c).\n",
    "    It will also be used to solve similar queries for Q6(b) and(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faab8b8",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step7.</font>adding Rank1 list to Rank2-10 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1252,
   "id": "34f08384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Babar Azam', 'Rassie van der Dussen', 'Quinton de Kock']"
      ]
     },
     "execution_count": 1252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding the first elememt(name) in Rank1 player name list to the rank2-10 list to get top10\n",
    "\n",
    "T10_batsmen_name= player_names1[:1]+name_batsmen210 #--------to be used in forming DF\n",
    "T10_batsmen_name[:3]#---------- Displaying only top 3 in list to avoid clutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "id": "bb9a9f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAK', 'SA', 'SA', 'PAK', 'IND', 'IND', 'AUS', 'ENG', 'NZ', 'AUS']"
      ]
     },
     "execution_count": 1253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding the first elememt(origin/country) in Rank1 player origin list to the rank2-10 list to get top10\n",
    "batman_origins= Origin1[:1]+country_batsmen210\n",
    "batman_origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1254,
   "id": "12f5c6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['890', '789', '784', '779', '744', '740', '737', '732', '722', '715']"
      ]
     },
     "execution_count": 1254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding the first elememt(element) in Rank1 player origin list to the rank2-10 list to get top10 ratings\n",
    "T10_ratings= Rating1[:1] + player_rtg210\n",
    "T10_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd9c8f",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Next: Step8.</font> initialising Dict() and loading it with the respective lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1255,
   "id": "cadc86f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Player Name': ['Babar Azam',\n",
       "  'Rassie van der Dussen',\n",
       "  'Quinton de Kock',\n",
       "  'Imam-ul-Haq',\n",
       "  'Virat Kohli',\n",
       "  'Rohit Sharma',\n",
       "  'David Warner',\n",
       "  'Jonny Bairstow',\n",
       "  'Ross Taylor',\n",
       "  'Aaron Finch'],\n",
       " 'Position': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'],\n",
       " 'Country': ['PAK',\n",
       "  'SA',\n",
       "  'SA',\n",
       "  'PAK',\n",
       "  'IND',\n",
       "  'IND',\n",
       "  'AUS',\n",
       "  'ENG',\n",
       "  'NZ',\n",
       "  'AUS'],\n",
       " 'Rating': ['890',\n",
       "  '789',\n",
       "  '784',\n",
       "  '779',\n",
       "  '744',\n",
       "  '740',\n",
       "  '737',\n",
       "  '732',\n",
       "  '722',\n",
       "  '715']}"
      ]
     },
     "execution_count": 1255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initializing dictionary to make df\n",
    "T10batsmen=dict()\n",
    "T10batsmen={'Player Name':T10_batsmen_name,'Position':pl_rk, 'Country':batman_origins, 'Rating':T10_ratings}\n",
    "T10batsmen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecbc119",
   "metadata": {},
   "source": [
    "<h3><font color='green'> FINALLY: Step9.</font>Create DF based on the Dict() composed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1256,
   "id": "30c26fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_mens_bats_df = pd.DataFrame(T10batsmen)\n",
    "icc_mens_bats_df.index = np.arange(1,len(icc_mens_bats_df)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9443c1c0",
   "metadata": {},
   "source": [
    "<h3>Solution for Q5(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1257,
   "id": "284cf677",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Position</th>\n",
       "      <th>Country</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>1</td>\n",
       "      <td>PAK</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>2</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>3</td>\n",
       "      <td>SA</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>4</td>\n",
       "      <td>PAK</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>5</td>\n",
       "      <td>IND</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>6</td>\n",
       "      <td>IND</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>7</td>\n",
       "      <td>AUS</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>8</td>\n",
       "      <td>ENG</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>9</td>\n",
       "      <td>NZ</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>10</td>\n",
       "      <td>AUS</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player Name Position Country Rating\n",
       "1              Babar Azam        1     PAK    890\n",
       "2   Rassie van der Dussen        2      SA    789\n",
       "3         Quinton de Kock        3      SA    784\n",
       "4             Imam-ul-Haq        4     PAK    779\n",
       "5             Virat Kohli        5     IND    744\n",
       "6            Rohit Sharma        6     IND    740\n",
       "7            David Warner        7     AUS    737\n",
       "8          Jonny Bairstow        8     ENG    732\n",
       "9             Ross Taylor        9      NZ    722\n",
       "10            Aaron Finch       10     AUS    715"
      ]
     },
     "execution_count": 1257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icc_mens_bats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d18e65",
   "metadata": {},
   "source": [
    " <h3><t>c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef55f4f",
   "metadata": {},
   "source": [
    "<h5>Solution:\n",
    "<h6> <font color='blue'> <u> https://www.icc-cricket.com/rankings/mens/team-rankings/odi'</font> </u><br>\n",
    "    1. Using the above URL for this demonstration.<br>\n",
    "    2. Using Bs4.\n",
    "    <br><br>\n",
    "<h3><font color='green'> First: Step1.</font> Libraries required. \n",
    "    Skipping import since we have already imported in this file for the previous example. </h6>\n",
    "   <h4> Also, Using Functions 1-6 from 5(b) to solve 5(c) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a888512d",
   "metadata": {},
   "source": [
    "<h5>Using common data from 5b we get the Rank1 Bowler information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad3227e",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step2.</font> using list elements 11-20 of Rank/Positions.</h3><h5>(Although, not required as it will yield the same ranks viz 1-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "id": "afc0079d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']"
      ]
     },
     "execution_count": 1263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bo_rk=player_pos(pl)[10:20]\n",
    "bo_rk #---------------------------to be used in forming df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6ee766",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step3.1.</font> Using Function2  we find Rank1 Bowler's name viz element(2) in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "id": "335e1a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trent Boult']"
      ]
     },
     "execution_count": 1265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowler_name1=playername1(pl)[1:2] #-------------------to be used multiple times later\n",
    "bowler_name1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae1bb51",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step3.2.</font> Using Function3  we find Rank2-10 Bowler viz element(10-18) in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "id": "de1f72c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Josh Hazlewood',\n",
       " 'Mujeeb Ur Rahman',\n",
       " 'Jasprit Bumrah',\n",
       " 'Shaheen Afridi',\n",
       " 'Mohammad Nabi',\n",
       " 'Mehedi Hasan',\n",
       " 'Rashid Khan',\n",
       " 'Matt Henry',\n",
       " 'Mustafizur Rahman']"
      ]
     },
     "execution_count": 1268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bowlers name-2-10\n",
    "name_bowler210=batname2_10(pl)[9:18]\n",
    "name_bowler210  #---------- Displaying only first 3 in list to avoid clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312f83c",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step4.1.</font> Using Function4  we find Rank1 Bowler's Country viz element(2) in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "id": "a5d70705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NZ\\n']\n"
     ]
    }
   ],
   "source": [
    "#Rank 1 bowlers' origin country\n",
    "borigin1=player_origin(pl)[1:2] \n",
    "print(borigin1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb71c0f2",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step4.2.</font> Using Function5  we find Rank2-10 Bowlers' Location viz element(9-18) in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "id": "94608ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SA', 'SA', 'PAK', 'IND', 'IND', 'AUS', 'ENG', 'NZ', 'AUS']"
      ]
     },
     "execution_count": 1277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank 2-10 bowlers' origin country\n",
    "country_batsmen210=batnation2_10(pl)[0:9]\n",
    "country_batsmen210"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096bbe2a",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step5.1.</font> Using Function5  we find Rank1 Bowler's Rating viz element(2) in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "id": "a3adfdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20']\n"
     ]
    }
   ],
   "source": [
    "#Rank 1 bowlers' rating\n",
    "brating1=player_rting(pl)[1:2]\n",
    "print(brating1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1341eaa",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step5.2.</font> Using Function6  we find Rank2-10 Bowler viz element(9-18) in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "id": "34987949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['679', '676', '662', '661', '657', '655', '651', '644', '640']"
      ]
     },
     "execution_count": 1279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank 2-10 Bowlers rating\n",
    "bowler_rtg210=batnrtg(pl)[9:18]\n",
    "bowler_rtg210"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae03961c",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step6.</font> initializing Dict and compiling the strings to make a complete dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "id": "b6e2a3ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Player Name': ['Trent Boult',\n",
       "  'Josh Hazlewood',\n",
       "  'Mujeeb Ur Rahman',\n",
       "  'Jasprit Bumrah',\n",
       "  'Shaheen Afridi',\n",
       "  'Mohammad Nabi',\n",
       "  'Mehedi Hasan',\n",
       "  'Rashid Khan',\n",
       "  'Matt Henry',\n",
       "  'Mustafizur Rahman'],\n",
       " 'Position': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'],\n",
       " 'Country': ['NZ\\n',\n",
       "  'SA',\n",
       "  'SA',\n",
       "  'PAK',\n",
       "  'IND',\n",
       "  'IND',\n",
       "  'AUS',\n",
       "  'ENG',\n",
       "  'NZ',\n",
       "  'AUS'],\n",
       " 'Rating': ['20',\n",
       "  '679',\n",
       "  '676',\n",
       "  '662',\n",
       "  '661',\n",
       "  '657',\n",
       "  '655',\n",
       "  '651',\n",
       "  '644',\n",
       "  '640']}"
      ]
     },
     "execution_count": 1280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initializing dictionary to make df\n",
    "T10bowlers=dict()\n",
    "T10bowlers={'Player Name':(bowler_name1+name_bowler210),'Position':bo_rk, 'Country':(borigin1 +country_batsmen210), 'Rating':(brating1+bowler_rtg210)}\n",
    "T10bowlers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16ade47",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Finally: Step7.</font> Using the Dict made, we compose a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "id": "c7520c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising and Displaying dict as DF\n",
    "icc_mens_bowl_df = pd.DataFrame(T10bowlers)#------------To start the serial# from 1 rather than 0\n",
    "icc_mens_bowl_df.index = np.arange(1,len(icc_mens_bowl_df)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35d068b",
   "metadata": {},
   "source": [
    "<h3>Solution for Q5(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "id": "21518b93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Position</th>\n",
       "      <th>Country</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>1</td>\n",
       "      <td>NZ\\n</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>2</td>\n",
       "      <td>SA</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>3</td>\n",
       "      <td>SA</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>4</td>\n",
       "      <td>PAK</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>5</td>\n",
       "      <td>IND</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>6</td>\n",
       "      <td>IND</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>7</td>\n",
       "      <td>AUS</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>8</td>\n",
       "      <td>ENG</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>9</td>\n",
       "      <td>NZ</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>10</td>\n",
       "      <td>AUS</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Player Name Position Country Rating\n",
       "1         Trent Boult        1    NZ\\n     20\n",
       "2      Josh Hazlewood        2      SA    679\n",
       "3    Mujeeb Ur Rahman        3      SA    676\n",
       "4      Jasprit Bumrah        4     PAK    662\n",
       "5      Shaheen Afridi        5     IND    661\n",
       "6       Mohammad Nabi        6     IND    657\n",
       "7        Mehedi Hasan        7     AUS    655\n",
       "8         Rashid Khan        8     ENG    651\n",
       "9          Matt Henry        9      NZ    644\n",
       "10  Mustafizur Rahman       10     AUS    640"
      ]
     },
     "execution_count": 1282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icc_mens_bowl_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e414cf",
   "metadata": {},
   "source": [
    "<h2><center><font color='red'> SUCCESS!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00226f",
   "metadata": {},
   "source": [
    "<h2><font color='red'>********************************************************************************************************* </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e874a59",
   "metadata": {},
   "source": [
    "<h2> <font color ='blue'>6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "<br>a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "<br>b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "<br>c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b77c6a",
   "metadata": {},
   "source": [
    "<h3>Solution:\n",
    "    <br>a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56e29fe",
   "metadata": {},
   "source": [
    "<h4>Before we begin, as mentioned earlier, there is a since of similarity and paralellism in the source codes structure of the webpage.\n",
    "    <br><br>I am attempting to solve this Q6, by calling the same functions used in Q5. most of them should work the same, if we just change the passed data into the functions while calling them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16570c9f",
   "metadata": {},
   "source": [
    "<h3><font color='green'> FIRST: Step1.</font> Request access for the source code for the given webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "id": "f21c1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cricket_ticket2():\n",
    "    path2= 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "    access=requests.get(path2)\n",
    "    #error handling\n",
    "    #if response is anything except 200 an exception is made\n",
    "    if access.status_code != 200:\n",
    "        raise Exception(f'Server Busy, Try again later! {path2}')\n",
    "    # Parse using BeautifulSoup function\n",
    "    icc_w = BeautifulSoup(access.content, 'html.parser')\n",
    "    return icc_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "id": "b3afd7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "wpl=cricket_ticket2()\n",
    "#wpl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca4b480",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step2.</font> Passing Data into functions created in Q5(a) -  of Top10 Country Womens ICC-Official Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "id": "fdf2b153",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australia', 'England', 'South Africa', 'India']"
      ]
     },
     "execution_count": 1310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of Top10 Womens Cricket team names- Full\n",
    "\n",
    "top_wo_icc_name1=country_name1(wpl)#-----------------------------Using function created in Q5(a)\n",
    "top_wo_icc_name1[:4] #---------------------------displaying only 4 countries to avoid clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8ffe4a",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step3.</font> Passing Data into functions created in Q5(a) -  of Top10 Country Womens ICC-short Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "id": "1d81aa68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUS', 'ENG', 'SA', 'IND']"
      ]
     },
     "execution_count": 1311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of Top10 Womens Cricket team names- Short\n",
    "\n",
    "top_wo_icc_name2=country_name2(wpl)#-----------------------------------Using function created in Q5(a)\n",
    "top_wo_icc_name2[:4] #---------------------------displaying only 4 countries to avoid clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d55519",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step4.</font> Passing Data into functions created in Q5(a) -  Function to generate Total matched played & team Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "id": "cfbb8ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29', '4,837', '33', '4,046', '35', '4,157', '32', '3,219']"
      ]
     },
     "execution_count": 1309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of top10 womens teams' total matches played and team score in one list\n",
    "\n",
    "wo_mp_score=country_match_np(wpl) #-----------------Using function from Q5(a) to give a list of matches played & Team score\n",
    "wo_mp_score[:8] #----------displaying only 4 sets of data to avoid clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301d23c2",
   "metadata": {},
   "source": [
    "<h5>Seperating the elements of the above list to give rise to two lists- womens match played by team and womens team rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1315,
   "id": "7a03bed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches played by listed teams: ['29', '33', '35', '32', '31', '30', '12', '30', '9', '11', '8']\n",
      "\n",
      "Listed team Scores: ['4,837', '4,046', '4,157', '3,219', '3,019', '2,768', '930', '1,962', '405', '495', '0']\n"
     ]
    }
   ],
   "source": [
    "# since the above list is populated by each teams matches played and scores sequentially. \n",
    "# We can use string operators to seperate odd and even elements\n",
    "wo_matches_played = [p for a, p in enumerate(wo_mp_score) if a % 2 == 0]\n",
    "wo_team_score = [q for b, q in enumerate(wo_mp_score) if b % 2 != 0]\n",
    "\n",
    "print(\"Matches played by listed teams:\",wo_matches_played)\n",
    "print()\n",
    "print('Listed team Scores:',wo_team_score,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1318,
   "id": "740b592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_icc_rating=country_rting(wpl)\n",
    "#wo_icc_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd1a18",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step5.</font> Compiling Lists to make a Dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1321,
   "id": "47020d2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Country | Official Name': ['Australia',\n",
       "  'England',\n",
       "  'South Africa',\n",
       "  'India',\n",
       "  'New Zealand',\n",
       "  'West Indies',\n",
       "  'Bangladesh',\n",
       "  'Pakistan',\n",
       "  'Ireland',\n",
       "  'Sri Lanka',\n",
       "  'Zimbabwe'],\n",
       " 'Country | Short Name': ['AUS',\n",
       "  'ENG',\n",
       "  'SA',\n",
       "  'IND',\n",
       "  'NZ',\n",
       "  'WI',\n",
       "  'BAN',\n",
       "  'PAK',\n",
       "  'IRE',\n",
       "  'SL',\n",
       "  'ZIM'],\n",
       " 'Matches Played': ['29',\n",
       "  '33',\n",
       "  '35',\n",
       "  '32',\n",
       "  '31',\n",
       "  '30',\n",
       "  '12',\n",
       "  '30',\n",
       "  '9',\n",
       "  '11',\n",
       "  '8'],\n",
       " 'Points Scored': ['4,837',\n",
       "  '4,046',\n",
       "  '4,157',\n",
       "  '3,219',\n",
       "  '3,019',\n",
       "  '2,768',\n",
       "  '930',\n",
       "  '1,962',\n",
       "  '405',\n",
       "  '495',\n",
       "  '0'],\n",
       " 'Rating': ['\\n                            167\\n                            \\n\\n',\n",
       "  '123',\n",
       "  '119',\n",
       "  '101',\n",
       "  '97',\n",
       "  '92',\n",
       "  '78',\n",
       "  '65',\n",
       "  '45',\n",
       "  '45',\n",
       "  '0']}"
      ]
     },
     "execution_count": 1321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialising a dictionary to store the lists as a precursor to make a dataframe.\n",
    "icc_womens_stats= dict()\n",
    "#Adding lists to Dictionary\n",
    "icc_womens_stats = {'Country | Official Name':top_wo_icc_name1, 'Country | Short Name':top_wo_icc_name2,'Matches Played':wo_matches_played,'Points Scored':wo_team_score, 'Rating':wo_icc_rating}\n",
    "icc_womens_stats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9281fa01",
   "metadata": {},
   "source": [
    "<h3><font color='green'> FINALLY: Step6.</font> Displaying Dictionary as Dataframe.----Solution 6(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1323,
   "id": "595c11f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution to 6(a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country | Official Name</th>\n",
       "      <th>Country | Short Name</th>\n",
       "      <th>Matches Played</th>\n",
       "      <th>Points Scored</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>AUS</td>\n",
       "      <td>29</td>\n",
       "      <td>4,837</td>\n",
       "      <td>\\n                            167\\n                            \\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>ENG</td>\n",
       "      <td>33</td>\n",
       "      <td>4,046</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>SA</td>\n",
       "      <td>35</td>\n",
       "      <td>4,157</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India</td>\n",
       "      <td>IND</td>\n",
       "      <td>32</td>\n",
       "      <td>3,219</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>NZ</td>\n",
       "      <td>31</td>\n",
       "      <td>3,019</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>WI</td>\n",
       "      <td>30</td>\n",
       "      <td>2,768</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>BAN</td>\n",
       "      <td>12</td>\n",
       "      <td>930</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>PAK</td>\n",
       "      <td>30</td>\n",
       "      <td>1,962</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>IRE</td>\n",
       "      <td>9</td>\n",
       "      <td>405</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>SL</td>\n",
       "      <td>11</td>\n",
       "      <td>495</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country | Official Name Country | Short Name Matches Played Points Scored  \\\n",
       "1                Australia                  AUS             29         4,837   \n",
       "2                  England                  ENG             33         4,046   \n",
       "3             South Africa                   SA             35         4,157   \n",
       "4                    India                  IND             32         3,219   \n",
       "5              New Zealand                   NZ             31         3,019   \n",
       "6              West Indies                   WI             30         2,768   \n",
       "7               Bangladesh                  BAN             12           930   \n",
       "8                 Pakistan                  PAK             30         1,962   \n",
       "9                  Ireland                  IRE              9           405   \n",
       "10               Sri Lanka                   SL             11           495   \n",
       "\n",
       "                                                                 Rating  \n",
       "1   \\n                            167\\n                            \\n\\n  \n",
       "2                                                                   123  \n",
       "3                                                                   119  \n",
       "4                                                                   101  \n",
       "5                                                                    97  \n",
       "6                                                                    92  \n",
       "7                                                                    78  \n",
       "8                                                                    65  \n",
       "9                                                                    45  \n",
       "10                                                                   45  "
      ]
     },
     "execution_count": 1323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icc_womens_df = pd.DataFrame(icc_womens_stats)\n",
    "icc_womens_df.index = np.arange(1,len(icc_womens_df)+1)\n",
    "print('Solution to 6(a)')\n",
    "icc_womens_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e5b82",
   "metadata": {},
   "source": [
    "<h3>b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f69394",
   "metadata": {},
   "source": [
    "<h3>Solution: \n",
    "<br><h3><font color='green'> FIRST: Step1.</font> Request access to share source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "id": "517adbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wo_players():\n",
    "    path3= 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi'\n",
    "    wo_player=requests.get(path3)\n",
    "    #error handling\n",
    "    #if response is anything except 200 an exception is made\n",
    "    if wo_player.status_code != 200:\n",
    "        raise Exception(f'Server Busy, Try again later! {path3}')\n",
    "    # Parse using BeautifulSoup function\n",
    "    playr = BeautifulSoup(wo_player.content, 'html.parser')\n",
    "    return playr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "id": "13abe46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbt=wo_players()\n",
    "#wbt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df06c9d3",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step2.</font>- Passing values to functions in 5(b) to find player positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "id": "9068bde7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']"
      ]
     },
     "execution_count": 1337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wo_pos=player_pos(wbt)#------------------------------function to find Player positions\n",
    "wo_pos[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb19ba8",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step3.</font>- Passing values to functions in 5(b) to find top10 Batting players Names-Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "id": "cec3965a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alyssa Healy', 'Sophie Ecclestone', 'Natalie Sciver']"
      ]
     },
     "execution_count": 1357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As discussed earlier, the top three players, from different genres, are in one block.\n",
    "wo_rk1name = playername1(wbt)\n",
    "wo_rk1name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "id": "d7b1622f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beth Mooney',\n",
       " 'Natalie Sciver',\n",
       " 'Laura Wolvaardt',\n",
       " 'Meg Lanning',\n",
       " 'Rachael Haynes',\n",
       " 'Amy Satterthwaite',\n",
       " 'Tammy Beaumont',\n",
       " 'Chamari Athapaththu',\n",
       " 'Smriti Mandhana']"
      ]
     },
     "execution_count": 1344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passing values to find Rank 2-10 Batting players' Names-women\n",
    "wo_rk2_10 = name2_10(wbt)[:9]\n",
    "wo_rk2_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c9ec70",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step4.</font>- Passing values to functions in 5(b) to find top10 Batting players origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "id": "4fcab12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUS', 'ENG', 'ENG']"
      ]
     },
     "execution_count": 1346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank1 Batting Players-origin\n",
    "wo_rk1_origin=player_origin(wbt)\n",
    "wo_rk1_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "id": "1d22e9c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUS', 'ENG', 'SA', 'AUS', 'AUS', 'NZ', 'ENG', 'SL', 'IND']"
      ]
     },
     "execution_count": 1348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank2-10 Batting PLayers-origin\n",
    "wo_rk2_10_origin=batnation2_10(wbt)[:9]\n",
    "wo_rk2_10_origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05500cc3",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step5.</font>- Passing values to functions in 5(b) to find top10 Batting players rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1349,
   "id": "8e25f50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['785', '761', '379']"
      ]
     },
     "execution_count": 1349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank1 Batting player-Rating\n",
    "wo_rk1_rating = player_rting(wbt)\n",
    "wo_rk1_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "id": "0e9339bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['749', '747', '732', '710', '701', '681', '667', '655', '649']"
      ]
     },
     "execution_count": 1351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank2-10 Batting player-Rating\n",
    "wo_rk2_10_rating = batnrtg(wbt)\n",
    "wo_rk2_10_rating[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d3a606",
   "metadata": {},
   "source": [
    "<h3><font color='green'> FINALLY: Step6.</font>- Passing values to functions in 5(b) to find top10 Batting players Names-Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "id": "3a824fe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Player Name': ['Alyssa Healy',\n",
       "  'Beth Mooney',\n",
       "  'Natalie Sciver',\n",
       "  'Laura Wolvaardt',\n",
       "  'Meg Lanning',\n",
       "  'Rachael Haynes',\n",
       "  'Amy Satterthwaite',\n",
       "  'Tammy Beaumont',\n",
       "  'Chamari Athapaththu',\n",
       "  'Smriti Mandhana'],\n",
       " 'Position': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'],\n",
       " 'Country': ['AUS',\n",
       "  'AUS',\n",
       "  'ENG',\n",
       "  'SA',\n",
       "  'AUS',\n",
       "  'AUS',\n",
       "  'NZ',\n",
       "  'ENG',\n",
       "  'SL',\n",
       "  'IND'],\n",
       " 'Rating': ['785',\n",
       "  '749',\n",
       "  '747',\n",
       "  '732',\n",
       "  '710',\n",
       "  '701',\n",
       "  '681',\n",
       "  '667',\n",
       "  '655',\n",
       "  '649']}"
      ]
     },
     "execution_count": 1358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initializing dictionary to make df----------compiling the rank1 and rank2-10 in one list while passing values into dictionary\n",
    "T10bats_wo=dict()\n",
    "T10bats_wo={'Player Name':(wo_rk1name[:1]+wo_rk2_10),'Position':wo_pos[:10], 'Country':(wo_rk1_origin[:1]+wo_rk2_10_origin), 'Rating':(wo_rk1_rating[:1]+wo_rk2_10_rating[:9])}\n",
    "T10bats_wo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "id": "2eb04c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_wo_bats_df = pd.DataFrame(T10bats_wo)\n",
    "icc_wo_bats_df.index = np.arange(1,len(icc_mens_bats_df)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c95c26",
   "metadata": {},
   "source": [
    "<h5>Solution to 6(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "id": "0ce62e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Position</th>\n",
       "      <th>Country</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>1</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>2</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>3</td>\n",
       "      <td>ENG</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>4</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>5</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>6</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>7</td>\n",
       "      <td>NZ</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>8</td>\n",
       "      <td>ENG</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>9</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>10</td>\n",
       "      <td>IND</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Player Name Position Country Rating\n",
       "1          Alyssa Healy        1     AUS    785\n",
       "2           Beth Mooney        2     AUS    749\n",
       "3        Natalie Sciver        3     ENG    747\n",
       "4       Laura Wolvaardt        4      SA    732\n",
       "5           Meg Lanning        5     AUS    710\n",
       "6        Rachael Haynes        6     AUS    701\n",
       "7     Amy Satterthwaite        7      NZ    681\n",
       "8        Tammy Beaumont        8     ENG    667\n",
       "9   Chamari Athapaththu        9      SL    655\n",
       "10      Smriti Mandhana       10     IND    649"
      ]
     },
     "execution_count": 1360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icc_wo_bats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74820af4",
   "metadata": {},
   "source": [
    "<h3>c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011866d4",
   "metadata": {},
   "source": [
    "<h3><font color='green'> FIRST: Step1.</font>- Passing values to functions in 5(c) to find top10 Batting players Ranks-Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "id": "6aa9a02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']"
      ]
     },
     "execution_count": 1361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ranks1-10\n",
    "wo_pos_ar=player_pos(pl)[20:30]\n",
    "wo_pos_ar #---------------------------to be used in forming df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec57683",
   "metadata": {},
   "source": [
    "<h3><font color='green'> FIRST: Step1.</font>- Passing values to functions in 5(c) to find top10 Batting players Ranks-Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1362,
   "id": "4bba2b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natalie Sciver']"
      ]
     },
     "execution_count": 1362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank1 Allrounder- Woman\n",
    "wo_ar_name1=playername1(wbt)[2:3]\n",
    "wo_ar_name1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1364,
   "id": "77cef126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ellyse Perry', 'Marizanne Kapp', 'Hayley Matthews', 'Amelia Kerr']"
      ]
     },
     "execution_count": 1364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank2-10 Allrounder- Woman\n",
    "wo_ar_name210 = batname2_10(wbt)[18:27]\n",
    "wo_ar_name210[:4]#-----------------displaying only 4 to avoid clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed14559d",
   "metadata": {},
   "source": [
    "<h3><font color='green'> FIRST: Step2.</font>- Passing values to functions in 5(c) to find top10 Batting players Rank1-country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "id": "fec0175c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENG']"
      ]
     },
     "execution_count": 1365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank1 All-rounder-Womans -country\n",
    "wo_ar_origin1 = player_origin(wbt)[2:3] \n",
    "wo_ar_origin1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1367,
   "id": "749f140f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUS', 'SA', 'WI', 'NZ', 'AUS', 'IND', 'AUS', 'ENG', 'WI']"
      ]
     },
     "execution_count": 1367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank 2-10 All-Rounders' origin country\n",
    "wo_ar_origin210 = batnation2_10(wbt)[18:27]\n",
    "wo_ar_origin210"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e2eae",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step3.</font>- Passing values to functions in 5(c) to find top10 Batting players Ratings-Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "id": "2705daf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['379']"
      ]
     },
     "execution_count": 1368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank 1 All Rounders' rating\n",
    "wo_ar_rating1 = player_rting(wbt)[2:3]\n",
    "wo_ar_rating1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1369,
   "id": "b79c4ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['374', '349', '339', '336', '270', '252', '246', '220', '207']"
      ]
     },
     "execution_count": 1369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank 2-10 All-Rounders' rating\n",
    "wo_ar_rating210 = batnrtg(wbt)[18:27]\n",
    "wo_ar_rating210"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e7448c",
   "metadata": {},
   "source": [
    "<h3><font color='green'> FINALLY: Step4.</font>- Passing values to functions in 5(c) to feed into DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1370,
   "id": "231a0d8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Player Name': ['Natalie Sciver',\n",
       "  'Ellyse Perry',\n",
       "  'Marizanne Kapp',\n",
       "  'Hayley Matthews',\n",
       "  'Amelia Kerr',\n",
       "  'Ashleigh Gardner',\n",
       "  'Deepti Sharma',\n",
       "  'Jess Jonassen',\n",
       "  'Katherine Brunt',\n",
       "  'Stafanie Taylor'],\n",
       " 'Position': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'],\n",
       " 'Country': ['ENG', 'AUS', 'SA', 'WI', 'NZ', 'AUS', 'IND', 'AUS', 'ENG', 'WI'],\n",
       " 'Rating': ['379',\n",
       "  '374',\n",
       "  '349',\n",
       "  '339',\n",
       "  '336',\n",
       "  '270',\n",
       "  '252',\n",
       "  '246',\n",
       "  '220',\n",
       "  '207']}"
      ]
     },
     "execution_count": 1370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initializing dictionary to make df\n",
    "T10_wo_ar = dict()\n",
    "T10_wo_ar = {'Player Name':(wo_ar_name1+wo_ar_name210),'Position':wo_pos_ar, 'Country':(wo_ar_origin1 +wo_ar_origin210), 'Rating':(wo_ar_rating1+wo_ar_rating210)}\n",
    "T10_wo_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1375,
   "id": "4e04026a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Position</th>\n",
       "      <th>Country</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>1</td>\n",
       "      <td>ENG</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>2</td>\n",
       "      <td>AUS</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>3</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>4</td>\n",
       "      <td>WI</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>5</td>\n",
       "      <td>NZ</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>6</td>\n",
       "      <td>AUS</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>7</td>\n",
       "      <td>IND</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>8</td>\n",
       "      <td>AUS</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>9</td>\n",
       "      <td>ENG</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>10</td>\n",
       "      <td>WI</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Player Name Position Country Rating\n",
       "0    Natalie Sciver        1     ENG    379\n",
       "1      Ellyse Perry        2     AUS    374\n",
       "2    Marizanne Kapp        3      SA    349\n",
       "3   Hayley Matthews        4      WI    339\n",
       "4       Amelia Kerr        5      NZ    336\n",
       "5  Ashleigh Gardner        6     AUS    270\n",
       "6     Deepti Sharma        7     IND    252\n",
       "7     Jess Jonassen        8     AUS    246\n",
       "8   Katherine Brunt        9     ENG    220\n",
       "9   Stafanie Taylor       10      WI    207"
      ]
     },
     "execution_count": 1375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialising and Displaying dict as DF\n",
    "icc_womens_ar_df= pd.DataFrame(T10_wo_ar)\n",
    "icc_womens_ar_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab35ba",
   "metadata": {},
   "source": [
    "<h2><center><font color= 'red'>SUCCESS!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27b5fc8",
   "metadata": {},
   "source": [
    "<h2><font color='red'>********************************************************************************************************* </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1762b24",
   "metadata": {},
   "source": [
    "<h2><font color='blue'>7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world : <br>\n",
    "<br>i) Headline\n",
    "<br>ii) Time\n",
    "<br>iii) News Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cea220c",
   "metadata": {},
   "source": [
    "<h3>i) Headline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2cadfc",
   "metadata": {},
   "source": [
    "<h3><font color='green'> FIRST: Step1.</font> Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "b813234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "f52c4442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Error handling enabled function, that requests access to parse source code into python.\n",
    "def cnbc_access():\n",
    "    path5= 'https://www.cnbc.com/world/?region=world'\n",
    "    anchor=requests.get(path5)\n",
    "    #error handling\n",
    "    #if response is anything except 200 an exception is made\n",
    "    if anchor.status_code != 200:\n",
    "        raise Exception(f'Server Busy, Try again later! {path5}')\n",
    "    # Parse using BeautifulSoup function\n",
    "    news = BeautifulSoup(anchor.content, 'html.parser')\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "12d97d1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ns=cnbc_access()\n",
    "#ns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "3fb857d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struggling with long Covid? Here's what you should  — and should not — eat\n"
     ]
    }
   ],
   "source": [
    "#Finding one match----------this way missing propill news--need alternate sourcing\n",
    "match=ns.find('div',class_=\"LatestNews-headlineWrapper\")\n",
    "hline=match.a.text\n",
    "print(hline)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "ee89c9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Struggling with long Covid? Here's what you should  — and should not — eat\""
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alternative catch------ finding normal and propill news. \n",
    "match2=ns.find('a',class_='LatestNews-headline')\n",
    "hline2=match2.text\n",
    "hline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "a028e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to catch all headings in the page.\n",
    "def h_line(ns):\n",
    "    artle=\"LatestNews-headline\"\n",
    "    line=ns.find_all('a',{'class',artle})\n",
    "    headline=[]\n",
    "    \n",
    "    for head in line:\n",
    "        paper=head.text\n",
    "        headline.append(paper)\n",
    "    return headline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "f548bacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Struggling with long Covid? Here's what you should  — and should not — eat\",\n",
       " \"Chinese stocks' U.S. delisting risk halves after audit deal, Goldman says \",\n",
       " 'China tech giants saw their worst quarterly growth, thanks to zero-Covid policy',\n",
       " 'Warren Buffett loves this stock. But Morningstar thinks it should be trading lower ',\n",
       " \"Goldman says we're at an 'inflection point' and it's time for a new playbook \",\n",
       " \"Japan's Nikkei leads losses as Asia markets drop after Powell's Jackson Hole speech\",\n",
       " 'Cramer: I will not abandon tech stocks because the end of their downturn is near',\n",
       " 'Dow futures sink around 200 points as Wall Street looks set to continue rout',\n",
       " 'This company wants to pay you to watch 13 classic horror movies—how to apply',\n",
       " 'These are the 10 happiest travel destinations in North America',\n",
       " 'Where Amazon is heading in health after the Amazon Care failure',\n",
       " \"This CEO has 1 weekly activity that gives him the ‘very best ideas'\",\n",
       " \"32-year-old poker champ: Here's how to read people and become mentally tough\",\n",
       " 'How Amazon is giving Rivian an edge in the EV industry',\n",
       " \"Pet 'moms and dads' are spending more. Here's where to find growth\",\n",
       " 'Even with two checks in September, Supplemental Security Income falls short',\n",
       " 'UBS upgrades lithium sector as demand rises. These stocks are poised to benefit',\n",
       " \"Wall Street's favorite Dow stocks, and where analysts think they're going\",\n",
       " 'Cash is king for EV makers as soaring battery prices drive up production costs',\n",
       " \"Airbnb hosts buy long-abandoned TX house and find 'valuable collectibles'\",\n",
       " 'Read these 6 books if you want to learn more about your attachment style',\n",
       " \"This retired couple left the U.S. and bought a home in Portugal for $534,000—here's a look inside\",\n",
       " 'Hold on before jumping to the conclusion the market will test the June low',\n",
       " \"U.S. companies are reshoring at a rapid pace. Here's how to play the trend\",\n",
       " 'Wall Street analysts name the most well-positioned stocks for the long term',\n",
       " \"Energy companies' cash flows could top $1 trillion this year\",\n",
       " 'The 10 best U.S. cities for new grads to start a career',\n",
       " 'Climate change may bring back wind as the future power source for ocean ships',\n",
       " \"Here's how to figure out if you qualify for federal student loan forgiveness\",\n",
       " 'Mortgage denial rate for Black borrowers is twice that of overall population']"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines=h_line(ns)\n",
    "#len(headlines)\n",
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "96d96ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODAY'S HEADLINES\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>List of Headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Struggling with long Covid? Here's what you sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chinese stocks' U.S. delisting risk halves aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China tech giants saw their worst quarterly gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Warren Buffett loves this stock. But Morningst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Goldman says we're at an 'inflection point' an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Japan's Nikkei leads losses as Asia markets dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cramer: I will not abandon tech stocks because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dow futures sink around 200 points as Wall Str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This company wants to pay you to watch 13 clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>These are the 10 happiest travel destinations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Where Amazon is heading in health after the Am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>This CEO has 1 weekly activity that gives him ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32-year-old poker champ: Here's how to read pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How Amazon is giving Rivian an edge in the EV ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pet 'moms and dads' are spending more. Here's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Even with two checks in September, Supplementa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UBS upgrades lithium sector as demand rises. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wall Street's favorite Dow stocks, and where a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cash is king for EV makers as soaring battery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Airbnb hosts buy long-abandoned TX house and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Read these 6 books if you want to learn more a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>This retired couple left the U.S. and bought a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Hold on before jumping to the conclusion the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>U.S. companies are reshoring at a rapid pace. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Wall Street analysts name the most well-positi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Energy companies' cash flows could top $1 tril...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The 10 best U.S. cities for new grads to start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Climate change may bring back wind as the futu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Here's how to figure out if you qualify for fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Mortgage denial rate for Black borrowers is tw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    List of Headlines\n",
       "1   Struggling with long Covid? Here's what you sh...\n",
       "2   Chinese stocks' U.S. delisting risk halves aft...\n",
       "3   China tech giants saw their worst quarterly gr...\n",
       "4   Warren Buffett loves this stock. But Morningst...\n",
       "5   Goldman says we're at an 'inflection point' an...\n",
       "6   Japan's Nikkei leads losses as Asia markets dr...\n",
       "7   Cramer: I will not abandon tech stocks because...\n",
       "8   Dow futures sink around 200 points as Wall Str...\n",
       "9   This company wants to pay you to watch 13 clas...\n",
       "10  These are the 10 happiest travel destinations ...\n",
       "11  Where Amazon is heading in health after the Am...\n",
       "12  This CEO has 1 weekly activity that gives him ...\n",
       "13  32-year-old poker champ: Here's how to read pe...\n",
       "14  How Amazon is giving Rivian an edge in the EV ...\n",
       "15  Pet 'moms and dads' are spending more. Here's ...\n",
       "16  Even with two checks in September, Supplementa...\n",
       "17  UBS upgrades lithium sector as demand rises. T...\n",
       "18  Wall Street's favorite Dow stocks, and where a...\n",
       "19  Cash is king for EV makers as soaring battery ...\n",
       "20  Airbnb hosts buy long-abandoned TX house and f...\n",
       "21  Read these 6 books if you want to learn more a...\n",
       "22  This retired couple left the U.S. and bought a...\n",
       "23  Hold on before jumping to the conclusion the m...\n",
       "24  U.S. companies are reshoring at a rapid pace. ...\n",
       "25  Wall Street analysts name the most well-positi...\n",
       "26  Energy companies' cash flows could top $1 tril...\n",
       "27  The 10 best U.S. cities for new grads to start...\n",
       "28  Climate change may bring back wind as the futu...\n",
       "29  Here's how to figure out if you qualify for fe...\n",
       "30  Mortgage denial rate for Black borrowers is tw..."
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#composing the list into a dictionary. \n",
    "HeadLines=dict()\n",
    "HeadLines={'List of Headlines':headlines}\n",
    "\n",
    "#displaying as Dataframe.\n",
    "Headlines_df=pd.DataFrame(HeadLines)\n",
    "Headlines_df.index = np.arange(1,len(Headlines_df)+1)\n",
    "print(\"TODAY'S HEADLINES\")\n",
    "print()\n",
    "print()\n",
    "Headlines_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbc1222",
   "metadata": {},
   "source": [
    "<h2>Time-timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "9fdd793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to catch all headings in the page.\n",
    "def h_timestamp(ns):\n",
    "    artle=\"LatestNews-timestamp\"\n",
    "    line=ns.find_all('time',{'class',artle})\n",
    "    time_stamp=[]\n",
    "    \n",
    "    for time in line:\n",
    "        clock=time.text\n",
    "        time_stamp.append(clock)\n",
    "    return time_stamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "043228f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30 Min Ago', '47 Min Ago', '3 Hours Ago', '4 Hours Ago', '4 Hours Ago']"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = h_timestamp(ns)\n",
    "#len(timestamp)\n",
    "timestamp[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f3ee6",
   "metadata": {},
   "source": [
    "<h2>Newslink for the headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "71f11eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlhl(ns):\n",
    "    news_link_hl=[]\n",
    "    for link in ns.find_all('a', attrs={'href': re.compile(\"^https://\")}):\n",
    "        news_link_hl.append(link.get('href'))       \n",
    "    return news_link_hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "b0e25c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.cnbc.com/2022/08/29/struggling-with-long-covid-heres-what-you-should-and-should-not-eat.html',\n",
       " 'https://www.cnbc.com/2022/08/29/struggling-with-long-covid-heres-what-you-should-and-should-not-eat.html',\n",
       " 'https://www.cnbc.com/2022/08/29/goldman-us-delisting-risk-for-chinese-adr-stocks-halves-after-deal.html',\n",
       " 'https://www.cnbc.com/2022/08/29/chinese-tech-giants-post-worst-growth-on-record-due-to-zero-covid.html',\n",
       " 'https://www.cnbc.com/2022/08/29/morningstar-buffett-backed-stock-still-overvalued-despite-turnaround-.html',\n",
       " 'https://www.cnbc.com/2022/08/29/goldman-says-were-at-an-inflection-point-with-higher-volatility.html',\n",
       " 'https://www.cnbc.com/2022/08/29/asia-markets-jerome-powell-jackson-hole-china-industrial-profits-drop.html',\n",
       " 'https://www.cnbc.com/2022/08/28/cramer-i-will-not-abandon-tech-stocks-as-end-of-downturn-is-near.html',\n",
       " 'https://www.cnbc.com/2022/08/28/stock-market-news-futures-open-to-close-live-updates.html',\n",
       " 'https://www.cnbc.com/2022/08/28/dish-is-paying-1300-to-watch-13-stephen-king-movieswhat-to-know.html',\n",
       " 'https://www.cnbc.com/2022/08/28/club-med-top-10-happiest-travel-destinations-in-north-america.html',\n",
       " 'https://www.cnbc.com/2022/08/28/where-amazon-is-heading-in-health-after-the-amazon-care-failure.html',\n",
       " 'https://www.cnbc.com/2022/08/28/goodrx-ceo-doug-hirsch-weekly-activity-results-in-very-best-ideas.html',\n",
       " 'https://www.cnbc.com/2022/08/28/poker-champ-dan-cates-how-to-read-people-become-mentally-tough.html',\n",
       " 'https://www.cnbc.com/2022/08/28/how-amazon-is-giving-rivian-an-edge-in-the-ev-industry.html',\n",
       " 'https://www.cnbc.com/2022/08/28/pet-moms-and-dads-are-spending-more-on-their-pets-heres-where-to-find-growth.html',\n",
       " 'https://www.cnbc.com/2022/08/28/with-two-checks-in-september-supplemental-security-income-falls-short.html',\n",
       " 'https://www.cnbc.com/2022/08/28/ubs-upgrades-lithium-sector-as-demand-rises-favors-these-stocks.html',\n",
       " 'https://www.cnbc.com/2022/08/28/these-are-wall-streets-favorite-dow-stocks-and-where-analysts-think-theyre-going.html',\n",
       " 'https://www.cnbc.com/2022/08/28/ev-makers-face-cash-squeeze-amid-soaring-battery-production-costs.html',\n",
       " 'https://www.cnbc.com/2022/08/27/texas-couple-turning-abandoned-house-into-an-airbnb-find-collectibles.html',\n",
       " 'https://www.cnbc.com/2022/08/27/6-books-to-read-if-you-want-to-learn-more-about-your-attachment-style.html',\n",
       " 'https://www.cnbc.com/2022/08/27/retired-couple-left-the-us-and-bought-an-apartment-in-portugal-for-534000-look-inside-their-home.html',\n",
       " 'https://www.cnbc.com/2022/08/27/testing-junes-stock-market-low-isnt-a-foregone-conclusion.html',\n",
       " 'https://www.cnbc.com/2022/08/27/us-companies-are-reshoring-at-a-rapid-pace-heres-how-to-play-the-trend.html',\n",
       " 'https://www.cnbc.com/2022/08/27/analysts-say-buy-outsized-growth-stocks-such-as-nio-world-wrestling-entertainment.html',\n",
       " 'https://www.cnbc.com/2022/08/27/energy-companies-cash-flows-could-top-1-trillion-here-are-analysts-favorite-names-in-the-sector.html',\n",
       " 'https://www.cnbc.com/2022/08/27/best-us-cities-for-new-grads-to-start-a-career.html',\n",
       " 'https://www.cnbc.com/2022/08/27/how-ocean-shipping-goes-green-from-wind-power-to-liquid-hydrogen.html',\n",
       " 'https://www.cnbc.com/2022/08/27/do-you-make-too-much-for-student-loan-forgiveness-heres-what-to-know.html']"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl_headlines=nlhl(ns)[15:45]#--- on careful examination.- the above links in this range belong to the 30 headline articles.\n",
    "nl_headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b0c59e",
   "metadata": {},
   "source": [
    "<h2>NewsLink-</h2> <h4>Assuming it is the live \"watch Live\" link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "91815010",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//www.cnbc.com/live-tv/\n"
     ]
    }
   ],
   "source": [
    "#inspected the webpage and URl, found that there was only one instance of the watch Live button, hence found that instance.\n",
    "lve=ns.find('div',class_=\"FeaturedVideoHeader-container FeaturedVideoHeader-lightMode\")\n",
    "nlink=(lve.a)['href'] #-------Since we did not need the text data, accessed the link as a dictionary.\n",
    "print(nlink)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72500841",
   "metadata": {},
   "source": [
    "<h2> Compiling all sub questions into one Dataframe for Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "895c92f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation for Q7\n",
      "\n",
      "Link for live News:  //www.cnbc.com/live-tv/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>URL for Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Struggling with long Covid? Here's what you sh...</td>\n",
       "      <td>30 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/29/struggling-wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chinese stocks' U.S. delisting risk halves aft...</td>\n",
       "      <td>47 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/29/struggling-wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China tech giants saw their worst quarterly gr...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/29/goldman-us-del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Warren Buffett loves this stock. But Morningst...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/29/chinese-tech-g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Goldman says we're at an 'inflection point' an...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/29/morningstar-bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Japan's Nikkei leads losses as Asia markets dr...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/29/goldman-says-w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cramer: I will not abandon tech stocks because...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/29/asia-markets-j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dow futures sink around 200 points as Wall Str...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/28/cramer-i-will-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This company wants to pay you to watch 13 clas...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/28/stock-market-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>These are the 10 happiest travel destinations ...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/28/dish-is-paying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Where Amazon is heading in health after the Am...</td>\n",
       "      <td>15 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/28/club-med-top-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>This CEO has 1 weekly activity that gives him ...</td>\n",
       "      <td>15 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/28/where-amazon-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32-year-old poker champ: Here's how to read pe...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/28/goodrx-ceo-dou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How Amazon is giving Rivian an edge in the EV ...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/28/poker-champ-da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pet 'moms and dads' are spending more. Here's ...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/28/how-amazon-is-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Even with two checks in September, Supplementa...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/28/pet-moms-and-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UBS upgrades lithium sector as demand rises. T...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/28/with-two-check...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wall Street's favorite Dow stocks, and where a...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/28/ubs-upgrades-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cash is king for EV makers as soaring battery ...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/28/these-are-wall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Airbnb hosts buy long-abandoned TX house and f...</td>\n",
       "      <td>August 27, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/28/ev-makers-face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Read these 6 books if you want to learn more a...</td>\n",
       "      <td>August 27, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/27/texas-couple-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>This retired couple left the U.S. and bought a...</td>\n",
       "      <td>August 27, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/27/6-books-to-rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Hold on before jumping to the conclusion the m...</td>\n",
       "      <td>August 27, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/27/retired-couple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>U.S. companies are reshoring at a rapid pace. ...</td>\n",
       "      <td>August 27, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/27/testing-junes-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Wall Street analysts name the most well-positi...</td>\n",
       "      <td>August 27, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/27/us-companies-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Energy companies' cash flows could top $1 tril...</td>\n",
       "      <td>August 27, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/27/analysts-say-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The 10 best U.S. cities for new grads to start...</td>\n",
       "      <td>August 27, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/27/energy-compani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Climate change may bring back wind as the futu...</td>\n",
       "      <td>August 27, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/27/best-us-cities...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Here's how to figure out if you qualify for fe...</td>\n",
       "      <td>August 27, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/27/how-ocean-ship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Mortgage denial rate for Black borrowers is tw...</td>\n",
       "      <td>August 27, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/27/do-you-make-to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headlines        Timestamp  \\\n",
       "1   Struggling with long Covid? Here's what you sh...       30 Min Ago   \n",
       "2   Chinese stocks' U.S. delisting risk halves aft...       47 Min Ago   \n",
       "3   China tech giants saw their worst quarterly gr...      3 Hours Ago   \n",
       "4   Warren Buffett loves this stock. But Morningst...      4 Hours Ago   \n",
       "5   Goldman says we're at an 'inflection point' an...      4 Hours Ago   \n",
       "6   Japan's Nikkei leads losses as Asia markets dr...      5 Hours Ago   \n",
       "7   Cramer: I will not abandon tech stocks because...      6 Hours Ago   \n",
       "8   Dow futures sink around 200 points as Wall Str...      7 Hours Ago   \n",
       "9   This company wants to pay you to watch 13 clas...     11 Hours Ago   \n",
       "10  These are the 10 happiest travel destinations ...     13 Hours Ago   \n",
       "11  Where Amazon is heading in health after the Am...     15 Hours Ago   \n",
       "12  This CEO has 1 weekly activity that gives him ...     15 Hours Ago   \n",
       "13  32-year-old poker champ: Here's how to read pe...     16 Hours Ago   \n",
       "14  How Amazon is giving Rivian an edge in the EV ...     16 Hours Ago   \n",
       "15  Pet 'moms and dads' are spending more. Here's ...     16 Hours Ago   \n",
       "16  Even with two checks in September, Supplementa...     16 Hours Ago   \n",
       "17  UBS upgrades lithium sector as demand rises. T...     17 Hours Ago   \n",
       "18  Wall Street's favorite Dow stocks, and where a...     17 Hours Ago   \n",
       "19  Cash is king for EV makers as soaring battery ...     18 Hours Ago   \n",
       "20  Airbnb hosts buy long-abandoned TX house and f...  August 27, 2022   \n",
       "21  Read these 6 books if you want to learn more a...  August 27, 2022   \n",
       "22  This retired couple left the U.S. and bought a...  August 27, 2022   \n",
       "23  Hold on before jumping to the conclusion the m...  August 27, 2022   \n",
       "24  U.S. companies are reshoring at a rapid pace. ...  August 27, 2022   \n",
       "25  Wall Street analysts name the most well-positi...  August 27, 2022   \n",
       "26  Energy companies' cash flows could top $1 tril...  August 27, 2022   \n",
       "27  The 10 best U.S. cities for new grads to start...  August 27, 2022   \n",
       "28  Climate change may bring back wind as the futu...  August 27, 2022   \n",
       "29  Here's how to figure out if you qualify for fe...  August 27, 2022   \n",
       "30  Mortgage denial rate for Black borrowers is tw...  August 27, 2022   \n",
       "\n",
       "                                     URL for Headline  \n",
       "1   https://www.cnbc.com/2022/08/29/struggling-wit...  \n",
       "2   https://www.cnbc.com/2022/08/29/struggling-wit...  \n",
       "3   https://www.cnbc.com/2022/08/29/goldman-us-del...  \n",
       "4   https://www.cnbc.com/2022/08/29/chinese-tech-g...  \n",
       "5   https://www.cnbc.com/2022/08/29/morningstar-bu...  \n",
       "6   https://www.cnbc.com/2022/08/29/goldman-says-w...  \n",
       "7   https://www.cnbc.com/2022/08/29/asia-markets-j...  \n",
       "8   https://www.cnbc.com/2022/08/28/cramer-i-will-...  \n",
       "9   https://www.cnbc.com/2022/08/28/stock-market-n...  \n",
       "10  https://www.cnbc.com/2022/08/28/dish-is-paying...  \n",
       "11  https://www.cnbc.com/2022/08/28/club-med-top-1...  \n",
       "12  https://www.cnbc.com/2022/08/28/where-amazon-i...  \n",
       "13  https://www.cnbc.com/2022/08/28/goodrx-ceo-dou...  \n",
       "14  https://www.cnbc.com/2022/08/28/poker-champ-da...  \n",
       "15  https://www.cnbc.com/2022/08/28/how-amazon-is-...  \n",
       "16  https://www.cnbc.com/2022/08/28/pet-moms-and-d...  \n",
       "17  https://www.cnbc.com/2022/08/28/with-two-check...  \n",
       "18  https://www.cnbc.com/2022/08/28/ubs-upgrades-l...  \n",
       "19  https://www.cnbc.com/2022/08/28/these-are-wall...  \n",
       "20  https://www.cnbc.com/2022/08/28/ev-makers-face...  \n",
       "21  https://www.cnbc.com/2022/08/27/texas-couple-t...  \n",
       "22  https://www.cnbc.com/2022/08/27/6-books-to-rea...  \n",
       "23  https://www.cnbc.com/2022/08/27/retired-couple...  \n",
       "24  https://www.cnbc.com/2022/08/27/testing-junes-...  \n",
       "25  https://www.cnbc.com/2022/08/27/us-companies-a...  \n",
       "26  https://www.cnbc.com/2022/08/27/analysts-say-b...  \n",
       "27  https://www.cnbc.com/2022/08/27/energy-compani...  \n",
       "28  https://www.cnbc.com/2022/08/27/best-us-cities...  \n",
       "29  https://www.cnbc.com/2022/08/27/how-ocean-ship...  \n",
       "30  https://www.cnbc.com/2022/08/27/do-you-make-to...  "
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#composing all the lists in  Q7 into a dictionary. \n",
    "headlines_info=dict()\n",
    "headlines_info={'Headlines':headlines,'Timestamp':timestamp ,'URL for Headline':nl_headlines}\n",
    "\n",
    "#displaying as Dataframe.\n",
    "headlines_info_df=pd.DataFrame(headlines_info)\n",
    "headlines_info_df.index = np.arange(1,len(headlines_info_df)+1)\n",
    "print(\"Compilation for Q7\")\n",
    "print()\n",
    "print(\"Link for live News: \",nlink)\n",
    "headlines_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2de190",
   "metadata": {},
   "source": [
    "<h2><center><font color='red'> SUCCESS!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcc6c0c",
   "metadata": {},
   "source": [
    "<h2><font color='red'>********************************************************************************************************* </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce09b9ba",
   "metadata": {},
   "source": [
    "<h2><font color='blue'>8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.<br> \n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details :\n",
    "<br>i) Paper Title \n",
    "<br>ii) Authors\n",
    "<br>iii) Published Date \n",
    "<br>iv) Paper URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1152e85",
   "metadata": {},
   "source": [
    "<h3><font color='green'> FIRST: Step1.</font> Request access to Source code for the webpage given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab476cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def journ():\n",
    "    path7= 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "    book=requests.get(path7)\n",
    "    #error handling\n",
    "    #if response is anything except 200 an exception is made\n",
    "    if book.status_code != 200:\n",
    "        raise Exception(f'Server Busy, Try again later! {path7}')\n",
    "    # Parse using BeautifulSoup function\n",
    "    jnl = BeautifulSoup(book.content, 'html.parser')\n",
    "    return jnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb19236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jl=journ()\n",
    "#jl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d400a998",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step2.</font> Scraping the Title of the Published Paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0107c7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward is enough\n"
     ]
    }
   ],
   "source": [
    "#Upon analysing the data, it is found that the title is in the 'ul' tags. checking directory for 1 instance\n",
    "epap=jl.find('ul', class_='sc-9zxyh7-0 ffmPq')\n",
    "title=epap.a.text\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ce6645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#above method cannot be used to find all instances of the tags, Hence employed another method, searching through another tag\n",
    "def epaper(jl):\n",
    "    artle=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"\n",
    "    \n",
    "    titles=[]\n",
    "    \n",
    "    for ti in jl.find_all('h2',class_=artle):\n",
    "        titles.append(ti.text)        \n",
    "    return titles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3c7bdbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reward is enough',\n",
       " 'Making sense of raw input',\n",
       " 'Law and logic: A review from an argumentation perspective',\n",
       " 'Creativity and artificial intelligence',\n",
       " 'Artificial cognition for social human–robot interaction: An implementation',\n",
       " 'Explanation in artificial intelligence: Insights from the social sciences',\n",
       " 'Making sense of sensory input',\n",
       " 'Conflict-based search for optimal multi-agent pathfinding',\n",
       " 'Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning',\n",
       " 'The Hanabi challenge: A new frontier for AI research',\n",
       " 'Evaluating XAI: A comparison of rule-based and example-based explanations',\n",
       " 'Argumentation in artificial intelligence',\n",
       " 'Algorithms for computing strategies in two-player simultaneous move games',\n",
       " 'Multiple object tracking: A literature review',\n",
       " 'Selection of relevant features and examples in machine learning',\n",
       " 'A survey of inverse reinforcement learning: Challenges, methods and progress',\n",
       " 'Explaining individual predictions when features are dependent: More accurate approximations to Shapley values',\n",
       " 'A review of possible effects of cognitive biases on interpretation of rule-based machine learning models',\n",
       " 'Integrating social power into the decision-making of cognitive agents',\n",
       " \"“That's (not) the output I expected!” On the role of end user expectations in creating explanations of AI systems\",\n",
       " 'Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in XAI user studies',\n",
       " 'Algorithm runtime prediction: Methods & evaluation',\n",
       " 'Wrappers for feature subset selection',\n",
       " 'Commonsense visual sensemaking for autonomous driving – On generalised neurosymbolic online abduction integrating vision and semantics',\n",
       " 'Quantum computation, quantum theory and AI']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_title=epaper(jl)\n",
    "paper_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c238e96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titles\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>List of Paper Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reward is enough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  List of Paper Title\n",
       "1                                    Reward is enough\n",
       "2                           Making sense of raw input\n",
       "3   Law and logic: A review from an argumentation ...\n",
       "4              Creativity and artificial intelligence\n",
       "5   Artificial cognition for social human–robot in...\n",
       "6   Explanation in artificial intelligence: Insigh...\n",
       "7                       Making sense of sensory input\n",
       "8   Conflict-based search for optimal multi-agent ...\n",
       "9   Between MDPs and semi-MDPs: A framework for te...\n",
       "10  The Hanabi challenge: A new frontier for AI re...\n",
       "11  Evaluating XAI: A comparison of rule-based and...\n",
       "12           Argumentation in artificial intelligence\n",
       "13  Algorithms for computing strategies in two-pla...\n",
       "14      Multiple object tracking: A literature review\n",
       "15  Selection of relevant features and examples in...\n",
       "16  A survey of inverse reinforcement learning: Ch...\n",
       "17  Explaining individual predictions when feature...\n",
       "18  A review of possible effects of cognitive bias...\n",
       "19  Integrating social power into the decision-mak...\n",
       "20  “That's (not) the output I expected!” On the r...\n",
       "21  Explaining black-box classifiers using post-ho...\n",
       "22  Algorithm runtime prediction: Methods & evalua...\n",
       "23              Wrappers for feature subset selection\n",
       "24  Commonsense visual sensemaking for autonomous ...\n",
       "25         Quantum computation, quantum theory and AI"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#composing the list into a dictionary. \n",
    "title_di=dict()\n",
    "title_di={'List of Paper Title':paper_title}\n",
    "\n",
    "#displaying as Dataframe.\n",
    "title_df=pd.DataFrame(title_di)\n",
    "title_df.index = np.arange(1,len(title_df)+1)\n",
    "print(\"titles\")\n",
    "print()\n",
    "print()\n",
    "title_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831ac54c",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step3.</font> Scraping the Author info of the respective papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbef19ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epaper_auth(jl):\n",
    "    artle=\"sc-1w3fpd7-0 pgLAT\"\n",
    "    \n",
    "    auth=[]\n",
    "    \n",
    "    for ta in jl.find_all('span',class_=artle):\n",
    "        auth.append(ta.text)        \n",
    "    return auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf2225cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Silver, David, Singh, Satinder, Precup, Doina, Sutton, Richard S. ',\n",
       " 'Evans, Richard, Bošnjak, Matko and 5 more',\n",
       " 'Prakken, Henry, Sartor, Giovanni ',\n",
       " 'Boden, Margaret A. ',\n",
       " 'Lemaignan, Séverin, Warnier, Mathieu and 3 more',\n",
       " 'Miller, Tim ',\n",
       " 'Evans, Richard, Hernández-Orallo, José and 3 more',\n",
       " 'Sharon, Guni, Stern, Roni, Felner, Ariel, Sturtevant, Nathan R. ',\n",
       " 'Sutton, Richard S., Precup, Doina, Singh, Satinder ',\n",
       " 'Bard, Nolan, Foerster, Jakob N. and 13 more',\n",
       " 'van der Waa, Jasper, Nieuwburg, Elisabeth, Cremers, Anita, Neerincx, Mark ',\n",
       " 'Bench-Capon, T.J.M., Dunne, Paul E. ',\n",
       " 'Bošanský, Branislav, Lisý, Viliam and 3 more',\n",
       " 'Luo, Wenhan, Xing, Junliang and 4 more',\n",
       " 'Blum, Avrim L., Langley, Pat ',\n",
       " 'Arora, Saurabh, Doshi, Prashant ',\n",
       " 'Aas, Kjersti, Jullum, Martin, Løland, Anders ',\n",
       " 'Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Johannes ',\n",
       " 'Pereira, Gonçalo, Prada, Rui, Santos, Pedro A. ',\n",
       " 'Riveiro, Maria, Thill, Serge ',\n",
       " 'Kenny, Eoin M., Ford, Courtney, Quinn, Molly, Keane, Mark T. ',\n",
       " 'Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyton-Brown, Kevin ',\n",
       " 'Kohavi, Ron, John, George H. ',\n",
       " 'Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srikrishna ',\n",
       " 'Ying, Mingsheng ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author=epaper_auth(jl)\n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef572922",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>List of Paper Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Miller, Tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  List of Paper Title\n",
       "1   Silver, David, Singh, Satinder, Precup, Doina,...\n",
       "2           Evans, Richard, Bošnjak, Matko and 5 more\n",
       "3                   Prakken, Henry, Sartor, Giovanni \n",
       "4                                 Boden, Margaret A. \n",
       "5     Lemaignan, Séverin, Warnier, Mathieu and 3 more\n",
       "6                                        Miller, Tim \n",
       "7   Evans, Richard, Hernández-Orallo, José and 3 more\n",
       "8   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...\n",
       "9   Sutton, Richard S., Precup, Doina, Singh, Sati...\n",
       "10        Bard, Nolan, Foerster, Jakob N. and 13 more\n",
       "11  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...\n",
       "12               Bench-Capon, T.J.M., Dunne, Paul E. \n",
       "13       Bošanský, Branislav, Lisý, Viliam and 3 more\n",
       "14             Luo, Wenhan, Xing, Junliang and 4 more\n",
       "15                      Blum, Avrim L., Langley, Pat \n",
       "16                   Arora, Saurabh, Doshi, Prashant \n",
       "17      Aas, Kjersti, Jullum, Martin, Løland, Anders \n",
       "18  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...\n",
       "19    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A. \n",
       "20                      Riveiro, Maria, Thill, Serge \n",
       "21  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...\n",
       "22  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...\n",
       "23                      Kohavi, Ron, John, George H. \n",
       "24  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...\n",
       "25                                   Ying, Mingsheng "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#composing the author list into a dictionary. \n",
    "author_di=dict()\n",
    "author_di={'List of Paper Title':author}\n",
    "\n",
    "#displaying as Dataframe.\n",
    "author_df=pd.DataFrame(author_di)\n",
    "author_df.index = np.arange(1,len(author_df)+1)\n",
    "print(\"Author\")\n",
    "print()\n",
    "print()\n",
    "author_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832bc53e",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step4.</font> Scraping the published Date info of the respective papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff025eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epub(jl):\n",
    "    artle=\"sc-1thf9ly-2 bKddwo\"\n",
    "    \n",
    "    pub=[]\n",
    "    \n",
    "    for to in jl.find_all('span',class_=artle):\n",
    "        pub.append(to.text)        \n",
    "    return pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bacfd7fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['October 2021',\n",
       " 'October 2021',\n",
       " 'October 2015',\n",
       " 'August 1998',\n",
       " 'June 2017',\n",
       " 'February 2019',\n",
       " 'April 2021',\n",
       " 'February 2015',\n",
       " 'August 1999',\n",
       " 'March 2020',\n",
       " 'February 2021',\n",
       " 'October 2007',\n",
       " 'August 2016',\n",
       " 'April 2021',\n",
       " 'December 1997',\n",
       " 'August 2021',\n",
       " 'September 2021',\n",
       " 'June 2021',\n",
       " 'December 2016',\n",
       " 'September 2021',\n",
       " 'May 2021',\n",
       " 'January 2014',\n",
       " 'December 1997',\n",
       " 'October 2021',\n",
       " 'February 2010']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_date=epub(jl)\n",
    "pub_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3e0d795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>List of Paper Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>October 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>August 1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>June 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>February 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>April 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>February 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>August 1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>March 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>February 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>October 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>August 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>April 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>December 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>August 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>September 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>June 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>December 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>September 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>May 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>January 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>December 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>October 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>February 2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   List of Paper Title\n",
       "1         October 2021\n",
       "2         October 2021\n",
       "3         October 2015\n",
       "4          August 1998\n",
       "5            June 2017\n",
       "6        February 2019\n",
       "7           April 2021\n",
       "8        February 2015\n",
       "9          August 1999\n",
       "10          March 2020\n",
       "11       February 2021\n",
       "12        October 2007\n",
       "13         August 2016\n",
       "14          April 2021\n",
       "15       December 1997\n",
       "16         August 2021\n",
       "17      September 2021\n",
       "18           June 2021\n",
       "19       December 2016\n",
       "20      September 2021\n",
       "21            May 2021\n",
       "22        January 2014\n",
       "23       December 1997\n",
       "24        October 2021\n",
       "25       February 2010"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#composing the list into a dictionary. \n",
    "p_date=dict()\n",
    "p_date={'List of Paper Title':pub_date}\n",
    "\n",
    "#displaying as Dataframe.\n",
    "p_date_df=pd.DataFrame(p_date)\n",
    "p_date_df.index = np.arange(1,len(p_date_df)+1)\n",
    "print(\"Author\")\n",
    "print()\n",
    "print()\n",
    "p_date_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ee5fc3",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step5.</font> Scraping the URL of the respective papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "07a73822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def purl(jl):\n",
    "    pur=[]\n",
    "    for link in jl.find_all('a', attrs={'href': re.compile(\"^https://\")}):\n",
    "        pur.append(link.get('href'))        \n",
    "    return pur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5e93029f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://account.elsevier.com/auth',\n",
       " 'https://elsevier.com/about',\n",
       " 'https://www.elsevier.com/connect',\n",
       " 'https://www.elsevier.com/about/careers',\n",
       " 'https://elsevier.com/about',\n",
       " 'https://www.elsevier.com/connect',\n",
       " 'https://www.elsevier.com/about/careers',\n",
       " 'https://www.elsevier.com/rd-solutions',\n",
       " 'https://www.elsevier.com/clinical-solutions',\n",
       " 'https://www.elsevier.com/research-platforms',\n",
       " 'https://www.elsevier.com/research-intelligence',\n",
       " 'https://www.elsevier.com/education',\n",
       " 'https://www.elsevier.com/solutions',\n",
       " 'https://www.elsevier.com/rd-solutions',\n",
       " 'https://www.elsevier.com/clinical-solutions',\n",
       " 'https://www.elsevier.com/research-platforms',\n",
       " 'https://www.elsevier.com/research-intelligence',\n",
       " 'https://www.elsevier.com/education',\n",
       " 'https://www.elsevier.com/solutions',\n",
       " 'https://www.elsevier.com/authors',\n",
       " 'https://www.elsevier.com/editors',\n",
       " 'https://www.elsevier.com/reviewers',\n",
       " 'https://www.elsevier.com/librarians',\n",
       " 'https://www.elsevier.com/strategic-partners',\n",
       " 'https://www.elsevier.com/open-access']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_urls=purl(jl)[:25]\n",
    "papers_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ed1ea23d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urls\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>List of Paper Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://account.elsevier.com/auth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://elsevier.com/about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.elsevier.com/connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.elsevier.com/about/careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://elsevier.com/about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.elsevier.com/connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.elsevier.com/about/careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.elsevier.com/rd-solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.elsevier.com/clinical-solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://www.elsevier.com/research-platforms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.elsevier.com/research-intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://www.elsevier.com/education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://www.elsevier.com/solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://www.elsevier.com/rd-solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://www.elsevier.com/clinical-solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://www.elsevier.com/research-platforms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://www.elsevier.com/research-intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://www.elsevier.com/education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://www.elsevier.com/solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>https://www.elsevier.com/authors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>https://www.elsevier.com/editors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>https://www.elsevier.com/reviewers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>https://www.elsevier.com/librarians</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>https://www.elsevier.com/strategic-partners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://www.elsevier.com/open-access</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               List of Paper Title\n",
       "1                https://account.elsevier.com/auth\n",
       "2                       https://elsevier.com/about\n",
       "3                 https://www.elsevier.com/connect\n",
       "4           https://www.elsevier.com/about/careers\n",
       "5                       https://elsevier.com/about\n",
       "6                 https://www.elsevier.com/connect\n",
       "7           https://www.elsevier.com/about/careers\n",
       "8            https://www.elsevier.com/rd-solutions\n",
       "9      https://www.elsevier.com/clinical-solutions\n",
       "10     https://www.elsevier.com/research-platforms\n",
       "11  https://www.elsevier.com/research-intelligence\n",
       "12              https://www.elsevier.com/education\n",
       "13              https://www.elsevier.com/solutions\n",
       "14           https://www.elsevier.com/rd-solutions\n",
       "15     https://www.elsevier.com/clinical-solutions\n",
       "16     https://www.elsevier.com/research-platforms\n",
       "17  https://www.elsevier.com/research-intelligence\n",
       "18              https://www.elsevier.com/education\n",
       "19              https://www.elsevier.com/solutions\n",
       "20                https://www.elsevier.com/authors\n",
       "21                https://www.elsevier.com/editors\n",
       "22              https://www.elsevier.com/reviewers\n",
       "23             https://www.elsevier.com/librarians\n",
       "24     https://www.elsevier.com/strategic-partners\n",
       "25            https://www.elsevier.com/open-access"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#composing the list into a dictionary. \n",
    "p_url=dict()\n",
    "p_url={'List of Paper Title':papers_urls}\n",
    "\n",
    "#displaying as Dataframe.\n",
    "p_url_df=pd.DataFrame(p_url)\n",
    "p_url_df.index = np.arange(1,len(p_url_df)+1)\n",
    "print(\"urls\")\n",
    "print()\n",
    "print()\n",
    "p_url_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8f1d2c",
   "metadata": {},
   "source": [
    "<h3><font color='green'> Finally: Step6.</font> Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43993dbf",
   "metadata": {},
   "source": [
    "<h2>Compiling Q8 (i) to (iv) into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fe2c3fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>List of Paper Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://account.elsevier.com/auth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://elsevier.com/about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.elsevier.com/connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.elsevier.com/about/careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://elsevier.com/about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.elsevier.com/connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.elsevier.com/about/careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.elsevier.com/rd-solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.elsevier.com/clinical-solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.elsevier.com/research-platforms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.elsevier.com/research-intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.elsevier.com/education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.elsevier.com/solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.elsevier.com/rd-solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.elsevier.com/clinical-solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.elsevier.com/research-platforms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.elsevier.com/research-intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.elsevier.com/education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.elsevier.com/solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.elsevier.com/authors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.elsevier.com/editors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.elsevier.com/reviewers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.elsevier.com/librarians</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.elsevier.com/strategic-partners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.elsevier.com/open-access</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  List of Paper Title  \\\n",
       "1                                    Reward is enough   \n",
       "2                           Making sense of raw input   \n",
       "3   Law and logic: A review from an argumentation ...   \n",
       "4              Creativity and artificial intelligence   \n",
       "5   Artificial cognition for social human–robot in...   \n",
       "6   Explanation in artificial intelligence: Insigh...   \n",
       "7                       Making sense of sensory input   \n",
       "8   Conflict-based search for optimal multi-agent ...   \n",
       "9   Between MDPs and semi-MDPs: A framework for te...   \n",
       "10  The Hanabi challenge: A new frontier for AI re...   \n",
       "11  Evaluating XAI: A comparison of rule-based and...   \n",
       "12           Argumentation in artificial intelligence   \n",
       "13  Algorithms for computing strategies in two-pla...   \n",
       "14      Multiple object tracking: A literature review   \n",
       "15  Selection of relevant features and examples in...   \n",
       "16  A survey of inverse reinforcement learning: Ch...   \n",
       "17  Explaining individual predictions when feature...   \n",
       "18  A review of possible effects of cognitive bias...   \n",
       "19  Integrating social power into the decision-mak...   \n",
       "20  “That's (not) the output I expected!” On the r...   \n",
       "21  Explaining black-box classifiers using post-ho...   \n",
       "22  Algorithm runtime prediction: Methods & evalua...   \n",
       "23              Wrappers for feature subset selection   \n",
       "24  Commonsense visual sensemaking for autonomous ...   \n",
       "25         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                               Author  Published Date  \\\n",
       "1   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "2           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "3                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "4                                 Boden, Margaret A.      August 1998   \n",
       "5     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "6                                        Miller, Tim    February 2019   \n",
       "7   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "8   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "9   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "10        Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "11  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "12               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "13       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "14             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "15                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "16                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "17      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "18  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "19    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "20                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "21  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "22  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "23                      Kohavi, Ron, John, George H.    December 1997   \n",
       "24  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "25                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                         Paper URL  \n",
       "1                https://account.elsevier.com/auth  \n",
       "2                       https://elsevier.com/about  \n",
       "3                 https://www.elsevier.com/connect  \n",
       "4           https://www.elsevier.com/about/careers  \n",
       "5                       https://elsevier.com/about  \n",
       "6                 https://www.elsevier.com/connect  \n",
       "7           https://www.elsevier.com/about/careers  \n",
       "8            https://www.elsevier.com/rd-solutions  \n",
       "9      https://www.elsevier.com/clinical-solutions  \n",
       "10     https://www.elsevier.com/research-platforms  \n",
       "11  https://www.elsevier.com/research-intelligence  \n",
       "12              https://www.elsevier.com/education  \n",
       "13              https://www.elsevier.com/solutions  \n",
       "14           https://www.elsevier.com/rd-solutions  \n",
       "15     https://www.elsevier.com/clinical-solutions  \n",
       "16     https://www.elsevier.com/research-platforms  \n",
       "17  https://www.elsevier.com/research-intelligence  \n",
       "18              https://www.elsevier.com/education  \n",
       "19              https://www.elsevier.com/solutions  \n",
       "20                https://www.elsevier.com/authors  \n",
       "21                https://www.elsevier.com/editors  \n",
       "22              https://www.elsevier.com/reviewers  \n",
       "23             https://www.elsevier.com/librarians  \n",
       "24     https://www.elsevier.com/strategic-partners  \n",
       "25            https://www.elsevier.com/open-access  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#composing all the lists in  Q8 into a dictionary. \n",
    "Paper_page=dict()\n",
    "Paper_page={'List of Paper Title':paper_title,'Author':author ,'Published Date':pub_date,'Paper URL':papers_urls}\n",
    "\n",
    "#displaying as Dataframe.\n",
    "Paper_page_df=pd.DataFrame(Paper_page)\n",
    "Paper_page_df.index = np.arange(1,len(Paper_page_df)+1)\n",
    "print(\"Compilation\")\n",
    "print()\n",
    "Paper_page_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed80624e",
   "metadata": {},
   "source": [
    "<h2><center><font color='red'>SUCCESS!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ed6cc",
   "metadata": {},
   "source": [
    "<h2><font color='red'>********************************************************************************************************* </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9d283c",
   "metadata": {},
   "source": [
    "<h2><font color='blue'>9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "<br>i) Restaurant name\n",
    "<br>ii) Cuisine\n",
    "<br>iii) Location \n",
    "<br>iv) Ratings\n",
    "<br>v) Image URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d49026",
   "metadata": {},
   "source": [
    "<h3><font color='green'> FIRST: Step1.</font> Request access to the source code of webpage and then use BS to parse the Source code into python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f0b5c701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "def dineout_access():\n",
    "\n",
    "    path10= \"https://www.dineout.co.in/bangalore-restaurants\"\n",
    "    dine=requests.get(path10)\n",
    "    #error handling\n",
    "    #if response is anything except 200 an exception is made\n",
    "    if dine.status_code != 200:\n",
    "        raise Exception(f'Server Busy, Try again later! {path10}')\n",
    "    # Parse using BeautifulSoup function\n",
    "    out = BeautifulSoup(dine.content, 'html.parser')\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f7bae43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "din=dineout_access()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5044265e",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step2.</font> Scraping Restaurant names by accessing the \"alt\" tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "f1a901fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not working- unable to scrape the 'alt' tags. tried different techniques \n",
    "def do_rest_names(din):\n",
    "    \n",
    "    #marquee the selection\n",
    "    \n",
    "    vessel=\"restnt-main-wrap clearfix\"\n",
    "    bowl=din.find_all('div',{'class':vessel})\n",
    "    \n",
    "    #Inititalise Empty list to store names\n",
    "    \n",
    "    res_names_dinout =[]\n",
    "    \n",
    "   \n",
    "    #select all the names from marquee\n",
    "    for spoon in bowl:\n",
    "        spoon1=spoon\n",
    "        res_names_dinout.append(spoon1.text)\n",
    "    \n",
    "    #return names\n",
    "        \n",
    "    return res_names_dinout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "50b213dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.44.3232 votesThe Bier Library Brewery & KitchenKoramangala, South Bangalore₹ 1,900 for 2 (approx) | Continental, Finger Food, North IndianDineout Pay',\n",
       " 'In high demand4.34.3232 votesUru BrewparkJP Nagar, South Bangalore₹ 2,000 for 2 (approx) | North Indian, Italian, Continental, AsianDineout Pay',\n",
       " '4.44.3232 votesHard Rock CafeSt. Marks Road, Central Bangalore₹ 2,500 for 2 (approx) | Continental, American, Finger FoodDineout Pay',\n",
       " '4.44.3232 votesBiergartenKoramangala, South Bangalore₹ 2,400 for 2 (approx) | Continental, EuropeanDineout Pay',\n",
       " '3.74.3232 votesNo Limmits Lounge and ClubAllied Grand Plaza,Magrath Road, Central Bangalore₹ 1,900 for 2 (approx) | North Indian, Continental, Chinese6 deals availableDineout PayDesi SundayBuy NowSouth Night Buy NowDeluxe Night PartyBuy NowLadies Night Buy NowThursday BoomboxBuy NowFriday Bangalore Cocktail NightBuy Now+5 more deals- See less',\n",
       " '4.34.3232 votesThe Bangalore CafeShanti Nagar, Central Bangalore₹ 800 for 2 (approx) | Continental, North Indian, Fast FoodDineout Pay',\n",
       " '4.54.3232 votesToscanoUB City,Vittal Mallya Road, Central Bangalore₹ 1,600 for 2 (approx) | ItalianDineout Pay',\n",
       " '4.24.3232 votesBadmaashUB City,Vittal Mallya Road, Central Bangalore₹ 1,500 for 2 (approx) | North Indian, Chettinad, Andhra, BiryaniDineout Pay',\n",
       " '4.44.3232 votesCafe NoirUB City,Vittal Mallya Road, Central Bangalore₹ 1,700 for 2 (approx) | Continental, French, European, Health Food, BeveragesDineout Pay',\n",
       " '4.34.3232 votesThe Biere ClubVittal Mallya Road, Central Bangalore₹ 2,000 for 2 (approx) | Finger FoodDineout Pay',\n",
       " '4.14.3232 votes21st Amendment GastrobarIndiranagar, East Bangalore₹ 1,500 for 2 (approx) | North Indian, Continental, Chinese, Fast FoodDineout Pay',\n",
       " '4.44.3232 votesJW KitchenJW Marriott Hotel,Vittal Mallya Road, Central Bangalore₹ 2,200 for 2 (approx) | North Indian, ContinentalDineout Pay',\n",
       " '4.34.3232 votesCafe AzzureMG Road, Central Bangalore₹ 1,200 for 2 (approx) | Continental, Italian, Desserts, BengaliDineout Pay',\n",
       " '4.54.3232 votesSalt - Indian Restaurant Bar & GrillUB City, Central Bangalore₹ 1,500 for 2 (approx) | North Indian, MughlaiDineout Pay',\n",
       " '4.34.3232 votesSanchezUB City,Vittal Mallya Road, Central Bangalore₹ 1,800 for 2 (approx) | MexicanDineout Pay',\n",
       " 'Popular for food44.3232 votesRaahiSt. Marks Road, Central Bangalore₹ 1,900 for 2 (approx) | FusionDineout Pay',\n",
       " '4.34.3232 votesDaddyIndiranagar, East Bangalore₹ 2,200 for 2 (approx) | Asian, North Indian, European, ItalianDineout Pay',\n",
       " '4.34.3232 votesSpice TerraceJW Marriott Hotel,Vittal Mallya Road, Central Bangalore₹ 3,900 for 2 (approx) | North Indian, MughlaiDineout Pay',\n",
       " '4.44.3232 votes1522 - The PubResidency Road, Central Bangalore₹ 1,600 for 2 (approx) | Continental, North Indian, Italian, AsianDineout Pay',\n",
       " '4.34.3232 votesFarzi CafeUB City,Vittal Mallya Road, Central Bangalore₹ 1,600 for 2 (approx) | Modern IndianDineout Pay',\n",
       " '4.34.3232 votesStories Brewery and KitchenBTM Layout, South Bangalore₹ 2,000 for 2 (approx) | Continental, Italian, Chinese, North IndianDineout Pay']"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dineout_restaurant_names=do_rest_names(din)[:21]\n",
    "dineout_restaurant_names\n",
    "#images_list.append({\"src\": src, \"alt\": alt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "5b975f0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Bier Library Brewery & Kitchen',\n",
       " 'Uru Brewpark',\n",
       " 'Hard Rock Cafe',\n",
       " 'Biergarten',\n",
       " 'No Limmits Lounge and Club',\n",
       " 'The Bangalore Cafe',\n",
       " 'Toscano',\n",
       " 'Badmaash',\n",
       " 'Cafe Noir',\n",
       " 'The Biere Club',\n",
       " '21st Amendment Gastrobar',\n",
       " 'JW Kitchen',\n",
       " 'Cafe Azzure',\n",
       " 'Salt - Indian Restaurant Bar & Grill',\n",
       " 'Sanchez',\n",
       " 'Raahi',\n",
       " 'Daddy',\n",
       " 'Spice Terrace',\n",
       " '1522 - The Pub',\n",
       " 'Farzi Cafe',\n",
       " 'Stories Brewery and Kitchen']"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new technique-concept inspired by logic found online\n",
    "#Restaurant names\n",
    "imgs = [div.find('img') for div in din.find_all(\"div\", {\"class\":\"restnt-main-wrap clearfix\"}) if div.find('img')]\n",
    "dinout_rest_names = [img.get('alt') for img in imgs][:21]\n",
    "dinout_rest_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4fcbf",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step3.</font> Scraping the cuisine info from the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "66444938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dine0ut_cuisine(din):\n",
    "    artle=\"double-line-ellipsis\"\n",
    "    \n",
    "    cuisine=[]\n",
    "    \n",
    "    for plate in din.find_all('span',class_=artle):\n",
    "        cuisine.append(plate.text.split('|').pop(1))        \n",
    "    return cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "ba64e43e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Continental, Finger Food, North Indian',\n",
       " ' North Indian, Italian, Continental, Asian',\n",
       " ' Continental, American, Finger Food',\n",
       " ' Continental, European',\n",
       " ' North Indian, Continental, Chinese',\n",
       " ' Continental, North Indian, Fast Food',\n",
       " ' Italian',\n",
       " ' North Indian, Chettinad, Andhra, Biryani',\n",
       " ' Continental, French, European, Health Food, Beverages',\n",
       " ' Finger Food',\n",
       " ' North Indian, Continental, Chinese, Fast Food',\n",
       " ' North Indian, Continental',\n",
       " ' Continental, Italian, Desserts, Bengali',\n",
       " ' North Indian, Mughlai',\n",
       " ' Mexican',\n",
       " ' Fusion',\n",
       " ' Asian, North Indian, European, Italian',\n",
       " ' North Indian, Mughlai',\n",
       " ' Continental, North Indian, Italian, Asian',\n",
       " ' Modern Indian',\n",
       " ' Continental, Italian, Chinese, North Indian']"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dineout_rest_cuisine=dine0ut_cuisine(din)[:21]\n",
    "dineout_rest_cuisine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e358c641",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step4.</font> Scraping Location info of the Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "4bef7d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dine0ut_area(din):\n",
    "    artle=\"restnt-loc ellipsis\"\n",
    "    \n",
    "    ar=[]\n",
    "    \n",
    "    for street in din.find_all('div',class_=artle):\n",
    "        ar.append(street.text)        \n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "7dd0eaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Koramangala, South Bangalore',\n",
       " 'JP Nagar, South Bangalore',\n",
       " 'St. Marks Road, Central Bangalore',\n",
       " 'Koramangala, South Bangalore',\n",
       " 'Allied Grand Plaza,Magrath Road, Central Bangalore',\n",
       " 'Shanti Nagar, Central Bangalore',\n",
       " 'UB City,Vittal Mallya Road, Central Bangalore',\n",
       " 'UB City,Vittal Mallya Road, Central Bangalore',\n",
       " 'UB City,Vittal Mallya Road, Central Bangalore',\n",
       " 'Vittal Mallya Road, Central Bangalore',\n",
       " 'Indiranagar, East Bangalore',\n",
       " 'JW Marriott Hotel,Vittal Mallya Road, Central Bangalore',\n",
       " 'MG Road, Central Bangalore',\n",
       " 'UB City, Central Bangalore',\n",
       " 'UB City,Vittal Mallya Road, Central Bangalore',\n",
       " 'St. Marks Road, Central Bangalore',\n",
       " 'Indiranagar, East Bangalore',\n",
       " 'JW Marriott Hotel,Vittal Mallya Road, Central Bangalore',\n",
       " 'Residency Road, Central Bangalore',\n",
       " 'UB City,Vittal Mallya Road, Central Bangalore',\n",
       " 'BTM Layout, South Bangalore']"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dineout_rest_loc=dine0ut_area(din)[:21]\n",
    "dineout_rest_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab8247",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step5.</font> Scraping the Rating of the restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "9f4af567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dine0ut_rating(din):\n",
    "    artle=\"restnt-rating rating-4\"\n",
    "    \n",
    "    rate=[]\n",
    "    \n",
    "    for star in din.find_all('div',class_=artle):\n",
    "        rate.append(star.text)        \n",
    "    return rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "36a6d3ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.4',\n",
       " '4.3',\n",
       " '4.4',\n",
       " '4.4',\n",
       " '3.7',\n",
       " '4.3',\n",
       " '4.2',\n",
       " '4.4',\n",
       " '4.3',\n",
       " '4.1',\n",
       " '4.4',\n",
       " '4.3',\n",
       " '4.3',\n",
       " '4',\n",
       " '4.3',\n",
       " '4.3',\n",
       " '4.4',\n",
       " '4.3',\n",
       " '4.3']"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only 19 restaurants info present so appending '0' to make them into nan values\n",
    "dineout_rest_rat=dine0ut_rating(din)\n",
    "dineout_rest_rat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "d1dbbe8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.4',\n",
       " '4.3',\n",
       " '4.4',\n",
       " '4.4',\n",
       " '3.7',\n",
       " '4.3',\n",
       " '4.2',\n",
       " '4.4',\n",
       " '4.3',\n",
       " '4.1',\n",
       " '4.4',\n",
       " '4.3',\n",
       " '4.3',\n",
       " '4',\n",
       " '4.3',\n",
       " '4.3',\n",
       " '4.4',\n",
       " '4.3',\n",
       " '4.3',\n",
       " '0',\n",
       " '0']"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#appended 0. will convert to 'nan' values while forming of df\n",
    "dineout_rest_rat.append('0')\n",
    "dineout_rest_rat.append('0')\n",
    "dineout_rest_rating=dineout_rest_rat[:21]\n",
    "dineout_rest_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ac5dca",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step6.</font> Scraping the URL to the img file of the restaurant, using the img tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "1481f7bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/r/y/p48670-15414807385be1212212d20.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/6/k/n/p60213-162643925660f17e58443c5.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/h/z/p3728-15819343935e4a6739ada8d.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/k/q/p50533-15783109835e131d4774e89.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/9/k/f/p9416-1637666314619cce0a06ca9.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/u/u/p48391-15501219495c64fbdd483e4.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/g/h/p860-16107933836002c1a7713ed.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/l/j/p87534-161719349660646a18dc26a.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/b/e/p4471-16353141816178ea05c332c.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/1/i/k/p1168-15992017925f51e2003d1f0.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/6/s/t/p64100-15789184475e1c622faf327.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/1/z/g/p13437-15370039825b9cd1cec3540.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/g/h/p29533-14807615365842a0c04da29.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/1/v/x/p106372-165303476162874f0909e7c.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/1/y/t/p1258-15517088875c7d32d7331ff.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/7/q/k/p71751-15743140755dd6205b7b8fa.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/u/f/p57949-15604908195d033343f04f5.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/1/m/n/p13467-15646445765d4294e08b5cc.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/r/q/p87607-163101820961375ce1110d7.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/b/h/p24670-164386528961fb64c942ac7.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/m/v/p50979-15681917225d78b4eade641.jpg?tr=tr:n-medium']"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = [div.find('img') for div in din.find_all(\"div\", {\"class\":\"restnt-main-wrap clearfix\"}) if div.find('img')]\n",
    "dinout_rest_pic = [img.get('data-src') for img in imgs][:21]\n",
    "dinout_rest_pic\n",
    "#imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc72f858",
   "metadata": {},
   "source": [
    " <h3><font color='green'> FINALLY: Step6.</font>Collaborating all Data to make one DF for Q9</h3><br><h4> Also using np.nan to change 0 to nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "923a25ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Location/Area</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Restaurant Rating</th>\n",
       "      <th>Restaurant img URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Bier Library Brewery &amp; Kitchen</td>\n",
       "      <td>Koramangala, South Bangalore</td>\n",
       "      <td>Continental, Finger Food, North Indian</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uru Brewpark</td>\n",
       "      <td>JP Nagar, South Bangalore</td>\n",
       "      <td>North Indian, Italian, Continental, Asian</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hard Rock Cafe</td>\n",
       "      <td>St. Marks Road, Central Bangalore</td>\n",
       "      <td>Continental, American, Finger Food</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Biergarten</td>\n",
       "      <td>Koramangala, South Bangalore</td>\n",
       "      <td>Continental, European</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No Limmits Lounge and Club</td>\n",
       "      <td>Allied Grand Plaza,Magrath Road, Central Banga...</td>\n",
       "      <td>North Indian, Continental, Chinese</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Bangalore Cafe</td>\n",
       "      <td>Shanti Nagar, Central Bangalore</td>\n",
       "      <td>Continental, North Indian, Fast Food</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Toscano</td>\n",
       "      <td>UB City,Vittal Mallya Road, Central Bangalore</td>\n",
       "      <td>Italian</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Badmaash</td>\n",
       "      <td>UB City,Vittal Mallya Road, Central Bangalore</td>\n",
       "      <td>North Indian, Chettinad, Andhra, Biryani</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cafe Noir</td>\n",
       "      <td>UB City,Vittal Mallya Road, Central Bangalore</td>\n",
       "      <td>Continental, French, European, Health Food, B...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Biere Club</td>\n",
       "      <td>Vittal Mallya Road, Central Bangalore</td>\n",
       "      <td>Finger Food</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21st Amendment Gastrobar</td>\n",
       "      <td>Indiranagar, East Bangalore</td>\n",
       "      <td>North Indian, Continental, Chinese, Fast Food</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>JW Kitchen</td>\n",
       "      <td>JW Marriott Hotel,Vittal Mallya Road, Central ...</td>\n",
       "      <td>North Indian, Continental</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cafe Azzure</td>\n",
       "      <td>MG Road, Central Bangalore</td>\n",
       "      <td>Continental, Italian, Desserts, Bengali</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Salt - Indian Restaurant Bar &amp; Grill</td>\n",
       "      <td>UB City, Central Bangalore</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sanchez</td>\n",
       "      <td>UB City,Vittal Mallya Road, Central Bangalore</td>\n",
       "      <td>Mexican</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Raahi</td>\n",
       "      <td>St. Marks Road, Central Bangalore</td>\n",
       "      <td>Fusion</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Daddy</td>\n",
       "      <td>Indiranagar, East Bangalore</td>\n",
       "      <td>Asian, North Indian, European, Italian</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Spice Terrace</td>\n",
       "      <td>JW Marriott Hotel,Vittal Mallya Road, Central ...</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1522 - The Pub</td>\n",
       "      <td>Residency Road, Central Bangalore</td>\n",
       "      <td>Continental, North Indian, Italian, Asian</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Farzi Cafe</td>\n",
       "      <td>UB City,Vittal Mallya Road, Central Bangalore</td>\n",
       "      <td>Modern Indian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Stories Brewery and Kitchen</td>\n",
       "      <td>BTM Layout, South Bangalore</td>\n",
       "      <td>Continental, Italian, Chinese, North Indian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Restaurant  \\\n",
       "1     The Bier Library Brewery & Kitchen   \n",
       "2                           Uru Brewpark   \n",
       "3                         Hard Rock Cafe   \n",
       "4                             Biergarten   \n",
       "5             No Limmits Lounge and Club   \n",
       "6                     The Bangalore Cafe   \n",
       "7                                Toscano   \n",
       "8                               Badmaash   \n",
       "9                              Cafe Noir   \n",
       "10                        The Biere Club   \n",
       "11              21st Amendment Gastrobar   \n",
       "12                            JW Kitchen   \n",
       "13                           Cafe Azzure   \n",
       "14  Salt - Indian Restaurant Bar & Grill   \n",
       "15                               Sanchez   \n",
       "16                                 Raahi   \n",
       "17                                 Daddy   \n",
       "18                         Spice Terrace   \n",
       "19                        1522 - The Pub   \n",
       "20                            Farzi Cafe   \n",
       "21           Stories Brewery and Kitchen   \n",
       "\n",
       "                                        Location/Area  \\\n",
       "1                        Koramangala, South Bangalore   \n",
       "2                           JP Nagar, South Bangalore   \n",
       "3                   St. Marks Road, Central Bangalore   \n",
       "4                        Koramangala, South Bangalore   \n",
       "5   Allied Grand Plaza,Magrath Road, Central Banga...   \n",
       "6                     Shanti Nagar, Central Bangalore   \n",
       "7       UB City,Vittal Mallya Road, Central Bangalore   \n",
       "8       UB City,Vittal Mallya Road, Central Bangalore   \n",
       "9       UB City,Vittal Mallya Road, Central Bangalore   \n",
       "10              Vittal Mallya Road, Central Bangalore   \n",
       "11                        Indiranagar, East Bangalore   \n",
       "12  JW Marriott Hotel,Vittal Mallya Road, Central ...   \n",
       "13                         MG Road, Central Bangalore   \n",
       "14                         UB City, Central Bangalore   \n",
       "15      UB City,Vittal Mallya Road, Central Bangalore   \n",
       "16                  St. Marks Road, Central Bangalore   \n",
       "17                        Indiranagar, East Bangalore   \n",
       "18  JW Marriott Hotel,Vittal Mallya Road, Central ...   \n",
       "19                  Residency Road, Central Bangalore   \n",
       "20      UB City,Vittal Mallya Road, Central Bangalore   \n",
       "21                        BTM Layout, South Bangalore   \n",
       "\n",
       "                                              Cuisine Restaurant Rating  \\\n",
       "1              Continental, Finger Food, North Indian               4.4   \n",
       "2           North Indian, Italian, Continental, Asian               4.3   \n",
       "3                  Continental, American, Finger Food               4.4   \n",
       "4                               Continental, European               4.4   \n",
       "5                  North Indian, Continental, Chinese               3.7   \n",
       "6                Continental, North Indian, Fast Food               4.3   \n",
       "7                                             Italian               4.2   \n",
       "8            North Indian, Chettinad, Andhra, Biryani               4.4   \n",
       "9    Continental, French, European, Health Food, B...               4.3   \n",
       "10                                        Finger Food               4.1   \n",
       "11      North Indian, Continental, Chinese, Fast Food               4.4   \n",
       "12                          North Indian, Continental               4.3   \n",
       "13            Continental, Italian, Desserts, Bengali               4.3   \n",
       "14                              North Indian, Mughlai                 4   \n",
       "15                                            Mexican               4.3   \n",
       "16                                             Fusion               4.3   \n",
       "17             Asian, North Indian, European, Italian               4.4   \n",
       "18                              North Indian, Mughlai               4.3   \n",
       "19          Continental, North Indian, Italian, Asian               4.3   \n",
       "20                                      Modern Indian               NaN   \n",
       "21        Continental, Italian, Chinese, North Indian               NaN   \n",
       "\n",
       "                                   Restaurant img URL  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "13  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "14  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "15  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "16  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "17  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "18  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "19  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "20  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "21  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#composing all the lists in  Q9 into a dictionary. \n",
    "dineout_page=dict()\n",
    "dineout_page={'Restaurant':dinout_rest_names,'Location/Area':dineout_rest_loc,'Cuisine':dineout_rest_cuisine ,'Restaurant Rating':dineout_rest_rat,'Restaurant img URL':dinout_rest_pic}\n",
    "dineout_page\n",
    "\n",
    "#displaying as Dataframe.\n",
    "dineout_page_df=pd.DataFrame(dineout_page)\n",
    "dineout_page_df.index = np.arange(1,len(dineout_page_df)+1)\n",
    "print(\"Compilation\")\n",
    "print()\n",
    "#dineout_page_df\n",
    "dineout_page_df_nan=dineout_page_df.replace('0',np.nan)\n",
    "dineout_page_df_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9506cfac",
   "metadata": {},
   "source": [
    "<h2><center><font color='red'>SUCCESS!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0ab746",
   "metadata": {},
   "source": [
    "<h2><font color='red'>********************************************************************************************************* </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76993329",
   "metadata": {},
   "source": [
    "<h2><font color='blue'>10) Write a python program to scrape the details of top publications from Google Scholar from \n",
    "<br>https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "<br>i) Rank \n",
    "<br>ii) Publication\n",
    "<br>iii) h5-index\n",
    "<br>iv) h5-median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c63a7c9",
   "metadata": {},
   "source": [
    "<h3><font color='green'> FIRST: Step1.</font>- Request Access for the source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "23323c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "def gulu_gulu_access():\n",
    "\n",
    "    path15= \"https://scholar.google.com/citations?view_op=top_venues&hl=en\"\n",
    "    gulut=requests.get(path15)\n",
    "    #error handling\n",
    "    #if response is anything except 200 an exception is made\n",
    "    if gulut.status_code != 200:\n",
    "        raise Exception(f'Server Busy, Try again later! {path10}')\n",
    "    # Parse using BeautifulSoup function\n",
    "    gulu_gulu = BeautifulSoup(gulut.content, 'html.parser')\n",
    "    return gulu_gulu\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "591aaeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "gulu=gulu_gulu_access()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a167ad",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step2.</font> Scrape the Ranks of the publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "24783d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceeding to harvest rank from selection\n",
    "\n",
    "def scholar_rank(gulu):\n",
    "    \n",
    "    #marquee the selection\n",
    "    \n",
    "    sel_google=\"gsc_mvt_p\"\n",
    "    selec_ind=gulu.find_all('td',{'class':sel_google})\n",
    "    \n",
    "    #Inititalise Empty list to store names\n",
    "    \n",
    "    sch_rank=[]\n",
    "    \n",
    "  \n",
    "    \n",
    "    for books in selec_ind:\n",
    "        \n",
    "        sch_rank.append(books.text)\n",
    "    \n",
    "\n",
    "        \n",
    "    return sch_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "ffefc81b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.', '2.', '3.', '4.', '5.']"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_scholar_rank=scholar_rank(gulu)\n",
    "#len(google_scholar_rank)\n",
    "google_scholar_rank[:5]#--------------------displaying only first five ranks to reduce clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080fd998",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step3.</font> Scraping Publication Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "c27f472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceeding to Publication name from selection\n",
    "\n",
    "def scholar_pub(gulu):\n",
    "    \n",
    "    #marquee the selection\n",
    "    \n",
    "    sel_goo=\"gsc_mvt_t\"\n",
    "    sele_ind=gulu.find_all('td',{'class':sel_goo})\n",
    "    \n",
    "    #Inititalise Empty list to store names\n",
    "    \n",
    "    sch_pub=[]\n",
    "    \n",
    " \n",
    "    \n",
    "    for pages in sele_ind:\n",
    "        \n",
    "        sch_pub.append(pages.text)\n",
    "    \n",
    "   \n",
    "        \n",
    "    return sch_pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "624a8089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nature',\n",
       " 'The New England Journal of Medicine',\n",
       " 'Science',\n",
       " 'IEEE/CVF Conference on Computer Vision and Pattern Recognition',\n",
       " 'The Lancet']"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_scholar_pub=scholar_pub(gulu)\n",
    "#len(google_scholar_pub)\n",
    "google_scholar_pub[:5]#--------------------displaying only first five ranks to reduce clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022ffed8",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step4.</font> Scraping H5-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "8bbede88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceeding to harvest h5index from selection\n",
    "\n",
    "def scholar_h5(gulu):\n",
    "    \n",
    "    #marquee the selection\n",
    "    \n",
    "    sel_go=\"gsc_mvt_n\"\n",
    "    selet_ind=gulu.find_all('td',{'class':sel_go})\n",
    "    \n",
    "    #Inititalise Empty list to store names\n",
    "    \n",
    "    sch_h5=[]\n",
    "    \n",
    "\n",
    "    \n",
    "    for page in selet_ind:\n",
    "        \n",
    "        sch_h5.append(page.text)\n",
    "    \n",
    "   \n",
    "        \n",
    "    return sch_h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "b72899d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['444', '667', '432', '780', '401']"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_scholar_h5=scholar_h5(gulu)[:100]#------splicing list, as list contains both h5 index and median. displaying only index\n",
    "len(google_scholar_h5)\n",
    "google_scholar_h5[:5]#--------------------displaying only first five ranks to reduce clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae25919",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step6.</font> Scraping H5median from the source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "030620a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceeding to harvest h5median from selection\n",
    "\n",
    "def scholar_med(gulu):\n",
    "    \n",
    "    #marquee the selection\n",
    "    \n",
    "    sel_span=\"gs_ibl gsc_mp_anchor\"\n",
    "    selet_med=gulu.find_all('span',{'class':sel_span})\n",
    "    \n",
    "    #Inititalise Empty list to store names\n",
    "    \n",
    "    sch_med=[]\n",
    "    \n",
    "    #from marquee harvest movie names using a simple text search in selection\n",
    "    \n",
    "    for pa in selet_med:\n",
    "        \n",
    "        sch_med.append(pa.text)\n",
    "    \n",
    "    #return the Indian movie names\n",
    "        \n",
    "    return sch_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "ea4e16e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['667', '780', '614', '627', '635']"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_scholar_med=scholar_med(gulu)\n",
    "len(google_scholar_med)\n",
    "google_scholar_med[:5]#--------------------displaying only first five ranks to reduce clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fe5a72",
   "metadata": {},
   "source": [
    "<h3><font color='green'> NEXT: Step7.</font> Structuring data into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "d5505d3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rank': ['1.',\n",
       "  '2.',\n",
       "  '3.',\n",
       "  '4.',\n",
       "  '5.',\n",
       "  '6.',\n",
       "  '7.',\n",
       "  '8.',\n",
       "  '9.',\n",
       "  '10.',\n",
       "  '11.',\n",
       "  '12.',\n",
       "  '13.',\n",
       "  '14.',\n",
       "  '15.',\n",
       "  '16.',\n",
       "  '17.',\n",
       "  '18.',\n",
       "  '19.',\n",
       "  '20.',\n",
       "  '21.',\n",
       "  '22.',\n",
       "  '23.',\n",
       "  '24.',\n",
       "  '25.',\n",
       "  '26.',\n",
       "  '27.',\n",
       "  '28.',\n",
       "  '29.',\n",
       "  '30.',\n",
       "  '31.',\n",
       "  '32.',\n",
       "  '33.',\n",
       "  '34.',\n",
       "  '35.',\n",
       "  '36.',\n",
       "  '37.',\n",
       "  '38.',\n",
       "  '39.',\n",
       "  '40.',\n",
       "  '41.',\n",
       "  '42.',\n",
       "  '43.',\n",
       "  '44.',\n",
       "  '45.',\n",
       "  '46.',\n",
       "  '47.',\n",
       "  '48.',\n",
       "  '49.',\n",
       "  '50.',\n",
       "  '51.',\n",
       "  '52.',\n",
       "  '53.',\n",
       "  '54.',\n",
       "  '55.',\n",
       "  '56.',\n",
       "  '57.',\n",
       "  '58.',\n",
       "  '59.',\n",
       "  '60.',\n",
       "  '61.',\n",
       "  '62.',\n",
       "  '63.',\n",
       "  '64.',\n",
       "  '65.',\n",
       "  '66.',\n",
       "  '67.',\n",
       "  '68.',\n",
       "  '69.',\n",
       "  '70.',\n",
       "  '71.',\n",
       "  '72.',\n",
       "  '73.',\n",
       "  '74.',\n",
       "  '75.',\n",
       "  '76.',\n",
       "  '77.',\n",
       "  '78.',\n",
       "  '79.',\n",
       "  '80.',\n",
       "  '81.',\n",
       "  '82.',\n",
       "  '83.',\n",
       "  '84.',\n",
       "  '85.',\n",
       "  '86.',\n",
       "  '87.',\n",
       "  '88.',\n",
       "  '89.',\n",
       "  '90.',\n",
       "  '91.',\n",
       "  '92.',\n",
       "  '93.',\n",
       "  '94.',\n",
       "  '95.',\n",
       "  '96.',\n",
       "  '97.',\n",
       "  '98.',\n",
       "  '99.',\n",
       "  '100.'],\n",
       " 'Publication': ['Nature',\n",
       "  'The New England Journal of Medicine',\n",
       "  'Science',\n",
       "  'IEEE/CVF Conference on Computer Vision and Pattern Recognition',\n",
       "  'The Lancet',\n",
       "  'Advanced Materials',\n",
       "  'Nature Communications',\n",
       "  'Cell',\n",
       "  'International Conference on Learning Representations',\n",
       "  'Neural Information Processing Systems',\n",
       "  'JAMA',\n",
       "  'Chemical Reviews',\n",
       "  'Proceedings of the National Academy of Sciences',\n",
       "  'Angewandte Chemie',\n",
       "  'Chemical Society Reviews',\n",
       "  'Journal of the American Chemical Society',\n",
       "  'IEEE/CVF International Conference on Computer Vision',\n",
       "  'Nucleic Acids Research',\n",
       "  'International Conference on Machine Learning',\n",
       "  'Nature Medicine',\n",
       "  'Renewable and Sustainable Energy Reviews',\n",
       "  'Science of The Total Environment',\n",
       "  'Advanced Energy Materials',\n",
       "  'Journal of Clinical Oncology',\n",
       "  'ACS Nano',\n",
       "  'Journal of Cleaner Production',\n",
       "  'Advanced Functional Materials',\n",
       "  'Physical Review Letters',\n",
       "  'Scientific Reports',\n",
       "  'The Lancet Oncology',\n",
       "  'Energy & Environmental Science',\n",
       "  'IEEE Access',\n",
       "  'PLoS ONE',\n",
       "  'Science Advances',\n",
       "  'Journal of the American College of Cardiology',\n",
       "  'Applied Catalysis B: Environmental',\n",
       "  'Nature Genetics',\n",
       "  'BMJ',\n",
       "  'Circulation',\n",
       "  'European Conference on Computer Vision',\n",
       "  'International Journal of Molecular Sciences',\n",
       "  'Nature Materials',\n",
       "  'Chemical engineering journal',\n",
       "  'AAAI Conference on Artificial Intelligence',\n",
       "  'Journal of Materials Chemistry A',\n",
       "  'ACS Applied Materials & Interfaces',\n",
       "  'Nature Biotechnology',\n",
       "  'The Lancet Infectious Diseases',\n",
       "  'Frontiers in Immunology',\n",
       "  'Applied Energy',\n",
       "  'Nano Energy',\n",
       "  'Nature Energy',\n",
       "  'Meeting of the Association for Computational Linguistics (ACL)',\n",
       "  'The Astrophysical Journal',\n",
       "  'Gastroenterology',\n",
       "  'Nature Methods',\n",
       "  'IEEE Transactions on Pattern Analysis and Machine Intelligence',\n",
       "  'Cochrane Database of Systematic Reviews',\n",
       "  'Blood',\n",
       "  'Neuron',\n",
       "  'Nano Letters',\n",
       "  'Morbidity and Mortality Weekly Report',\n",
       "  'European Heart Journal',\n",
       "  'Nature Nanotechnology',\n",
       "  'ACS Catalysis',\n",
       "  'Nature Neuroscience',\n",
       "  'American Economic Review',\n",
       "  'Journal of High Energy Physics',\n",
       "  'IEEE Communications Surveys & Tutorials',\n",
       "  'Annals of Oncology',\n",
       "  'Nutrients',\n",
       "  'Accounts of Chemical Research',\n",
       "  'Immunity',\n",
       "  'Environmental Science & Technology',\n",
       "  'Nature Reviews. Molecular Cell Biology',\n",
       "  'Gut',\n",
       "  'Physical Review D',\n",
       "  'ACS Energy Letters',\n",
       "  'Monthly Notices of the Royal Astronomical Society',\n",
       "  'Conference on Empirical Methods in Natural Language Processing (EMNLP)',\n",
       "  'Clinical Infectious Diseases',\n",
       "  'Cell Metabolism',\n",
       "  'Nature Reviews Immunology',\n",
       "  'Joule',\n",
       "  'Nature Photonics',\n",
       "  'International Journal of Environmental Research and Public Health',\n",
       "  'Environmental Pollution',\n",
       "  'Computers in Human Behavior',\n",
       "  'Frontiers in Microbiology',\n",
       "  'Nature Physics',\n",
       "  'Small',\n",
       "  'Cell Reports',\n",
       "  'Molecular Cell',\n",
       "  'Clinical Cancer Research',\n",
       "  'Bioresource Technology',\n",
       "  'Journal of Business Research',\n",
       "  'Molecular Cancer',\n",
       "  'Sensors',\n",
       "  'Nature Climate Change',\n",
       "  'IEEE Internet of Things Journal'],\n",
       " 'H5-Index': ['444',\n",
       "  '667',\n",
       "  '432',\n",
       "  '780',\n",
       "  '401',\n",
       "  '614',\n",
       "  '389',\n",
       "  '627',\n",
       "  '354',\n",
       "  '635',\n",
       "  '312',\n",
       "  '418',\n",
       "  '307',\n",
       "  '428',\n",
       "  '300',\n",
       "  '505',\n",
       "  '286',\n",
       "  '533',\n",
       "  '278',\n",
       "  '436',\n",
       "  '267',\n",
       "  '425',\n",
       "  '265',\n",
       "  '444',\n",
       "  '256',\n",
       "  '364',\n",
       "  '245',\n",
       "  '332',\n",
       "  '244',\n",
       "  '386',\n",
       "  '242',\n",
       "  '344',\n",
       "  '239',\n",
       "  '415',\n",
       "  '238',\n",
       "  '550',\n",
       "  '237',\n",
       "  '421',\n",
       "  '235',\n",
       "  '389',\n",
       "  '227',\n",
       "  '324',\n",
       "  '225',\n",
       "  '311',\n",
       "  '220',\n",
       "  '300',\n",
       "  '213',\n",
       "  '315',\n",
       "  '211',\n",
       "  '277',\n",
       "  '211',\n",
       "  '273',\n",
       "  '210',\n",
       "  '280',\n",
       "  '207',\n",
       "  '294',\n",
       "  '206',\n",
       "  '274',\n",
       "  '202',\n",
       "  '329',\n",
       "  '202',\n",
       "  '290',\n",
       "  '200',\n",
       "  '303',\n",
       "  '198',\n",
       "  '278',\n",
       "  '197',\n",
       "  '294',\n",
       "  '195',\n",
       "  '276',\n",
       "  '192',\n",
       "  '246',\n",
       "  '191',\n",
       "  '297',\n",
       "  '190',\n",
       "  '307',\n",
       "  '189',\n",
       "  '301',\n",
       "  '186',\n",
       "  '321',\n",
       "  '183',\n",
       "  '253',\n",
       "  '181',\n",
       "  '265',\n",
       "  '181',\n",
       "  '224',\n",
       "  '180',\n",
       "  '296',\n",
       "  '178',\n",
       "  '220',\n",
       "  '177',\n",
       "  '223',\n",
       "  '175',\n",
       "  '315',\n",
       "  '173',\n",
       "  '296',\n",
       "  '173',\n",
       "  '228',\n",
       "  '173',\n",
       "  '217'],\n",
       " 'H5-Median': ['667',\n",
       "  '780',\n",
       "  '614',\n",
       "  '627',\n",
       "  '635',\n",
       "  '418',\n",
       "  '428',\n",
       "  '505',\n",
       "  '533',\n",
       "  '436',\n",
       "  '425',\n",
       "  '444',\n",
       "  '364',\n",
       "  '332',\n",
       "  '386',\n",
       "  '344',\n",
       "  '415',\n",
       "  '550',\n",
       "  '421',\n",
       "  '389',\n",
       "  '324',\n",
       "  '311',\n",
       "  '300',\n",
       "  '315',\n",
       "  '277',\n",
       "  '273',\n",
       "  '280',\n",
       "  '294',\n",
       "  '274',\n",
       "  '329',\n",
       "  '290',\n",
       "  '303',\n",
       "  '278',\n",
       "  '294',\n",
       "  '276',\n",
       "  '246',\n",
       "  '297',\n",
       "  '307',\n",
       "  '301',\n",
       "  '321',\n",
       "  '253',\n",
       "  '265',\n",
       "  '224',\n",
       "  '296',\n",
       "  '220',\n",
       "  '223',\n",
       "  '315',\n",
       "  '296',\n",
       "  '228',\n",
       "  '217',\n",
       "  '232',\n",
       "  '314',\n",
       "  '304',\n",
       "  '234',\n",
       "  '254',\n",
       "  '296',\n",
       "  '293',\n",
       "  '243',\n",
       "  '229',\n",
       "  '231',\n",
       "  '207',\n",
       "  '302',\n",
       "  '265',\n",
       "  '264',\n",
       "  '220',\n",
       "  '248',\n",
       "  '263',\n",
       "  '220',\n",
       "  '304',\n",
       "  '243',\n",
       "  '214',\n",
       "  '211',\n",
       "  '242',\n",
       "  '214',\n",
       "  '340',\n",
       "  '235',\n",
       "  '217',\n",
       "  '212',\n",
       "  '194',\n",
       "  '249',\n",
       "  '278',\n",
       "  '211',\n",
       "  '292',\n",
       "  '233',\n",
       "  '228',\n",
       "  '225',\n",
       "  '222',\n",
       "  '214',\n",
       "  '225',\n",
       "  '222',\n",
       "  '196',\n",
       "  '205',\n",
       "  '202',\n",
       "  '201',\n",
       "  '190',\n",
       "  '233',\n",
       "  '209',\n",
       "  '201',\n",
       "  '228',\n",
       "  '212']}"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#composing all the lists in  Q10 into a dictionary. \n",
    "g_Scholar_page=dict()\n",
    "g_Scholar_page={'Rank':google_scholar_rank,'Publication':google_scholar_pub,'H5-Index':google_scholar_h5,'H5-Median':google_scholar_med}\n",
    "g_Scholar_page\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc57f7",
   "metadata": {},
   "source": [
    "<h3><font color='green'> FINALLY: Step8.</font> Structuring data as a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "4baad09d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>H5-Index</th>\n",
       "      <th>H5-Median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>667</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>432</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>780</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>401</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>296</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>173</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>228</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>173</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>217</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank                                        Publication H5-Index  \\\n",
       "1      1.                                             Nature      444   \n",
       "2      2.                The New England Journal of Medicine      667   \n",
       "3      3.                                            Science      432   \n",
       "4      4.  IEEE/CVF Conference on Computer Vision and Pat...      780   \n",
       "5      5.                                         The Lancet      401   \n",
       "..    ...                                                ...      ...   \n",
       "96    96.                       Journal of Business Research      296   \n",
       "97    97.                                   Molecular Cancer      173   \n",
       "98    98.                                            Sensors      228   \n",
       "99    99.                              Nature Climate Change      173   \n",
       "100  100.                    IEEE Internet of Things Journal      217   \n",
       "\n",
       "    H5-Median  \n",
       "1         667  \n",
       "2         780  \n",
       "3         614  \n",
       "4         627  \n",
       "5         635  \n",
       "..        ...  \n",
       "96        233  \n",
       "97        209  \n",
       "98        201  \n",
       "99        228  \n",
       "100       212  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying as Dataframe.\n",
    "g_Scholar_page_df=pd.DataFrame(g_Scholar_page)\n",
    "g_Scholar_page_df.index = np.arange(1,len(g_Scholar_page_df)+1)\n",
    "print(\"Compilation\")\n",
    "print()\n",
    "g_Scholar_page_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7538cf4e",
   "metadata": {},
   "source": [
    "<h2><center><font color ='red'>SUCCESS!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9755ab74",
   "metadata": {},
   "source": [
    "<h2><font color='red'>********************************************************************************************************* </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd0f2ce",
   "metadata": {},
   "source": [
    "<h2><center><font color ='red'>End of File"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
