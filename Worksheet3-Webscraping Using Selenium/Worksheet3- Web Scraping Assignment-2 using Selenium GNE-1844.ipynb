{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "969e512d",
   "metadata": {},
   "source": [
    "<h2 align='center'><font color='maroon'>Worksheet-3 | GNE- 1844</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f72f4",
   "metadata": {},
   "source": [
    "<h1 align='center'><font color='red'>WEB SCRAPING – ASSIGNMENT 2</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fef6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all required libraries for all the questions.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00377264",
   "metadata": {},
   "source": [
    "<h3><font color='green'><b>Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.</h3><h4><font color='green'>\n",
    "<br>This task will be done in following steps:\n",
    "<br>1. First get the webpage https://www.naukri.com/\n",
    "<br>2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "<br>3. Then click the search button.\n",
    "<br>4. Then scrape the data for the first 10 jobs results you get.\n",
    "<br>5. Finally create a dataframe of the scraped data.\n",
    "<br>Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "94807a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero=webdriver.Chrome(r\"C:\\Users\\Glenn\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb476ea",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q1.1 Opening the website in the automated window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "849f9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b000aa7",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q1.2 Automating the search fields to show results for \"Data Analyst\" in \"Bangalore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "86d130b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "designition=hero.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designition.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c24dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=hero.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf67b7f",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q1.3 Automating the click on submit to query in the search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8dfadbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=hero.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d068a1c5",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q1.4 Scraping the Data from the results in the automated window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e1ca093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising Empty Lists to store the data.\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "package=[]\n",
    "skills=[]\n",
    "comments=[]\n",
    "url=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f6895a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags= hero.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]') \n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "loc_tags=hero.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in loc_tags[0:10]:\n",
    "    loc=i.text\n",
    "    job_location.append(loc)\n",
    "\n",
    "company_tags=hero.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "experience_tags=hero.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    \n",
    "pack=hero.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 \"]')\n",
    "for i in pack[0:10]:\n",
    "    age=i.text\n",
    "    package.append(age)\n",
    "    \n",
    "skill=hero.find_elements(By.XPATH,'//ul[@class=\"tags has-description\"]')\n",
    "for i in skill[0:10]:\n",
    "    set=i.text\n",
    "    skills.append(set)  \n",
    "    \n",
    "comm=hero.find_elements(By.XPATH,'//div[@class=\"job-description fs12 grey-text\"]')\n",
    "for i in comm[0:10]:\n",
    "    ments=i.text\n",
    "    comments.append(ments)\n",
    "    \n",
    "\n",
    "urls= hero.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]') \n",
    "for i in urls[0:10]:\n",
    "    links=i.get_attribute('href')\n",
    "    url.append(links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d37f2575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#checking for the length of each list, to ensure it has captured all the necessary data\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required),len(url),len(comments),len(package),len(skills))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bbbfd0",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q1.5 Displaying all the captured data as a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "20630bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "      <th>Skillset Required</th>\n",
       "      <th>Comments</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Business Analysis\\nIT Skills\\nOracle\\nTableau\\...</td>\n",
       "      <td>Willing / able to work staggered shifts to all...</td>\n",
       "      <td>https://www.naukri.com/job-listings-contractua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - Decision Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jana Small Finance Bank</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Data Analytics\\nExcel\\nSAS\\nSQL</td>\n",
       "      <td>Masters in Statistics, Economics, Engineering ...</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Domlur)</td>\n",
       "      <td>KrazyBee</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Python\\nSQL</td>\n",
       "      <td>Proficient at writing queries / reports and pr...</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Augie Pets India Pvt limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Market analysis\\nUsage\\nExcel\\nData collection...</td>\n",
       "      <td>Responsible for co-ordinating data with other ...</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Novel Office</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>MIS\\nData Analysis\\nCommunication Skills\\nMont...</td>\n",
       "      <td>Good communication &amp; comprehending skills3 Yea...</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BYJU'S DBEL : Sr Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>BYJUS</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>data analysis\\ndata mining\\nmachine learning\\n...</td>\n",
       "      <td>Experience in using statistical analysis for p...</td>\n",
       "      <td>https://www.naukri.com/job-listings-byju-s-dbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SR. Data Analyst- SME- Pharma and Healthcare</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>CHRYSELYS</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Python Data Analytics\\nData Analysis\\nSQL Data...</td>\n",
       "      <td>Bachelors or masters degree required in any di...</td>\n",
       "      <td>https://www.naukri.com/job-listings-sr-data-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>Botree Software</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Power BI\\nData Visualization\\nquantitative ana...</td>\n",
       "      <td>In this role, you are required to analyze a la...</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Varite</td>\n",
       "      <td>8-11 Yrs</td>\n",
       "      <td>Data analysis\\nmetadata\\nData management\\nMach...</td>\n",
       "      <td>Essential Functions: - Build Machine learning ...</td>\n",
       "      <td>https://www.naukri.com/job-listings-business-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst - KPO</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram, Gurgaon...</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "      <td>Data Modeling\\nSQL\\nBFSI\\nData Management\\nCon...</td>\n",
       "      <td>Must understand data models: Technically able ...</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Contractual Hiring For Top MNC || Business Dat...   \n",
       "1                    Data Analyst - Decision Science   \n",
       "2                                Senior Data Analyst   \n",
       "3                                       Data Analyst   \n",
       "4                                       Data Analyst   \n",
       "5                      BYJU'S DBEL : Sr Data Analyst   \n",
       "6       SR. Data Analyst- SME- Pharma and Healthcare   \n",
       "7                                       Data Analyst   \n",
       "8                              Business Data Analyst   \n",
       "9                          Senior Data Analyst - KPO   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                        Bangalore/Bengaluru(Domlur)   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "7                       Bangalore/Bengaluru, Chennai   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9  Bangalore/Bengaluru, Gurgaon/Gurugram, Gurgaon...   \n",
       "\n",
       "                   Company Name Experience Required  \\\n",
       "0                     TeamLease             5-8 Yrs   \n",
       "1       Jana Small Finance Bank             3-8 Yrs   \n",
       "2                      KrazyBee             3-5 Yrs   \n",
       "3  Augie Pets India Pvt limited             0-3 Yrs   \n",
       "4                  Novel Office             0-3 Yrs   \n",
       "5                         BYJUS             3-7 Yrs   \n",
       "6                     CHRYSELYS             2-6 Yrs   \n",
       "7               Botree Software             1-5 Yrs   \n",
       "8                        Varite            8-11 Yrs   \n",
       "9     Huquo Consulting Pvt. Ltd            7-12 Yrs   \n",
       "\n",
       "                                   Skillset Required  \\\n",
       "0  Business Analysis\\nIT Skills\\nOracle\\nTableau\\...   \n",
       "1                    Data Analytics\\nExcel\\nSAS\\nSQL   \n",
       "2                                        Python\\nSQL   \n",
       "3  Market analysis\\nUsage\\nExcel\\nData collection...   \n",
       "4  MIS\\nData Analysis\\nCommunication Skills\\nMont...   \n",
       "5  data analysis\\ndata mining\\nmachine learning\\n...   \n",
       "6  Python Data Analytics\\nData Analysis\\nSQL Data...   \n",
       "7  Power BI\\nData Visualization\\nquantitative ana...   \n",
       "8  Data analysis\\nmetadata\\nData management\\nMach...   \n",
       "9  Data Modeling\\nSQL\\nBFSI\\nData Management\\nCon...   \n",
       "\n",
       "                                            Comments  \\\n",
       "0  Willing / able to work staggered shifts to all...   \n",
       "1  Masters in Statistics, Economics, Engineering ...   \n",
       "2  Proficient at writing queries / reports and pr...   \n",
       "3  Responsible for co-ordinating data with other ...   \n",
       "4  Good communication & comprehending skills3 Yea...   \n",
       "5  Experience in using statistical analysis for p...   \n",
       "6  Bachelors or masters degree required in any di...   \n",
       "7  In this role, you are required to analyze a la...   \n",
       "8  Essential Functions: - Build Machine learning ...   \n",
       "9  Must understand data models: Technically able ...   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.naukri.com/job-listings-contractua...  \n",
       "1  https://www.naukri.com/job-listings-data-analy...  \n",
       "2  https://www.naukri.com/job-listings-senior-dat...  \n",
       "3  https://www.naukri.com/job-listings-data-analy...  \n",
       "4  https://www.naukri.com/job-listings-data-analy...  \n",
       "5  https://www.naukri.com/job-listings-byju-s-dbe...  \n",
       "6  https://www.naukri.com/job-listings-sr-data-an...  \n",
       "7  https://www.naukri.com/job-listings-data-analy...  \n",
       "8  https://www.naukri.com/job-listings-business-d...  \n",
       "9  https://www.naukri.com/job-listings-senior-dat...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Job Title':job_title,'Job Location':job_location, 'Company Name':company_name, 'Experience Required':experience_required,'Skillset Required':skills,'Comments':comments,'URL':url})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce70f959",
   "metadata": {},
   "source": [
    "<h3><font color='green'><b>Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. </h3><h4><font color='green'>\n",
    "    You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "<br>This task will be done in following steps:\n",
    "<br>1. First get the webpage https://www.naukri.com/\n",
    "<br>2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "<br>3. Then click the search button.\n",
    "<br>4. Then scrape the data for the first 10 jobs results you get.\n",
    "<br>5. Finally create a dataframe of the scraped data.\n",
    "<br>Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eff883da",
   "metadata": {},
   "outputs": [],
   "source": [
    "naukri=webdriver.Chrome(r\"C:\\Users\\Glenn\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eceac8",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q2.1 Opening the website in the automated window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47b275af",
   "metadata": {},
   "outputs": [],
   "source": [
    "naukri.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3bc468",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q2.2 Automating the search fields to show results for \"Data Scientist\" in \"Bangalore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc0ea7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "designition2=naukri.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designition2.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2a0b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "location2=naukri.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location2.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca58a2a7",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q2.3 Automating the click on submit to query in the search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7eacecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search2=naukri.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search2.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723ec037",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q2.4 Scraping the Data from the results in the automated window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d13f8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising Empty Lists to store the data.\n",
    "j_title=[]\n",
    "j_location=[]\n",
    "c_name=[]\n",
    "exp_required=[]\n",
    "pkge=[]\n",
    "skillset=[]\n",
    "description=[]\n",
    "url2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62982e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_tags= naukri.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]') \n",
    "for i in t_tags[0:10]:\n",
    "    ttle=i.text\n",
    "    j_title.append(ttle)\n",
    "\n",
    "l_tags=naukri.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in l_tags[0:10]:\n",
    "    lic=i.text\n",
    "    j_location.append(lic)\n",
    "\n",
    "c_tags=naukri.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in c_tags[0:10]:\n",
    "    cmpny=i.text\n",
    "    c_name.append(cmpny)\n",
    "    \n",
    "exp_tags=naukri.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in exp_tags[0:10]:\n",
    "    exper=i.text\n",
    "    exp_required.append(exper)\n",
    "    \n",
    "pk=naukri.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 \"]')\n",
    "for i in pk[0:10]:\n",
    "    cage=i.text\n",
    "    pkge.append(cage)\n",
    "    \n",
    "ski=naukri.find_elements(By.XPATH,'//ul[@class=\"tags has-description\"]')\n",
    "for i in ski[0:10]:\n",
    "    st=i.text\n",
    "    skillset.append(st)  \n",
    "    \n",
    "desc=naukri.find_elements(By.XPATH,'//div[@class=\"job-description fs12 grey-text\"]')\n",
    "for i in desc[0:10]:\n",
    "    tion=i.text\n",
    "    description.append(tion)\n",
    "    \n",
    "\n",
    "urll= naukri.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]') \n",
    "for i in urll[0:10]:\n",
    "    lnks=i.get_attribute('href')\n",
    "    url2.append(lnks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8cba61e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#checking for the length of each list, to ensure it has captured all the necessary data\n",
    "print(len(j_title),len(j_location),len(c_name),len(exp_required),len(url2),len(description),len(pkge),len(skillset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c852a967",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q2.5 Displaying all the captured data as a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "44fa2859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "      <th>Skillset Required</th>\n",
       "      <th>Comments</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Opportunity on Data Science_ Python with T...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>deep learning\\npython\\ndata analysis\\ndata sci...</td>\n",
       "      <td>Greetings of the Day!!!We have an opportunity ...</td>\n",
       "      <td>https://www.naukri.com/job-listings-opportunit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Data Science\\nNLP\\nMachine Learning\\nDeep Lear...</td>\n",
       "      <td>Work with OMICs, image, med device and RWE dat...</td>\n",
       "      <td>https://www.naukri.com/job-listings-assistant-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bfsi\\nConsulting\\nMachine learning\\nOpen sourc...</td>\n",
       "      <td>This role will be a part of Survey Solutions a...</td>\n",
       "      <td>https://www.naukri.com/job-listings-analystics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Data Science\\nArtificial Intelligence\\nMachine...</td>\n",
       "      <td>Dear All, We have urgent requirement for Data ...</td>\n",
       "      <td>https://www.naukri.com/job-listings-hiring-for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - A.P. Maersk</td>\n",
       "      <td>Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "      <td>Maersk</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Celonis\\nPower Bi\\nProcess Mining\\npython\\nR\\n...</td>\n",
       "      <td>We Offer:This position offers the unique oppor...</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>10-15 Yrs</td>\n",
       "      <td>data science\\nmachine learning\\nNLP\\ndocumenta...</td>\n",
       "      <td>looking for a Principal Machine Learning Scien...</td>\n",
       "      <td>https://www.naukri.com/job-listings-principal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist / Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Mindtree</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "      <td>deep learning\\npython\\nCloud Services\\ncompute...</td>\n",
       "      <td>Job Title: Data Scientist/ Senior Data Scienti...</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "      <td>deep learning\\nLinux\\ndata science\\nAnalytical...</td>\n",
       "      <td>10 years experience in data science and MLAcad...</td>\n",
       "      <td>https://www.naukri.com/job-listings-lead-ml-sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tcs Hiring For Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai, Mumbai (All Areas)</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>python\\nmachine learning\\nPower Bi\\nTableau\\nN...</td>\n",
       "      <td>Programming exp in Python, Spark and Experienc...</td>\n",
       "      <td>https://www.naukri.com/job-listings-tcs-hiring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - II</td>\n",
       "      <td>Bangalore/Bengaluru, India, Mumbai (All Areas)</td>\n",
       "      <td>SMARTPADDLE TECHNOLOGY PVT. LTD.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Python\\nData Analytics\\nJava\\nIT Skills\\nBusin...</td>\n",
       "      <td>Have experience with working and deploying sta...</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Job Opportunity on Data Science_ Python with T...   \n",
       "1                   Assistant Manager - Data Science   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "4                       Data Scientist - A.P. Maersk   \n",
       "5                           Principal Data Scientist   \n",
       "6             Data Scientist / Senior Data Scientist   \n",
       "7                                  Lead ML Scientist   \n",
       "8                      Tcs Hiring For Data Scientist   \n",
       "9                                Data Scientist - II   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "1                  Bangalore/Bengaluru, Mumbai, Pune   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "3  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "4            Bangalore/Bengaluru\\n(WFH during Covid)   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                 Bangalore/Bengaluru, Pune, Chennai   \n",
       "7                        Bangalore/Bengaluru, Mumbai   \n",
       "8   Bangalore/Bengaluru, Chennai, Mumbai (All Areas)   \n",
       "9     Bangalore/Bengaluru, India, Mumbai (All Areas)   \n",
       "\n",
       "                                  Company Name Experience Required  \\\n",
       "0                                Tech Mahindra             4-9 Yrs   \n",
       "1                                   CitiusTech             5-9 Yrs   \n",
       "2                                    Accenture             6-8 Yrs   \n",
       "3  NTT DATA Business Solutions Private Limited             4-9 Yrs   \n",
       "4                                       Maersk            5-10 Yrs   \n",
       "5                                        Optum           10-15 Yrs   \n",
       "6                                     Mindtree            7-12 Yrs   \n",
       "7                            Fractal Analytics            6-10 Yrs   \n",
       "8              TATA CONSULTANCY SERVICES (TCS)             3-8 Yrs   \n",
       "9             SMARTPADDLE TECHNOLOGY PVT. LTD.             3-6 Yrs   \n",
       "\n",
       "                                   Skillset Required  \\\n",
       "0  deep learning\\npython\\ndata analysis\\ndata sci...   \n",
       "1  Data Science\\nNLP\\nMachine Learning\\nDeep Lear...   \n",
       "2  Bfsi\\nConsulting\\nMachine learning\\nOpen sourc...   \n",
       "3  Data Science\\nArtificial Intelligence\\nMachine...   \n",
       "4  Celonis\\nPower Bi\\nProcess Mining\\npython\\nR\\n...   \n",
       "5  data science\\nmachine learning\\nNLP\\ndocumenta...   \n",
       "6  deep learning\\npython\\nCloud Services\\ncompute...   \n",
       "7  deep learning\\nLinux\\ndata science\\nAnalytical...   \n",
       "8  python\\nmachine learning\\nPower Bi\\nTableau\\nN...   \n",
       "9  Python\\nData Analytics\\nJava\\nIT Skills\\nBusin...   \n",
       "\n",
       "                                            Comments  \\\n",
       "0  Greetings of the Day!!!We have an opportunity ...   \n",
       "1  Work with OMICs, image, med device and RWE dat...   \n",
       "2  This role will be a part of Survey Solutions a...   \n",
       "3  Dear All, We have urgent requirement for Data ...   \n",
       "4  We Offer:This position offers the unique oppor...   \n",
       "5  looking for a Principal Machine Learning Scien...   \n",
       "6  Job Title: Data Scientist/ Senior Data Scienti...   \n",
       "7  10 years experience in data science and MLAcad...   \n",
       "8  Programming exp in Python, Spark and Experienc...   \n",
       "9  Have experience with working and deploying sta...   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.naukri.com/job-listings-opportunit...  \n",
       "1  https://www.naukri.com/job-listings-assistant-...  \n",
       "2  https://www.naukri.com/job-listings-analystics...  \n",
       "3  https://www.naukri.com/job-listings-hiring-for...  \n",
       "4  https://www.naukri.com/job-listings-data-scien...  \n",
       "5  https://www.naukri.com/job-listings-principal-...  \n",
       "6  https://www.naukri.com/job-listings-data-scien...  \n",
       "7  https://www.naukri.com/job-listings-lead-ml-sc...  \n",
       "8  https://www.naukri.com/job-listings-tcs-hiring...  \n",
       "9  https://www.naukri.com/job-listings-data-scien...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.DataFrame({'Job Title':j_title,'Job Location':j_location, 'Company Name':c_name, 'Experience Required':exp_required,'Skillset Required':skillset,'Comments':description,'URL':url2})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d512a9b1",
   "metadata": {},
   "source": [
    "<h3><font color='green'>Q3: In this question you have to scrape data using the filters available on the webpage as shown below:</h3><h4><font color='green'>\n",
    "You have to use the location and salary filter.\n",
    "<br>You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "<br>You have to scrape the job-title, job-location, company name, experience required.\n",
    "<br>The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "<br>The task will be done as shown in the below steps:\n",
    "<br>1. first get the webpage https://www.naukri.com/\n",
    "<br>2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "<br>3. Then click the search button.\n",
    "<br>4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "<br>5. Then scrape the data for the first 10 jobs results you get.\n",
    "<br>6. Finally create a dataframe of the scraped data.\n",
    "<br>Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e975886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtr=webdriver.Chrome(r\"C:\\Users\\Glenn\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b243ef1",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q3.1 Opening the website in the automated window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "36d98ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtr.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6976d6",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q3.2 Automating the search fields to show results for \"Data Scientist\" in \"Bangalore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "673dcfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "designition2=filtr.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designition2.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c52e98",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q3.3 Automating the click on submit to query in the search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "50876f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search2=filtr.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search2.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b1c185",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q3.4 Automating the click on Job location and salary range in filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "697c0067",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc1=filtr.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[5]/div[2]/div[3]/label/i\")\n",
    "loc1.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9dda1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal1=filtr.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/i\")\n",
    "sal1.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e91b94",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q3.4 Scraping the Data from the results in the automated window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bdf9a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising Empty Lists to store the data.\n",
    "job1_title=[]\n",
    "job1_location=[]\n",
    "company1_name=[]\n",
    "exp_req1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b383f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "j1_tags= filtr.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]') \n",
    "for i in j1_tags[0:10]:\n",
    "    ttle=i.text\n",
    "    job1_title.append(ttle)\n",
    "\n",
    "l1_tags=filtr.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]//span')\n",
    "for i in l1_tags[0:10]:\n",
    "    loc=i.text\n",
    "    job1_location.append(loc)\n",
    "    \n",
    "c1_tags=filtr.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in c1_tags[0:10]:\n",
    "    cmpny=i.text\n",
    "    company1_name.append(cmpny)\n",
    "    #//div[@class=\"mt-7 companyInfo subheading lh16\"]\n",
    "    \n",
    "exp_tags1=filtr.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in exp_tags1[0:10]:\n",
    "    exper=i.text\n",
    "    exp_req1.append(exper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cc5827d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#checking for the length of each list, to ensure it has captured all the necessary data\n",
    "print(len(job1_title),len(job1_location),len(company1_name),len(exp_req1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc9ac41",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q3.5 Displaying all the captured data as a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4b7745d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist / Chat-bot Developer</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Predictive Analytics</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Noida, Mumbai, Chandigarh, Hyderabad/Secundera...</td>\n",
       "      <td>SECUREKLOUD TECHNOLOGIES</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>4i Odc</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jr. Data Scientist</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Dataflow</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Urgent Hiring- Expertise in Data Scientist in ...</td>\n",
       "      <td>Delhi / NCR, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>CLARITY CONSULTING</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                    DigitalBCG GAMMA Data Scientist   \n",
       "1                Data Scientist / Chat-bot Developer   \n",
       "2                                Lead Data Scientist   \n",
       "3              Data Scientist - Predictive Analytics   \n",
       "4         Data Scientist For Healthcare Product team   \n",
       "5                                     Data Scientist   \n",
       "6                  Data Scientist - Engine Algorithm   \n",
       "7                                 Jr. Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9  Urgent Hiring- Expertise in Data Scientist in ...   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                     New Delhi, Bangalore/Bengaluru   \n",
       "1  New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...   \n",
       "2                             Noida(Sector-59 Noida)   \n",
       "3                                 (WFH during Covid)   \n",
       "4  Noida, Mumbai, Chandigarh, Hyderabad/Secundera...   \n",
       "5          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "6                                              Noida   \n",
       "7  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "8                                              Noida   \n",
       "9             Delhi / NCR, Pune, Bangalore/Bengaluru   \n",
       "\n",
       "                              Company Name Experience Required  \n",
       "0                  Boston Consulting Group             2-5 Yrs  \n",
       "1                             Big Seo Buzz             3-7 Yrs  \n",
       "2                  R Systems International            7-10 Yrs  \n",
       "3                             Confidential             1-6 Yrs  \n",
       "4                 SECUREKLOUD TECHNOLOGIES             2-7 Yrs  \n",
       "5                                   4i Odc             2-4 Yrs  \n",
       "6                             Primo Hiring             1-3 Yrs  \n",
       "7                                 Dataflow             2-5 Yrs  \n",
       "8  Mount Talent Consulting Private Limited             2-4 Yrs  \n",
       "9                       CLARITY CONSULTING             3-8 Yrs  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.DataFrame({'Job Title':job1_title,'Job Location':job1_location, 'Company Name':company1_name, 'Experience Required':exp_req1})\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802633cb",
   "metadata": {},
   "source": [
    "<h3><font color='green'>Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:</h3>\n",
    "<h4><font color='green'>\n",
    "1. Brand\n",
    "<br>2. Product Description\n",
    "<br>3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "<br>1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "<br>2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "<br>3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "<br>4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "<br>5. Now scrape data from this page as usual\n",
    "<br>6. Repeat this until you get data for 100 sunglasses.\n",
    "<br>Note: That all of the above steps have to be done by coding only and not manually.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3369b8e",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q4.1 Opening the website in the automated window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "48120cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "web=webdriver.Chrome(r\"C:\\Users\\Glenn\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "31301854",
   "metadata": {},
   "outputs": [],
   "source": [
    "web.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ee54c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "byp=web.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "byp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ead904e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search2=web.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "search2.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "03e7c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "search2=web.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "932ca9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_glasses=[]\n",
    "cost_glasses=[]\n",
    "info_glasses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "92454341",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=3\n",
    "for page4 in range(start,end):\n",
    "    glass=web.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in glass:\n",
    "        brand_glasses.append(i.text)\n",
    "    next_button=web.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "175cea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=3\n",
    "for page4 in range(start,end):\n",
    "    glass_price=web.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in glass_price:\n",
    "        cost_glasses.append(i.text)\n",
    "    next_button=web.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "85dd9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=3\n",
    "for page4 in range(start,end):\n",
    "    info=web.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in info:\n",
    "        info_glasses.append(i.text)\n",
    "    next_button=web.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ce5c682a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brand_glasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8b927e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND</th>\n",
       "      <th>INFORMATION</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Round Sungl...</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Mirrored Aviator Sunglasses (55)</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Round Sun...</td>\n",
       "      <td>₹899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>CRYSTAL CART</td>\n",
       "      <td>Mirrored, Night Vision Oval Sunglasses (Free S...</td>\n",
       "      <td>₹199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (55)</td>\n",
       "      <td>₹719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             BRAND                                        INFORMATION PRICE\n",
       "0           SUNBEE  UV Protection, Polarized, Mirrored Round Sungl...  ₹949\n",
       "1        ROYAL SON                   Mirrored Aviator Sunglasses (55)  ₹999\n",
       "2         Fastrack             UV Protection Wayfarer Sunglasses (56)  ₹264\n",
       "3    VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...  ₹639\n",
       "4   ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...  ₹799\n",
       "..             ...                                                ...   ...\n",
       "95  ROZZETTA CRAFT  by Lenskart Polarized, UV Protection Round Sun...  ₹899\n",
       "96    CRYSTAL CART  Mirrored, Night Vision Oval Sunglasses (Free S...  ₹199\n",
       "97        Fastrack             UV Protection Wayfarer Sunglasses (55)  ₹719\n",
       "98  ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...  ₹499\n",
       "99        Roadster  UV Protection, Gradient Rectangular Sunglasses...  ₹999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.DataFrame({'BRAND':brand_glasses[:100],'INFORMATION':info_glasses[:100],'PRICE':cost_glasses[:100]})\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa5ff77",
   "metadata": {},
   "source": [
    "<h3><font color='green'>Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:</h3><h4><font color='green'>\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "<br>2. Enter “iphone 11” in “Search” field .\n",
    "<br>3. Then click the search button.\n",
    "<br>You will reach to the below shown webpage .\n",
    "<br>As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "<br>1. Rating\n",
    "<br>2. Review summary\n",
    "<br>3. Full review\n",
    "<br>4. You have to scrape this data for first 100 reviews.\n",
    "<br>Note: All the steps required during scraping should be done through code only and not manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc068c4",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q5.1 Opening the website in the automated window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3630335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "web5=webdriver.Chrome(r\"C:\\Users\\Glenn\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1243e6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "web5.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da461b8",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q5.2 Automating the search fields to show results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9d4f7767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bypassing Signin Splash Screen\n",
    "byp5=web5.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "byp5.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f09cb74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search for iphone\n",
    "search5=web5.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "search5.send_keys(\"iphone 11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4262ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click search\n",
    "search5b=web5.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search5b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cf661800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising \n",
    "newtab=[]\n",
    "rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c845a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting link to open in new tab\n",
    "url1= web5.find_elements(By.XPATH,'//a[@class=\"_1fQZEK\"]') \n",
    "for i in url1[0:1]:\n",
    "    lnks=i.get_attribute('href')\n",
    "    newtab.append(lnks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "46e9bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pasting link in new tab\n",
    "str1=''.join([str(elem) for elem in newtab])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ce37c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open new tab in the same window\n",
    "web5.execute_script(\"window.open('');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b9dedd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#switch tabs\n",
    "web5.switch_to.window(web5.window_handles[1])\n",
    "web5.get(str1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f012094",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Q5 Extracting Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e898fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate= web5.find_elements(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[6]/div/div[2]/div[1]/div/div[1]/div/div[1]/div') \n",
    "for i in rate:\n",
    "    ttle=i.text\n",
    "    rating.append(ttle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3068326c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.6★']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0bebd1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_summary=[]\n",
    "stars=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f0ddf814",
   "metadata": {},
   "outputs": [],
   "source": [
    "star= web5.find_elements(By.XPATH,'//li[@class=\"_28Xb_u\"]') \n",
    "for i in star[0:5]:\n",
    "    ttle=i.text\n",
    "    stars.append(ttle)\n",
    "\n",
    "reviews= web5.find_elements(By.XPATH,'//li[@class=\"_28Xb_u\"]') \n",
    "for i in reviews[10:15]:\n",
    "    ttle=i.text\n",
    "    review_summary.append(ttle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3ef6363f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STAR</th>\n",
       "      <th>REVIEWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5★</td>\n",
       "      <td>72,447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4★</td>\n",
       "      <td>13,039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3★</td>\n",
       "      <td>3,081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2★</td>\n",
       "      <td>1,126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1★</td>\n",
       "      <td>3,685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STAR REVIEWS\n",
       "0   5★  72,447\n",
       "1   4★  13,039\n",
       "2   3★   3,081\n",
       "3   2★   1,126\n",
       "4   1★   3,685"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df=pd.DataFrame({\"STAR\":stars,\"REVIEWS\":review_summary})\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4f42f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_reviews=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e71057ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_r= web5.find_elements(By.XPATH,'//div[@class=\"col JOpGWq\"]//a') \n",
    "for i in get_r[:1]:\n",
    "    lnks=i.get_attribute('href')\n",
    "    get_reviews.append(lnks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dc188f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.flipkart.com/apple-iphone-11-white-64-gb/product-reviews/itmfc6a7091eb20b?pid=MOBFWQ6BVWVEH3XE&lid=LSTMOBFWQ6BVWVEH3XEMXQMLO&aid=dc0f2b2d-7619-44cc-b5fc-2fe3e4d453a7&mid=FLIPKART&fid=f6215942-ca9a-42c5-ba64-6b058f6ecda5.MOBFWQ6BVWVEH3XE&an=Camera&cat=Mobile&vert=Handset']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a2861b03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str2=''.join([str(elem) for elem in get_reviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3c9e316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "web5.switch_to.window(web5.window_handles[1])\n",
    "web5.get(str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "687fd221",
   "metadata": {},
   "outputs": [],
   "source": [
    "search5b=web5.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[1]/div[2]/div/div/a[1]\")\n",
    "search5b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0d2c618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_comp_star=[]\n",
    "review_comp_summary=[]\n",
    "review_comp_full=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "86be9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=10\n",
    "for page5b in range(start,end):\n",
    "    reviewsb=web5.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in reviewsb:\n",
    "        review_comp_star.append(i.text)\n",
    "    next_button5=web5.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button5.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3afe50a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=10\n",
    "for page5b in range(start,end):\n",
    "    reviewsb=web5.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in reviewsb:\n",
    "        review_comp_summary.append(i.text)\n",
    "    next_button5=web5.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button5.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "508150a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=10\n",
    "for page5b in range(start,end):\n",
    "    reviewsb=web5.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in reviewsb:\n",
    "        review_comp_full.append(i.text)\n",
    "    next_button5=web5.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button5.click()\n",
    "    time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22f0fca",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Creating Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "312c66c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It is just awesome mobile for this price from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Smooth like butter, camera like fantabulous, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5       Simply awesome   \n",
       "1       5     Perfect product!   \n",
       "2       5  Best in the market!   \n",
       "3       5    Worth every penny   \n",
       "4       5   Highly recommended   \n",
       "..    ...                  ...   \n",
       "95      5     Perfect product!   \n",
       "96      5   Highly recommended   \n",
       "97      5             Terrific   \n",
       "98      5            Wonderful   \n",
       "99      5    Worth every penny   \n",
       "\n",
       "                                          Full Review  \n",
       "0   iphone 11 is a very good phone to buy only if ...  \n",
       "1   It’s a must buy who is looking for an upgrade ...  \n",
       "2   Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "3   It is just awesome mobile for this price from ...  \n",
       "4   Smooth like butter, camera like fantabulous, s...  \n",
       "..                                                ...  \n",
       "95  This is my first iOS phone. I am very happy wi...  \n",
       "96  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "97  i11 is worthy to buy, too much happy with the ...  \n",
       "98  It's my first time to use iOS phone and I am l...  \n",
       "99  So far it’s been an AMAZING experience coming ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=pd.DataFrame({'Rating':review_comp_star,'Review Summary':review_comp_summary,'Full Review':review_comp_full})\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e611c30b",
   "metadata": {},
   "source": [
    "<h3><font color='green'>Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.</h3><h4><font color='green'>\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "<br>1. Brand\n",
    "<br>2. Product Description\n",
    "<br>3. Price\n",
    "<br>As shown in the below image, you have to scrape the tick marked attributes.\n",
    "<br>Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa07023e",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Automating of the browser and webpage to search for desired product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "5068d141",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpkt=webdriver.Chrome(r\"C:\\Users\\Glenn\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "ac6a2007",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpkt.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "33dd1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "byp6=fpkt.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "byp6.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "917bb169",
   "metadata": {},
   "outputs": [],
   "source": [
    "search6=fpkt.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "search6.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fa37b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "search6b=fpkt.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search6b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "61fa76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising lists\n",
    "sneaker_brand=[]\n",
    "sneaker_desc=[]\n",
    "sneaker_disc=[]\n",
    "sneaker_price=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a7e695",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Extraction of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ebe8f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=3\n",
    "for page6 in range(start,end):\n",
    "    reviewsb=fpkt.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in reviewsb:\n",
    "        sneaker_brand.append(i.text)\n",
    "    next_button5=fpkt.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button5.click()\n",
    "    time.sleep(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "bb26f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=3\n",
    "#//div[@id='id-74385'][@class='guest clearfix']\n",
    "\n",
    "#a='//a[@class=\"IRpwTa _2-ICcC\"]''//a[@class=\"IRpwTa\"]'and'//a[@class=\"IRpwTa _2-ICcC\"]'\n",
    "#b='//a[@class=\"IRpwTa\"]'\n",
    "for page6 in range(start,end):\n",
    "    reviewsb=fpkt.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]'and'//a[@class=\"IRpwTa _2-ICcC\"]')\n",
    "    for i in reviewsb:\n",
    "        sneaker_desc.append(i.text)\n",
    "    next_button5=fpkt.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button5.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #unable to put \"verified\" and normal attributes in one list.------redo!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "617c32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=3\n",
    "\n",
    "for page6 in range(start,end):\n",
    "    reviewsb=fpkt.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]//span')\n",
    "    for i in reviewsb:\n",
    "        sneaker_disc.append(i.text)\n",
    "    next_button5=fpkt.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button5.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "6f53efec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sneaker_disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "17474c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=3\n",
    "\n",
    "for page6 in range(start,end):\n",
    "    reviewsb=fpkt.find_elements(By.XPATH,'//div[@class=\"_25b18c\"]')\n",
    "    for i in reviewsb:\n",
    "        sneaker_price.append(i.text.split('₹').pop(1))\n",
    "    next_button5=fpkt.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button5.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "3659cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sneaker_price2 = ['₹ ' + sub for sub in sneaker_price]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e9c057",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Displaying extracted data as Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "9219f461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND</th>\n",
       "      <th>TOTAL DISCOUNT</th>\n",
       "      <th>FINAL PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PORT</td>\n",
       "      <td>85% off</td>\n",
       "      <td>₹ 299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>55% off</td>\n",
       "      <td>₹ 447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sparx</td>\n",
       "      <td>15% off</td>\n",
       "      <td>₹ 709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>77% off</td>\n",
       "      <td>₹ 229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>60% off</td>\n",
       "      <td>₹ 399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Xtoon</td>\n",
       "      <td>70% off</td>\n",
       "      <td>₹ 559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>aadi</td>\n",
       "      <td>68% off</td>\n",
       "      <td>₹ 199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fzzirok</td>\n",
       "      <td>50% off</td>\n",
       "      <td>₹ 389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>82% off</td>\n",
       "      <td>₹ 599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>60% off</td>\n",
       "      <td>₹ 399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BRAND TOTAL DISCOUNT FINAL PRICE\n",
       "0      PORT        85% off       ₹ 299\n",
       "1     BIRDE        55% off       ₹ 447\n",
       "2     Sparx        15% off       ₹ 709\n",
       "3    Layasa        77% off       ₹ 229\n",
       "4    Layasa        60% off       ₹ 399\n",
       "..      ...            ...         ...\n",
       "95    Xtoon        70% off       ₹ 559\n",
       "96     aadi        68% off       ₹ 199\n",
       "97  Fzzirok        50% off       ₹ 389\n",
       "98   BRUTON        82% off       ₹ 599\n",
       "99   Shozie        60% off       ₹ 399\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6=pd.DataFrame({'BRAND':sneaker_brand[:100],'TOTAL DISCOUNT':sneaker_disc[:100],'FINAL PRICE':sneaker_price2[:100]})\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72feb2e2",
   "metadata": {},
   "source": [
    "<h3><font color='green'>Q7: Go to the link - https://www.myntra.com/shoes</h3><h4><font color='green'>\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "<br>And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "<br>description, price of the shoe as shown in the below image.\n",
    "<br>Note: Applying the filter and scraping the data, everything should be done through code only and there\n",
    "should not be any manual step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9191c15a",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Automate launch of web browser and searching for product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "8ce2015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "myn=webdriver.Chrome(r\"C:\\Users\\Glenn\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "4e5ccf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "myn.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "67cd75fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "black7=myn.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/span[1]\")\n",
    "black7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "cc43a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "blackshoe_brand=[]\n",
    "blackshoe_desc=[] \n",
    "blackshoe_price=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f6459",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Extraction of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "f942a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=2\n",
    "\n",
    "for page7 in range(start,end):\n",
    "    reviewsb=myn.find_elements(By.XPATH,'//div[@class=\"product-productMetaInfo\"]//h3')\n",
    "    for i in reviewsb:\n",
    "        blackshoe_brand.append(i.text)\n",
    "    next_button5=myn.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[3]/a')\n",
    "    next_button5.click()\n",
    "    time.sleep(3)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "0963dedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blackshoe_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "23a1712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page1=myn.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[3]/a\")\n",
    "page1.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "026d0867",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=2\n",
    "\n",
    "for page7 in range(start,end):\n",
    "    reviewsb=myn.find_elements(By.XPATH,'//div[@class=\"product-productMetaInfo\"]//h4')\n",
    "    for i in reviewsb:\n",
    "        blackshoe_desc.append(i.text)\n",
    "    next_button5=myn.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[12]/a')\n",
    "    next_button5.click()\n",
    "    time.sleep(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "145e9455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Men Rep Flex-1 Training Shoes',\n",
       " '',\n",
       " 'Embellished Velvet Wedge Sandals',\n",
       " '',\n",
       " 'Men ENIGMA Running Shoes']"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blackshoe_desc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "e32b0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [i for i in blackshoe_desc if i != '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "e90f861b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Men Rep Flex-1 Training Shoes',\n",
       " 'Embellished Velvet Wedge Sandals',\n",
       " 'Men ENIGMA Running Shoes',\n",
       " 'Women Fly Sneakers',\n",
       " 'Kids Revolution 4 Running']"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "9cfdb482",
   "metadata": {},
   "outputs": [],
   "source": [
    "page1=myn.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[3]/a\")\n",
    "page1.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "d0a77643",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=2\n",
    "\n",
    "for page7 in range(start,end):\n",
    "    reviewsb=myn.find_elements(By.XPATH,'//div[@class=\"product-productMetaInfo\"]//div')\n",
    "    for i in reviewsb:\n",
    "        blackshoe_price.append(i.text)\n",
    "    next_button5=myn.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[12]/a')\n",
    "    next_button5.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "4f953144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rs. 1529Rs. 5099(70% OFF)',\n",
       " 'Rs. 9349Rs. 10999(15% OFF)',\n",
       " 'Rs. 1619Rs. 5399(70% OFF)',\n",
       " 'Rs. 1294Rs. 3699(65% OFF)',\n",
       " 'Rs. 3024Rs. 5499(45% OFF)']"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(blackshoe_price)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "a40de834",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blackshoe2=[i.split('Rs.', 2)[1] for i in blackshoe_price]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "0f08d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "blackshoe_price2 = ['₹ ' + sub for sub in blackshoe2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "3f71917b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹  1529', '₹  9349', '₹  1619', '₹  1294', '₹  3024']"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blackshoe_price2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0938525",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Displaying Extracted Data in Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "887568d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND</th>\n",
       "      <th>Description</th>\n",
       "      <th>FINAL PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>₹  1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>₹  872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Revolution 5 Running Shoes</td>\n",
       "      <td>₹  3695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Enzo Running Shoes</td>\n",
       "      <td>₹  3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FAUSTO</td>\n",
       "      <td>Men Slip-On Sneakers</td>\n",
       "      <td>₹  890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ZAPATOZ</td>\n",
       "      <td>Women PU Sneakers</td>\n",
       "      <td>₹  798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Men Leather Biker Boots</td>\n",
       "      <td>₹  2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Lebron Witness VI Basketball</td>\n",
       "      <td>₹  8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Sparx</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>₹  1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Running Shoes</td>\n",
       "      <td>₹  2999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BRAND                     Description FINAL PRICE\n",
       "0   Red Tape               Men Walking Shoes     ₹  1349\n",
       "1   Roadster                    Men Sneakers      ₹  872\n",
       "2       Nike  Men Revolution 5 Running Shoes     ₹  3695\n",
       "3       Puma          Men Enzo Running Shoes     ₹  3024\n",
       "4     FAUSTO            Men Slip-On Sneakers      ₹  890\n",
       "..       ...                             ...         ...\n",
       "95   ZAPATOZ               Women PU Sneakers      ₹  798\n",
       "96  Red Tape         Men Leather Biker Boots     ₹  2279\n",
       "97      Nike    Lebron Witness VI Basketball     ₹  8295\n",
       "98     Sparx               Men Running Shoes     ₹  1281\n",
       "99      Puma             Women Running Shoes     ₹  2999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7=pd.DataFrame({'BRAND':blackshoe_brand[:100],'Description':res[:100],'FINAL PRICE':blackshoe_price2[:100]})\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f773d8",
   "metadata": {},
   "source": [
    "<h3><font color='green'>Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "<br>Then set CPU Type filter to “Intel Core i7” as shown in the below image:</h3><h4><font color='green'>\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "<br>1. Title\n",
    "<br>2. Ratings\n",
    "<br>3. Price\n",
    "<br>\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fa695a",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Automate wepage launch and search for parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59580a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "zon=webdriver.Chrome(r\"C:\\Users\\Glenn\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6d015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zon.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecfc728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search8=zon.find_element(By.XPATH,'//input[@type=\"text\"]')\n",
    "search8.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a7882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search8b=zon.find_element(By.XPATH,'//input[@id=\"nav-search-submit-button\"]')\n",
    "search8b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ce6cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tick8c=zon.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[4]/li[12]/span/a/div')\n",
    "tick8c.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc7094",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Extracting required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "624aff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list initialistation\n",
    "tp_title=[]\n",
    "#tp_rating=[]\n",
    "#tp_price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b4ad42f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laptop Title\n",
    "tpt= zon.find_elements(By.XPATH,'//div[@class=\"sg-col sg-col-4-of-12 sg-col-8-of-16 sg-col-12-of-20 s-list-col-right\"]//h2') \n",
    "for i in tpt:\n",
    "    ttle=i.text.split('Intel')[0]\n",
    "    tp_title.append(ttle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e3f99ba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tp_Title=tp_title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "300a2729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laptop Price\n",
    "tpp= zon.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]') \n",
    "for i in tpp:\n",
    "    ttle=i.text\n",
    "    tp_price.append(ttle)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "46b0af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_Price = ['₹ ' + sub for sub in tp_price]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3dce1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laptop rating\n",
    "tpr= zon.find_elements(By.XPATH,'//div[@class=\"a-row a-size-small\"]//span') \n",
    "for i in tpr:\n",
    "    tp=i.get_attribute('aria-label')\n",
    "    tp_rating.append(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7632d962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tp_Rating=tp_rating[:50:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb15fe",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Displaying Extracted data as Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f34d2c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND</th>\n",
       "      <th>RATING</th>\n",
       "      <th>FINAL PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung Galaxy Book2 Pro</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>₹ 1,06,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung Galaxy Book2 Pro 360</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "      <td>₹ 1,29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Slim 5</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>₹ 82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo ThinkBook 15</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>₹ 80,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo ThinkPad E14</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>₹ 94,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Victus 11th Gen</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>₹ 1,08,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo Yoga 7i 11th Gen</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>₹ 1,06,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "      <td>₹ 79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>₹ 1,26,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>₹ 1,07,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               BRAND              RATING  \\\n",
       "0                          Samsung Galaxy Book2 Pro   3.6 out of 5 stars   \n",
       "1                      Samsung Galaxy Book2 Pro 360   3.5 out of 5 stars   \n",
       "2                             Lenovo IdeaPad Slim 5   4.3 out of 5 stars   \n",
       "3                               Lenovo ThinkBook 15   4.3 out of 5 stars   \n",
       "4                               Lenovo ThinkPad E14   5.0 out of 5 stars   \n",
       "5                                HP Victus 11th Gen   5.0 out of 5 stars   \n",
       "6                           Lenovo Yoga 7i 11th Gen   4.4 out of 5 stars   \n",
       "7  ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...  4.7 out of 5 stars   \n",
       "8  ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...  4.1 out of 5 stars   \n",
       "9  ASUS TUF Gaming F15 (2022), 15.6\" (39.62 cms) ...  4.1 out of 5 stars   \n",
       "\n",
       "  FINAL PRICE  \n",
       "0  ₹ 1,06,990  \n",
       "1  ₹ 1,29,990  \n",
       "2    ₹ 82,990  \n",
       "3    ₹ 80,990  \n",
       "4    ₹ 94,990  \n",
       "5  ₹ 1,08,990  \n",
       "6  ₹ 1,06,999  \n",
       "7    ₹ 79,990  \n",
       "8  ₹ 1,26,990  \n",
       "9  ₹ 1,07,990  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8=pd.DataFrame({'BRAND':tp_Title,'RATING':tp_Rating,'FINAL PRICE':tp_Price[:10]})\n",
    "df8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3045d719",
   "metadata": {},
   "source": [
    "<h3><font color='green'>Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida </h3><h4><font color='green'>\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company. \n",
    "This task will be done in following steps:\n",
    "<br>1. First get the webpage https://www.ambitionbox.com/\n",
    "<br>2. Click on the Job option as shown in the image\n",
    "<br>3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button.\n",
    "<br>4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n",
    "<br>5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "<br>6. Finally create a dataframe of the scraped data.\n",
    "Note: All the steps required during scraping should be done through code only and not manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d72391",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Automate Webbrowser launch and search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1e196520",
   "metadata": {},
   "outputs": [],
   "source": [
    "job=webdriver.Chrome(r\"C:\\Users\\Glenn\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "12c2f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a714a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "click9b=job.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[5]/a')\n",
    "click9b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "721101a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search9c=job.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input')\n",
    "search9c.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "73f6ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "click9c=job.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button/span')\n",
    "click9c.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "53e960cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc9d=job.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/i')\n",
    "loc9d.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "85095099",
   "metadata": {},
   "outputs": [],
   "source": [
    "search9c=job.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "search9c.send_keys(\"Noida\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4e664426",
   "metadata": {},
   "outputs": [],
   "source": [
    "click9d=job.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "click9d.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c85cc1",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Extracting required Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "04f7a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_titlenr=[]\n",
    "Job_company=[]\n",
    "Job_exp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a348ba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Job Title\n",
    "jt= job.find_elements(By.XPATH,'//div[@class=\"info\"]//a') \n",
    "for i in jt:\n",
    "    temp=i.text\n",
    "    Job_titlenr.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "e4c92378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quality Engineer',\n",
       " 'Data Scientist- SAS Analyst',\n",
       " 'EY GDS - Data Scientist (10-20 yrs)']"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_title=Job_titlenr[::3]\n",
    "Job_title[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "3cf47a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.1', '4.3', '3.8']"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_review=Job_titlenr[1::3]\n",
    "Job_review[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0f7f52b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Company Name\n",
    "jc= job.find_elements(By.XPATH,'//div[@class=\"info\"]//div//p') \n",
    "for i in jc:\n",
    "    temp=i.get_attribute('title')\n",
    "    Job_company.append(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "b5b99026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Optum Global Solutions (India) Private Limited',\n",
       " 'BARCLAYS GLOBAL SERVICE CENTRE PRIVATE LIMITED',\n",
       " 'EY GDS']"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_company[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "cb24c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Job Exp\n",
    "je= job.find_elements(By.XPATH,'//div[@class=\"other-info\"]//div//p') \n",
    "for i in je:\n",
    "    temp=i.text\n",
    "    Job_exp.append(temp)\n",
    "Job_Exp= [x for x in Job_exp if 'Yrs' in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "fef86914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-7 Yrs', '2-7 Yrs', '10-20 Yrs']"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_Exp[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d0581",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Displaying data as Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a9ae48a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB TITLE</th>\n",
       "      <th>COMPANY NAME</th>\n",
       "      <th>REVIEW</th>\n",
       "      <th>EXPERIENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quality Engineer</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist- SAS Analyst</td>\n",
       "      <td>BARCLAYS GLOBAL SERVICE CENTRE PRIVATE LIMITED</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EY GDS - Data Scientist (10-20 yrs)</td>\n",
       "      <td>EY GDS</td>\n",
       "      <td>3.8</td>\n",
       "      <td>10-20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GLOBALLOGIC INDIA PRIVATE LIMITED</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring Data Scientist #productbasecompany #CBRE</td>\n",
       "      <td>CBRE South Asia Pvt Ltd</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Genpact-Data Scientist- Forecasting...</td>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Genpact - Data Scientist - Forecasting/Python/...</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Machine Learning Algorithms (...</td>\n",
       "      <td>Dew Solutions Pvt. Ltd.</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>One97 Communications Limited</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           JOB TITLE  \\\n",
       "0                                   Quality Engineer   \n",
       "1                        Data Scientist- SAS Analyst   \n",
       "2                EY GDS - Data Scientist (10-20 yrs)   \n",
       "3                                     Data Scientist   \n",
       "4    Hiring Data Scientist #productbasecompany #CBRE   \n",
       "5  Hiring For Genpact-Data Scientist- Forecasting...   \n",
       "6  Genpact - Data Scientist - Forecasting/Python/...   \n",
       "7                                     Data Scientist   \n",
       "8  Data Scientist - Machine Learning Algorithms (...   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                     COMPANY NAME REVIEW EXPERIENCE  \n",
       "0  Optum Global Solutions (India) Private Limited    4.1    2-7 Yrs  \n",
       "1  BARCLAYS GLOBAL SERVICE CENTRE PRIVATE LIMITED    4.3    2-7 Yrs  \n",
       "2                                          EY GDS    3.8  10-20 Yrs  \n",
       "3               GLOBALLOGIC INDIA PRIVATE LIMITED    4.0   8-10 Yrs  \n",
       "4                         CBRE South Asia Pvt Ltd    4.3    5-9 Yrs  \n",
       "5                   GENPACT India Private Limited    4.0   7-12 Yrs  \n",
       "6                                         Genpact    4.0   6-10 Yrs  \n",
       "7        Ericsson India Global Services Pvt. Ltd.    4.3   4-12 Yrs  \n",
       "8                         Dew Solutions Pvt. Ltd.    4.3    3-8 Yrs  \n",
       "9                    One97 Communications Limited    3.8    1-2 Yrs  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9=pd.DataFrame({'JOB TITLE':Job_title,'COMPANY NAME':Job_company,'REVIEW':Job_review,'EXPERIENCE':Job_Exp})\n",
    "df9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b470643d",
   "metadata": {},
   "source": [
    "<h3><font color='green'>Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary. </h3><h4><font color='green'>\n",
    "The above task will be, done as shown in the below steps:\n",
    "<br>1. First get the webpage https://www.ambitionbox.com/\n",
    "<br>2. Click on the salaries option as shown in the image\n",
    "<br>3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and \n",
    "then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "<br>4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average \n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "<br>5. Store the data in a dataframe.\n",
    "<br>Note: All the steps required during scraping should be done through code only and not manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae960922",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Automate web Browser launch and Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "ae39972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "amb=webdriver.Chrome(r\"C:\\Users\\Glenn\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f7c13bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "amb.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "87bce3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "click10a=amb.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[3]/span').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "755e8a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "click10b=amb.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[3]/div/ul/li[1]/div/div[2]/p').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "65309e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "search10a=amb.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div/div/div/div[1]/span/input').send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "9fe1b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "click10b=amb.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div/div/div/div[1]/span/div/div[2]/div[2]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "0d4bf38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "click10b=amb.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div/div/div/button/span').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886a1267",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Scraping the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "f291e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising\n",
    "jobtitle=[]\n",
    "totalsalary=[]\n",
    "job_exper=[]\n",
    "avg_sal=[]\n",
    "minsal=[]\n",
    "maxsal=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "354a36ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Company name\n",
    "cj= amb.find_elements(By.XPATH,'//div[@class=\"name\"]//a') \n",
    "for i in cj:\n",
    "    temp=i.text.split('\\n')[0]\n",
    "    companyjob.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "ae853e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TCS', 'Accenture', 'IBM']"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyjob[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "5f7b413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg Salary\n",
    "As= amb.find_elements(By.XPATH,'//span[@class=\"salary-datapoints\"]') \n",
    "for i in As:\n",
    "    temp=i.text\n",
    "    totalsalary.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "146d53af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1.2k Salaries)', '(723 Salaries)', '(539 Salaries)']"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalsalary[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "53ce0e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Job Exp\n",
    "Je= amb.find_elements(By.XPATH,'//div[@class=\"company-info\"]//span') \n",
    "for i in Je:\n",
    "    temp=i.text\n",
    "    job_exper.append(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "216d052e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-9 yrs exp', '2-9 yrs exp', '2-11 yrs exp']"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_exper[1::3][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "b3924aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min & Max Sal\n",
    "\n",
    "Ms= amb.find_elements(By.XPATH,'//div[@class=\"salary-values\"]//div') \n",
    "for i in Ms:\n",
    "    temp=i.text\n",
    "    minsal.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "dc3744d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 4.4L', '₹ 5.3L', '₹ 5.0L']"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Min=minsal[18::2]\n",
    "Min[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "0c9955e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 15.0L', '₹ 23.0L', '₹ 25.0L']"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Max=Max[19::2]\n",
    "max[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "39a4092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avg annual sal\n",
    "aas= amb.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]') \n",
    "for i in aas:\n",
    "    temp=i.text\n",
    "    avg_sal.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "bddbb988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 7.5L', '₹ 12.1L', '₹ 12.8L']"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_sal[9:][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c6c4ac",
   "metadata": {},
   "source": [
    "<h4><font color='maroon'> Displaying extracted data as Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "edf6e7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPANY NAME</th>\n",
       "      <th>TOTAL SALARY RECORD</th>\n",
       "      <th>EXPERIENCE REQUIRED</th>\n",
       "      <th>MIN SALARY</th>\n",
       "      <th>MAX SALARY</th>\n",
       "      <th>AVG SALARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCS</td>\n",
       "      <td>(1.2k Salaries)</td>\n",
       "      <td>2-9 yrs exp</td>\n",
       "      <td>₹ 4.4L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 7.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>(723 Salaries)</td>\n",
       "      <td>2-9 yrs exp</td>\n",
       "      <td>₹ 5.3L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>₹ 12.1L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>(539 Salaries)</td>\n",
       "      <td>2-11 yrs exp</td>\n",
       "      <td>₹ 5.0L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 12.8L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cognizant</td>\n",
       "      <td>(447 Salaries)</td>\n",
       "      <td>2-10 yrs exp</td>\n",
       "      <td>₹ 4.8L</td>\n",
       "      <td>₹ 17.0L</td>\n",
       "      <td>₹ 9.4L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Capgemini</td>\n",
       "      <td>(392 Salaries)</td>\n",
       "      <td>2-8 yrs exp</td>\n",
       "      <td>₹ 4.8L</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>(333 Salaries)</td>\n",
       "      <td>2-7 yrs exp</td>\n",
       "      <td>₹ 4.5L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wipro</td>\n",
       "      <td>(315 Salaries)</td>\n",
       "      <td>2-9 yrs exp</td>\n",
       "      <td>₹ 4.4L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "      <td>₹ 9.2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>(309 Salaries)</td>\n",
       "      <td>2-12 yrs exp</td>\n",
       "      <td>₹ 4.0L</td>\n",
       "      <td>₹ 16.4L</td>\n",
       "      <td>₹ 7.4L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>(231 Salaries)</td>\n",
       "      <td>1-10 yrs exp</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 50.0L</td>\n",
       "      <td>₹ 27.8L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>(219 Salaries)</td>\n",
       "      <td>2-6 yrs exp</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 23.4L</td>\n",
       "      <td>₹ 15.8L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        COMPANY NAME TOTAL SALARY RECORD EXPERIENCE REQUIRED MIN SALARY  \\\n",
       "0                TCS     (1.2k Salaries)         2-9 yrs exp     ₹ 4.4L   \n",
       "1          Accenture      (723 Salaries)         2-9 yrs exp     ₹ 5.3L   \n",
       "2                IBM      (539 Salaries)        2-11 yrs exp     ₹ 5.0L   \n",
       "3          Cognizant      (447 Salaries)        2-10 yrs exp     ₹ 4.8L   \n",
       "4          Capgemini      (392 Salaries)         2-8 yrs exp     ₹ 4.8L   \n",
       "5            Infosys      (333 Salaries)         2-7 yrs exp     ₹ 4.5L   \n",
       "6              Wipro      (315 Salaries)         2-9 yrs exp     ₹ 4.4L   \n",
       "7      Tech Mahindra      (309 Salaries)        2-12 yrs exp     ₹ 4.0L   \n",
       "8             Amazon      (231 Salaries)        1-10 yrs exp     ₹ 9.0L   \n",
       "9  Fractal Analytics      (219 Salaries)         2-6 yrs exp     ₹ 9.0L   \n",
       "\n",
       "  MAX SALARY AVG SALARY  \n",
       "0    ₹ 15.0L     ₹ 7.5L  \n",
       "1    ₹ 23.0L    ₹ 12.1L  \n",
       "2    ₹ 25.0L    ₹ 12.8L  \n",
       "3    ₹ 17.0L     ₹ 9.4L  \n",
       "4    ₹ 14.5L     ₹ 8.5L  \n",
       "5    ₹ 21.0L     ₹ 8.8L  \n",
       "6    ₹ 18.0L     ₹ 9.2L  \n",
       "7    ₹ 16.4L     ₹ 7.4L  \n",
       "8    ₹ 50.0L    ₹ 27.8L  \n",
       "9    ₹ 23.4L    ₹ 15.8L  "
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10=pd.DataFrame({'COMPANY NAME':companyjob,'TOTAL SALARY RECORD':totalsalary,'EXPERIENCE REQUIRED':job_exper[1::3],'MIN SALARY':Min,'MAX SALARY':Max,'AVG SALARY':avg_sal[9:]})\n",
    "df10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
